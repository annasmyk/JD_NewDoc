# Spectral Analysis Principles and Tools

add : R code, rjd3toolkit references 

## Overview
## Periodogram
### Step 1
For any given frequency $\omega$ the sample periodogram is the sample
analog of the sample spectrum. In general, the periodogram is used to
identify the periodic components of unknown frequency in the time
series. X-13ARIMA-SEATS and TRAMO-SEATS use this tool for detecting
seasonality in raw time series and seasonally adjusted series. Apart
from this it is applied for checking randomness of the residuals from
the ARIMA model.

To define the periodogram, first consider the vector of complex
numbers[^71]:

  $$\mathbf{x} = \begin{bmatrix}      
  x_{1} \\                             
  x_{2} \\                             
  . \\                                 
  . \\                                 
  . \\                                 
  x_{n} \\                             
  \end{bmatrix} \in \mathbb{C}^{n}$$   


where $\mathbb{C}^{n}$ is the set of all column vectors with
complex-valued components.

The Fourier frequencies associated with the sample size $$n$$ are
defined as a set of values $$ω_{j} = \frac{2\pi j}{n}$$,
$$j = - \lbrack \frac{n-1}{2}\rbrack,\ldots,\lbrack\frac{n}{2}\rbrack$$,
$$-\pi< \omega_{j} \leq \pi$$, $$j\in F_{n}$$, where ${\lbrack n\rbrack}$ denotes the largest integer less than or
equal to $n$. The Fourier frequencies, which are called harmonics, are
given by integer multiples of the fundamental frequency
$\ \frac{2\pi}{n}$.

Now the $n$ vectors
$$e_{j} = n^{- \frac{1}{2}}\left(e^{-i\omega_{j}},e^{-i{2\omega}_{j}},
\ldots,e^{- inω_{j}}\right)^{'}$$ can be defined. Vectors $$e_{1},\ldots, e_{n}$$ are orthonormal in the
sense that:

 $$
 {\mathbf{e}_{j}^{*}\mathbf{e}}_{k} = n^{- 1}\sum_{r = 1}^{n}e^{ir(\omega_{j} - \omega_{k})} = \left\{ \begin{matrix}  
  1,\ if\ j = k \\                                                                                                         
  0,\ if\ j \neq k \\                                                                                                      
  \end{matrix} \right.\ 
  $$ 

where $$\mathbf{e}_{j}^{*}$$ denotes the row vector, which $$k^{th}$$
component is the complex conjugate of the $$k^{th}$$ component of
$$\mathbf{e}_{j}$$.[^72] These vectors are a basis of $$F_{n}$$, so that any
$$\mathbf{x}\in\mathbb{C}^{n}$$ can be expressed as a sum of $$n$$ components:

 $$
 \mathbf{x} = \sum_{j = - \lbrack\frac{n - 1}{2}\rbrack}^{\lbrack\frac{n}{2}\rbrack}{a_{j}\mathbf{e}_{j}}
 $$ 

where the coefficients
$$a_{j} = \mathbf{e}_{j}^{*}\mathbf{x}=n^{-\frac{1}{2}}\sum_{t = 1}^{n}x_{t}e^{-it\omega_{j}}$$ are derived from \[3\] by multiplying the equation on the left by $$\mathbf{e}_{j}^{*}$$ and using \[1\].

The sequence of $$\{a_{j},j\in F_{n}\}$$ is referred as a
discrete Fourier transform of $\mathbf{x}\mathbb{\in C}^{n}$ and the
periodogram $I(\omega_{j})$ of $\mathbf{x}$ at Fourier frequency
$\omega_{j} = \frac{2\pi j}{n}$ is defined as the square of the Fourier
transform $$\{a_{j}\}$$ of $\mathbf{x}$: 

$$
{I\left( \omega_{j} \right)\mathbf{=}{\left| a_{j} \right|^{2}}_{\ } = n^{- \ 1}\left| \sum_{t = 1}^{n}x_{t}e^{- it\omega_{j}} \right|^{2}}_{\mathbf{\ }}
$$



From \[2\] and \[3\] it can be shown that in fact the
periodogram decomposes the total sum of squares
$\sum_{t = 1}^{n}\left| x_{t} \right|^{2}$ into a sums of components
associated with the Fourier frequencies $$ω_{j}$$:

$$
  \sum_{t=1}^{n}{\left|x_{t}\right|}^{2} = \sum_{j = - \lbrack\frac{n - 1}{2}\rbrack}^{\lbrack\frac{n}{2}\rbrack}\left|a_{j}\right|^{2} = \sum_{j = - \lbrack\frac{n - 1}{2}\rbrack}^{\lbrack\frac{n}{2}\rbrack}{I\left( \omega_{j} \right)}
$$   

If $\ \mathbf{x\  \in}\ {R}^{n}$, $\omega_{j}$ and
$${-\omega}_{j}$$ are both in
$$\lbrack- \pi, -\pi \rbrack$$ and $$a_{j}$$ is presented in its polar form
(i.e.$$a_{j} = r_{j}\exp\left( i\theta_{j} \right)$$), where
$r_{j}$ is the modulus of $$a_{j}$$, then \[3\] can be
rewritten in the form:
 

 $$
 \mathbf{x} = a_{0}\mathbf{e}_{0} + \sum_{j = 1}^{\lbrack\frac{n - 1}{2}\rbrack}{ {2^{1/2}r}_{j}{(\mathbf{c}}_{j}\cos\theta_{j}{- \mathbf{s}}_{j}\sin\theta_{j}) + a_{n/2}\mathbf{e}_{n/2}}
 $$  

The orthonormal basis for $${R}^{n}$$ is
$$\{\mathbf{e}_{0},\mathbf{c}_{1},\mathbf{s}_{1},\ldots,\mathbf{c}_{\lbrack\frac{n - 1}{2}\rbrack},\mathbf{s}_{\lbrack\frac{n - 1}{2}\rbrack},\mathbf{e}_{\frac{n}{2}(excluded\ if\ n\ is\ odd)}\}
$$,
where: 

$$\mathbf{e}_{0}$$ is a vector composed of n elements equal to $$n^{- 1/2}$$, which implies that $$\mathbf{a}_{0}\mathbf{e}_{0} = {(n^{-1}\sum_{t = 1}^{n}x_{t},\ldots,n^{- 1}\sum_{t=1}^{n}x_{t})}^{'}$$;

$$
\mathbf{c}_{j}=\left(\frac{n}{2}\right)^{- 1/2}{\left(\cos\omega_{j},\cos{2\omega}_{j},\ldots,\cos{n\omega_{j}}\right)}^{'}, for 1 \leq j \leq \lbrack \frac{(n - 1)}{2}\rbrack
$$ ;

$$
\mathbf{s}_{j} = {\left( \frac{n}{2} \right)}^{-1/2}{\left(\sin{\omega_{j}},\sin{2\omega_{j}},\ldots,\sin{n\omega_{j}}\right)}^{'},\ for\ 1 \leq j \leq \lbrack \frac{(n - 1)}{2} \rbrack
$$;

$$
\mathbf{e}_{n/2} = {\left(- \left(n^{-\frac{1}{2}}\right),n^{- \frac{1}{2}},\ldots,{-\left(n\right)}^{- \frac{1}{2}}),n^{-\frac{1}{2}}\right)}^{'}
$$. 

Equation \[5\] can be seen as an OLS regression of $$x_{t}$$ on a
constant and the trigonometric terms. As the vector of explanatory
variables includes $$n$$ elements, the number of explanatory
variables in \[5\] is equal to the number of observations. HAMILTON,
J.D. (1994) shows that the explanatory variables are linearly
independent, which implies that an OLS regression yields a perfect fit
(i.e. without an error term). The coefficients have the form of a simple
OLS projection of the data on the orthonormal basis:

  $$
  {\widehat{a}}_{0}=\frac{1}{\sqrt{n}}\sum_{t=1}^{n}x_{t}
  $$ \[7\] <!---\[7.108\]      -->
  
  $$
  {\widehat{a}}_{n/2}=\frac{1}{\sqrt{n}}\sum_{t=1}^{n}{(-1)}^{t}x_{t}\left(   \text{only when n is even} \right)
  $$  \[8\] <!---\[7.109\]      -->
  
  $$
  {\widehat{a}}_{0}=\frac{1}{\sqrt{n}}\sum_{t=1}^{n}x_{t}
  $$  \[9\] <!---\[7.110\]      -->
  
  $$
  {\widehat{\alpha}}_{j} = 2^{1/2}r_{j}\cos{\theta_{j}} = {\left(\frac{n}{2} \right)}^{- 1/2}\sum_{t = 1}^{n}x_{t}\cos{\left(t\frac{2\pi j}{n}\right)}, j   = 1,\ldots,\lbrack\frac{n - 1}{2}\rbrack
  $$   \[10\] <!---\[7.111\]      -->
  
  $$
  {\widehat{\beta}}_{j} = 2^{1/2}r_{j}\sin{\theta_{j}} = {\left( \frac{n}{2} \right)}^{-1/2}\sum_{t = 1}^{n}x_{t}\sin{\left(t\frac{2\pi j}{n} \right)}, j = 1,\ldots,\lbrack\frac{n - 1}{2}\rbrack
  $$  \[11\] <!---\[7.112\]      -->

With \[5\] the total sum of squares
$\sum_{t = 1}^{n}\left| x_{t} \right|^{2}$ can be decomposed into
$$2 \times \lbrack\frac{n - 1}{2}\rbrack$$ components corresponding to
$$\mathbf{c}_{j}$$ and $$\mathbf{s}_{j}$$, which are grouped to produce
the "frequency $$ω_{j}$$" component for $$1 \geq j \geq \lbrack\frac{n - 1}{2}\rbrack$$. As it is shown in the table below, the
value of the periodogram at the frequency $\omega_{j}$ is the
contribution of the$\ j^{\text{th}}\ $harmonic to the total sum of
squares $\sum_{t = 1}^{n}\left| x_{t} \right|^{2}$.

**Decomposition of sum of squares into components
corresponding to the harmonics**

{: .table .table-style}
  |**Frequency**                                   |**Degrees of freedom**   |**Sum of squares decomposition**|
  |----------------------------------------------- |------------------------ |-------------------------------------------------------------|
  |$\omega_{0}$(mean)                              |1                        |$${a_{0}^{2}}_{\ }=n^{- 1}\left( \sum_{t=1}^{n}x_{t} \right)^{2} = I\left( 0 \right)$$|
  |$$\omega_{1}$$                                  |2                        |$${2r_{1}^{2}}_{\ } = 2{\|a_{1}\|}^{2} = 2I\left( \omega_{1} \right)$$|
  |$$\vdots$$                                      |$$\vdots$$               |$$\vdots$$|
  |$$\omega_{k}$$                                  |2                        |$${2r_{k}^{2}}_{\ } = 2{\|a_{k}\|}^{2} = 2I\left( \omega_{k} \right)$$|
  |$$\vdots$$                                      |$$\vdots$$               |$$\vdots$$|
  |$\omega_{n/2} = \pi$ (excluded if $n$ is odd)   |1                        |$$a_{n/2}^{2} = I\left( \pi \right)$$|
  |**Total**                                       |$$\mathbf{n}$$           |$$\sum_{\mathbf{t = 1}}^{\mathbf{n}}\mathbf{x}_{\mathbf{t}}^{\mathbf{2}}$$|

Source: DE ANTONIO, D., and PALATE, J. (2015).



Obviously, if series were random then each component
$I\left( \omega_{j} \right)\ $would have the same expectation. On the
contrary, when the series contains a systematic sine component having a
frequency $j$ and amplitude $A$ then the sum of squares
$I\left( \omega_{j} \right)$ increases with $A$. In practice, it is
unlikely that the frequency $j$ of an unknown systematic sine component
would exacly match any of the frequencies, for which peridogram have
been calcuated. Therefore, the periodogram would show an increase in
intensities in the immediate vicinity of $j$.[^73]

Note that in JDemetra+ the periodogram object corresponds exactly to the
contribution to the sum of squares of the standardised data, since the
series are divided by their standard deviation for computational
reasons.

Using the decomposition presented in table above the periodogram can be
expressed as:

$$
I\left( \omega_{j} \right)\mathbf{=}\begin{matrix}                                                                                r_{j}^{2} = \frac{1}{2}{(\alpha}_{j}^{2} + \beta_{j}^{2}) = \ {\frac{1}{n}\left( \sum_{t = 1}^{n}{x_{t}\cos{\left( {t\frac{2\pi j}{n}}_{\ } \right)\ }} \right)}^{2} + \frac{1}{n}\left( \sum_{t = 1}^{n}{x_{t}\sin\left( t\frac{2\pi j}{n} \right)_{\ }} \right)^{2} \\   
\end{matrix}
$$ \[12\] <!---\[7.113\]      -->

where $j = 0,\ldots,\left\lbrack \frac{n}{2} \right\rbrack$*.*

Since $\mathbf{x} - \overline{\mathbf{x}}$ are generated by an
orthonormal basis, and
$\overline{\mathbf{x}}\mathbf{=}a_{0}\mathbf{e}_{0}$ \[5\] can be
rearranged to show that the sum of squares is equal to the sum of the
squared coefficients:

 $$
 \mathbf{x} - a_{0}\mathbf{e}_{0} =\sum_{j=1}^{\lbrack(n - 1)/2\rbrack}\left(\alpha_{j}\mathbf{c}_{j}+\beta_{j}\mathbf{s}_{j}\right) + a_{n/2}\mathbf{e}_{n/2}
 $$.   \[13\] <!---\[7.114\]      -->

Thus the sample variance of $$x_{t}$$ can be expressed as:

$$
n^{- 1}\sum_{t=1}^{n}{\left(x_{t}-\overline{x}\right)}^{2}=n^{-1}\left(\sum_{k=1}^{\lbrack(n - 1)/2\rbrack}2{r_{j}}^{2}
+{a_{n/2}}^{2}\right) 
$$,  \[14\] <!---\[7.115\]      -->

where $a_{n/2}^{2}$ is excluded if $n$ is odd.

The term $$2{r_{j}}^{2}$$ in \[14\] is then the contribution of
the $j^{\text{th}}$ harmonic to the variance and \[14\] shows then
how the total variance is partitioned.

The periodogram ordinate $I\left( \omega_{j} \right)$ and the
autocovariance coefficient $\gamma(k)$ are both quadratic forms of
$$x_{t}$$. It can be shown that the periodogram and
autocovarinace function are related and the periodogram can be written
in terms of the sample autocovariance function for any non-zero Fourier
frequency $$ω_{j}$$ :[^74]

  $$
  I\left( \omega_{j} \right) = \sum_{\left| k \right| < n}^{\ }{\widehat{\gamma}\left( k \right)}_{\ }e^{- ik\omega_{j}} = {\widehat{\gamma}\left( 0 \right)}_{\ } + 2\sum_{k = 1}^{n - 1}{\widehat{\gamma}\left( k \right)\cos{(k\omega_{j})}}_{\ }
  $$  

and for the zero frequency
$\ I\left( 0 \right) = n\left| \overline{x} \right|^{2}$.

Once comparing \[15\] with an expression for the spectral density of
a stationary process:


   $$
f\left( \omega_{\ } \right) = \frac{1}{2\pi}\sum_{k < - \infty}^{\infty}{\gamma\left( k \right)}_{\ }e^{- ik\omega_{\ }} = \frac{1}{2\pi}\left\lbrack {\gamma\left( 0 \right)}_{\ } + 2\left(\sum_{k = 1}^{\infty}{\gamma\left( k \right)\cos{(k\omega_{\ })}} \right) \right\rbrack
   $$


it can be noticed that the periodogram is a sample analog of the
population spectrum. In fact, it can be shown that the periodogram is
asymptotically unbiased but inconsistent estimator of the population
spectum $f(\omega)$.[^75] Therefore, the periodogram is a wildly
fluctuatating, with high variance, estimate of the spectrum. However,
the consistent estimator can be achieved by applying the different
linear smoothing filters to the periodogram, called lag-window
estimators. The lag-window estimators implemented in JDemetra+ includes
square, Welch, Tukey, Barlett, Hanning and Parzen. They are described in
DE ANTONIO, D., and PALATE, J. (2015). Alternatively, the model-based
consistent estimation procedure, resulting in autoregressive spectrum
estimator, can be applied.

[^71]: BROCKWELL, P.J., and DAVIS, R.A. (2002).

[^72]: For details see BROCKWELL, P.J., and DAVIS, R.A. (2006).

[^73]: BOX, G.E.P., JENKINS, G.M., and REINSEL, G.C. (2007).

[^74]: The proof is given in BROCKWELL, P.J., and DAVIS, R.A. (2006).


### Step 2
The periodogram $$ I(\omega_j)$$  of $$ \mathbf{X} \in \mathbb{C}^n $$ is defined as the squared of the Fourier transform

$$
I(\omega_{j})=a_{j}^{2}=n^{-1}\left| \sum_{t=1}^{n}\mathbf{X_t} e^{-it\omega_j} \right|^{2},
$$

where the Fourier frequencies  $$ \omega_{j} $$  are given by multiples of the fundamental frequency $$ \frac{2\pi}{n} $$:

$$
\omega_{j}= \frac{2\pi j}{n}, -\pi < \omega_{j} \leq \pi 
$$

An orthonormal basis in  $$ \mathbb{R}^n $$:

$$ 
\left\{ e_0, ~~~~~~c_1, s_1, ~~~~~\ldots~~~~~\ , ~~~~c_{[(n-1)/2]}, s_{[(n-1)/2]}~~~~,~~~~~~ e_{n/2}  \right\},
$$ 
where $$ e_{n/2} $$ is excluded if $$ n $$ is odd,  
can be used to project the data and obtain the spectral decomposition

Thus, the periodogram is given by the projection coefficients and represents the contribution of the jth 
harmonic to the total sum of squares, as illustrated by Brockwell and Davis (1991):

| Source   | Degrees of freedom  |  $$~~~~$$ Sum of squares decomposition |
|---|:---:|---:|
| Frequency $$ \omega_{0} $$  | 1  | $$ a_{0}^{2}= n^{-1}(\sum_{t=1}^{n}x_t )^2 =I(0)$$ |
| Frequency $$ \omega_{1} $$    |  2 | $$ 2 r^{2}_{1} = 2 \left\| a_{1} \right\|^{2} = 2 I(\omega_{1}) $$  |
| $$ \vdots $$  |   $$ \vdots $$   |  $$ \vdots $$  |
| Frequency $$ \omega_{k} $$  | 2  | $$ 2 r^{2}_{k} = 2 \left\| a_{k} \right\|^{2} = 2 I(\omega_{k}) $$    |
| $$ \vdots $$  |  $$ \vdots $$    |   $$ \vdots $$  |
| Frequency $$ \omega_{n/2}=\pi $$    | 1  | $$ a_{n/2}^{2} = I(\pi) $$  |
| (excluded if $$ n $$ is odd)   |   |   |
|  $$ ========= $$ | $$ ====== $$ | $$ ============ $$   |
|  Total |  n |    $$ \sum_{t=1}^{n}\mathbf{X^2_t} $$|

$$~~~~$$

In JDemetra+, the periodogram of $$ \mathbf{X} \in \mathbb{R}^n $$ is computed for the standardized time series. 


This scenario is designed for advanced users interested in an in-depth analysis of
time series in the frequency domain using three spectral graphs. Those
graphs can also be used as a complementary analysis for a better
understanding of the results obtained with some of the tests described
above.

Economic time series are usually presented in a time domain (X-axis).
However, for analytical purposes it is convenient to convert the
series to a frequency domain due to the fact that any stationary time
series can be expressed as a combination of cosine (or sine) functions.
These functions are characterized with different periods (amount of time
to complete a full cycle) and amplitudes (maximum/minimum value during
the cycle).

The tool used for the analysis of a time series in a frequency domain is
called a spectrum. The peaks in the spectrum indicate the presence of
cyclical movements with periodicity between two months and one year. A seasonal
series should have peaks at the seasonal
frequencies. Calendar adjusted data are not expected to have peak at with a
calendar frequency.

The periodicity of the phenomenon at frequency *f* is $\frac{2\pi}{f}$. It
means that for a monthly time series the seasonal frequencies
$\frac{\pi}{6},\ \frac{\pi}{3},\ \frac{\pi}{2},\ \frac{2\pi}{3},\ \frac{5\pi}{6}\ $
and $\pi$ correspond to 1, 2, 3, 4, 5 and 6 cycles per year. For
example, the frequency $\frac{\pi}{3}$ corresponds to a periodicity of 6
months (2 cycles per year are completed). For the quarterly series there
are two seasonal frequencies: $\frac{\pi}{2}$ (one cycle per year) and
$\pi$ (two cycles per year). A peak at the zero frequency always
corresponds to the trend component of the series. Seasonal frequencies
are marked as grey vertical lines, while violet vertical lines represent the
trading-days frequencies. The trading day frequency is 0.348 and derives
from the fact that a daily component which repeats every seven days goes
through 4.348 cycles in a month of average length 30.4375 days. It is
therefore seen to advance 0.348 cycles per month when the data are
obtained at twelve equally spaced times in 365.25 days (the average
length of a year).

The interpretation of the spectral graph is rather straightforward. When
the values of a spectral graph for low frequencies (i.e. one year and
more) are large in relation to its other values it means that the
long-term movements dominate in the series. When the values of a
spectral graph for high frequencies (i.e. below one year) are large in
relation to its other values it means that the series are rather
trendless and contains a lot of noise. When the values of a spectral
graph are distributed randomly around a constant without any visible
peaks, then it is highly probable that the series is a random process.
The presence of seasonality in a time series is manifested in a spectral
graph by the peaks on the seasonal frequencies.


A time series $$x_{t}$$ with stationary covariance, mean $μ$ and
$$k^{th}$$ autocovariance
$E\left( \left( x_{t} - \mu \right)\left( x_{t - k} - \mu \right) \right) = \gamma(k)\$ can be described as a weighted sum of periodic trigonometric functions:
sin$(\omega t)$ and cos$(\omega t)$, where $\omega$ denotes frequency.
Spectral analysis investigates this frequency domain representation of
$x_{t}$ to determine how important cycles of different frequencies are
in accounting for the behaviour of $x_{t}$.

Assuming that the autocovariances $\gamma(k)$ are absolutely summable
($\sum_{k = - \infty}^{\infty}\left| \gamma(k) \right| < \infty$), the
autocovariance generating function, which summarises these
autocovariances through a scalar valued function, is given by equation
\[1\][^65].

 
  $acgf(z) = \sum_{k = - \infty}^{\infty}{z^{k}\gamma(k)}$,  

where $z$ denotes complex scalar.

Once the equation \[1\]<!---\[7.98\]--> is divided by $\pi$ and evaluated at some
$z{= e}^{- i\omega} = cos\omega - isin\omega$, where $i = \sqrt{- 1}$
and $\omega$ is a real scalar,$\  - \infty < \ \omega < \infty$, the
result of this transformation is called a population spectrum
$f\left( \omega \right)\ $for $\ x_{t}$, given in equation \[2\][^65].

 
$$f\left( \omega \right) = \frac{1}{\pi}\sum_{k = - \infty}^{\infty}{e^{- ik\omega}\gamma(k)}$$  


Therefore, the analysis of the population spectrum in the frequency
domain is equivalent to the examination of the autocovariance function
in the time domain analysis; however it provides an alternative way of
inspecting the process. Because $f\left( \omega \right)\text{dω}$ is
interpreted as a contribution to the variance of components with
frequencies in the range $(\omega,\ \omega + d\omega)$, a peak in the
spectrum indicates an important contribution to the variance at
frequencies near the value that corresponds to this peak.

As $e^{- i\omega} = cos\omega - isin\omega,\ $the spectrum can be also
expressed as in equation \[3\].


$$f\left( \omega \right) = \frac{1}{\pi}\sum_{k = - \infty}^{\infty}{(cos\omega k - isin\omega k)\gamma(k)}$$ 

Since $\gamma(k) = \gamma( - k)$ (i.e. $\gamma(k)\ $is an even function
of $k$) and $\sin{( - x)}\  = \operatorname{-sin}x$, \[3\]<!---\[7.100\]--> can be
presented as equation

$$f\left( \omega \right) = \frac{1}{\pi}\left\lbrack \ \gamma(0) + 2\sum_{k = 1}^{\infty}{\ \gamma(k)}cos\text{ωk} \right\rbrack$$,  

This implies that if autocovariances are absolutely summable the
population spectrum exists and is a continuous, real-valued function of
$\omega$. Due to the properties of trigonometric functions
$\left( \cos\left( - \omega k \right) = \cos\left( \text{ωk} \right) \right.\ \ $and
$\left. \ \cos\left( \omega + 2\pi j)k = cos(\omega k \right) \right)\ $the
spectrum is a periodic, even function of $\omega$, symmetric around
$\omega = 0$. Therefore, the analysis of the spectrum can be reduced to
the interval $( - \pi,\pi).$ The spectrum is nonnegative for all
$\omega \in ( - \pi,\pi)$.

The shortest cycle that can be distinguished in a time series lasts two
periods. The frequency which corresponds to this cycle is $\omega = \pi$
and is called the Nyquist frequency. The frequency of the longest cycles
that can be observed in the time series with $n$ observations is
$\omega = \frac{2\pi}{n}$ and is called the fundamental (Fourier)
frequency.

Note that if $$x_{t}$$ is a white noise process with zero mean and
variance $$\sigma^{2}$$, then for all $$\left| k \right| > 0$$
$$\gamma\left(k\right)=0$$ and the spectrum of $$x_{t}$$ is constant
($$f\left(\omega\right)= \frac{\sigma^{2}}{\pi}$$) since each frequency
in the specrum contributes equally to the variance of the process[^68].

The aim of spectral analysis is to determine how important cycles of
different frequencies are in accounting for the behaviour of a time
series[^65]. Since spectral analysis can be used to detect the presence
of periodic components, it is a natural diagnostic tool for detecting
trading day effects as well as seasonal effects[^70]. Among the tools
used for spectral analysis are the autoregressive spectrum and the
periodogram.

The explanations given in the subsections of this node derive mainly from DE
ANTONIO, D., and PALATE, J. (2015) and BROCKWELL, P.J., and DAVIS, R.A.
(2006).


[^65]: HAMILTON, J.D. (1994).
[^67]: CHATFIELD, C. (2004).
[^68]: BROCKWELL, P.J., and DAVIS, R.A. (2002).
[^70]: SOKUP, R.J., and FINDLEY, D. F. (1999).
##  AR Spectrum definition

The estimator of the spectral density at frequency $$\lambda \in [0,\pi]$$ will be given by the assumption that the series will follow 
an AR(p) process with large $$p$$. The spectral density of such model, with an innovation variance $$ var(x_{t})=\sigma^2_x $$, is  expressed 
as follows:

$$
 10\times log_{10} f_x(\lambda)=10\times log_{10} \frac{\sigma^2_x}{2\pi \left|\phi(e^{i\lambda}) \right|^2 }=10\times log_{10} \frac{\sigma^2_x}{2\pi \left|1-\sum_{k=1}^{p}\phi_k e^{i k \lambda}) \right|^2 }
$$

where $$ \phi_k $$ denotes the AR(k) coefficient, and $$ e^{-ik\lambda}=cos⁡(-ik\lambda)+i sin⁡(-ik\lambda)$$. 

Soukup and Findely (1999) suggest the use of p=30, which in practice much larger than the order that would result from the AIC criterion. 
The minimum number of observations needed to compute the spectrum is set to *n=80* for monthly data (or *n=60*) for quarterly series. 
In turn, the maximum number of observations considered for the estimation is *n=121*. This choice offers enough resolution, 
being able to identify a maximum of 30 peaks in a plot of 61 frequencies: by choosing $$ \lambda_j=\pi j/60 $$,for $$ j=0,1,…,60 $$, we are able to 
calculate our density estimates at exact seasonal frequencies (1, 2, 3, 4, 5 and 6 cycles per year). Note that $$x$$ cycles per year can be converted 
into cycles per month by simply dividing by twelve, $$x/12$$, and to radians by applying the transformation $$2\pi(x/12)$$.  

The traditional trading day frequency corresponding to 0.348 cycles per month is used in place of the closest frequency  $$\pi j/60$$. Thus, we replace $$\pi 42/60$$ 
by $$\lambda_{42}=0.348\times 2 \pi = 2.1865 $$. The frequencies neighbouring $$ \lambda_{42}$$ are set to  $$ \lambda_{41}= 2.1865-1/60 $$ and $$\lambda_{43}= 2.1865+1/60$$.
The periodogram below illustrates the proximity of this trading day frequency $$\lambda_{42}$$ (red shade) and the frequency corresponding 
to 4 cycles per year $$\lambda_{40}=2.0944$$. This proximity is precisely what poses the identification problems: the AR spectrum boils down to a smoothed version of the periodogram and the 
contribution of the of the trading day frequency may be obscured by the leakage resulting from the potential seasonal peak at $$\lambda_{40}$$, and vice-versa.  



![Text](All_imagesUG_A_image19.png)

**Periodogram with seasonal (grey) and calendar (red)
frequencies highlighted**


JDemetra+ allows the user to modify the number of lags of this estimator and to change the number of 
observations used to determine the AR parameters. These two options can improve the resolution of this estimator.

![artest](All_images/spectrum.png)


## Autoregressive spectrum estimation

BROCKWELL, P.J., and DAVIS, R.A. (2006) point out that for any
real-valued stationary process $\left\(x_{t}\right\)$ with continuous spectral
density $f\left\(\omega\right\)$ it is possible to find both
$AR(p)$ and $MA(q)$ processes which spectral densities are arbitrarily
close to $f\left\(\omega\right)$. For this reason, in some sense,
$\left\(x_{t}\right\)$ can be approximated by either $AR(p)$ or $MA(q)$
process. This fact is a basis of one of the methods of achieving a
consistent estimator of the spectrum, which is called an autoregressive
spectrum estimation. It is based on the approximation of the stochastic
process $\left\(x_{t}\right\)$ by an autoregressive process of
sufficiently high order $p$:

  $$
  x_{t} = \mu + \left( \phi_{1}B + \ldots + \phi_{p}B^{p} \right)x_{t} + \varepsilon_{t}
  $$   

where $$\varepsilon_{t}$$ is a white-noise variable with mean zero and a
constant variance.

The autoregressive spectrum estimator for the series $x_{t}$ is defined
as: [^76]

 $$
 \widehat{s}\left( \omega \right) = 10\operatorname{\times}{\log_{10}\frac{\sigma_{x}^{2}}{2\pi{|1 - \sum_{k = 1}^{p}{\widehat{\phi}}_{k}e^{- ik\omega}|}^{2}}}
 $$ 

where:

$\omega$-- frequency, $0 \leq \omega \leq \pi$;

$\sigma_{x}^{2}$ -- the innovation variance of the sample residuals;

$${\widehat{\phi}}_{k}$$ -- $\text{AR}\left\(k\right\)$ coefficient
estimates of the linear regression of $x_{t} - \overline{x}$ on
$x_{t - k} - \overline{x}$, $1 \leq k \leq p$.

The autoregressive spectrum estimator is used in the visual spectral
analysis tool for detecting significant peaks in the spectrum. The
criterion of *visual significance*, implemented in JDemetra+, is based
on the range ${\widehat{s}}^{\max} - {\widehat{s}}^{\min}$ of the
$\widehat{s}\left( \omega \right)$ values, where
${\widehat{s}}^{\max} = \max_{k}\widehat{s}\left( \omega_{k} \right)$;
${\widehat{s}}^{\min} = \min_{k}\widehat{s}\left( \omega_{k} \right);$
and $\widehat{s}\left( \omega_{k} \right)\ $is $k^{\text{th}}$ value of
autoregressive spectrum estimator.

The particular value is considered to be visually significant if, at a
trading day or at a seasonal frequency $\omega_{k}$ (other than the
seasonal frequency $\omega_{60} = \pi$),
$\widehat{s}\left( \omega_{k} \right)\ $is above the median of the
plotted values of $\widehat{s}\left( \omega_{k} \right)$ and is larger
than both neighbouring values $\widehat{s}\left( \omega_{k - 1} \right)$
and $\widehat{s}\left( \omega_{k + 1} \right)$ by at least
$\frac{6}{52}$ times the range
${\widehat{s}}^{\max} - {\widehat{s}}^{\min}$.

Following the suggestion of SOUKUP, R.J., and FINDLEY, D.F. (1999),
JDemetra+ uses an autoregressive model spectral estimator of model order 30. This order yields high resolution of strong components, meaning peaks that are sharply defined in the plot of
$\widehat{s}\left( \omega \right)$ with 61 frequencies. The minimum
number of observations needed to compute the spectrum is set to $n =$ 80
for monthly data and to $n =$ 60 for quarterly series while the maximum
number of observations considered for the estimation is 121.
Consequently, with these settings it is possible to identify up to 30
peaks in the plot of 61 frequencies. By choosing
$\omega_{k} = \frac{\text{πk}}{60}$ for $k = $0,1,...,60 the density
estimates are calculated at exact seasonal frequencies
(1, 2, 3, 4, 5 and 6 cycles per year).

The model order can also be selected based on the AIC criterion (in
practice it is much lower than 30). A lower order produces the smoother
spectrum, but the contrast between the spectral amplitudes at the
trading day frequencies and neighbouring frequencies is weaker, and
therefore not as suitable for automatic detection.

SOUKUP, R.J., and FINDLEY, D.F. (1999) also explain that the periodogram
can be used in the *visual significance* test as it has as good as those
of the AR(30) spectrum abilities to detect trading day effect, but also
has a greater false alarm rate[^77].

[^76]: Definition from '*X-12-ARIMA Reference Manual*' (2011).

[^77]: The false alarm rate is defined as the fraction of the 50
    replicates for which a visually significant spectral peak occurred
    at one of the trading day frequencies being considered in the
    designated output spectra (SOUKUP, R.J., and FINDLEY, D.F. (1999)).


####  Use

The test can be applied directly to any series by selecting the 
option *Statistical Methods >> Seasonal Adjustment >> Tools >> Seasonality Tests*. This is
an example of how results are displayed for the case of a monthly series:

 


JDemetra+ considers critical values for  $$ \alpha=1\%$$  (code “A”) and $$ \alpha=5\%$$  (code “a”) at each one of the seasonal
frequencies represented in the table below, e.g. frequencies $\frac{\pi}{6},\ \frac{\pi}{3},\ \frac{\pi}{2},\ \frac{2\pi}{3}\text{ and } \frac{5\pi}{6}\ $ corresponding 
to 1, 2, 3, 4, 5 and 6 cycles per year in this example, since we are dealing with monthly 
data. The codes “t” and “T” correpond to the so-called
[Tukey spectrum]({{ site.baseurl }}/pages/theory/Tests_TKspectrum.html), so ignore them for the moment.

**The seasonal and trading day frequencies by time series
frequency**

  |**Number of months per full period**  | **Seasonal frequency**                                                               | **Trading day frequency (radians)**|
  |--------------------------------------| -------------------------------------------------------------------------------------| ------------------------------------|
  |12                                    | $\frac{\pi}{6},\frac{\pi}{3},\ \frac{\pi}{2},\frac{2\pi}{3},\ \frac{5\pi}{6},\ \pi$  | $d$, 2.714|
  |6                                     | $\frac{\pi}{3},\frac{2\pi}{3}$, $\pi$                                                | $$d$$
  |4                                     | $\frac{\pi}{2}$, $\pi$                                                               | $d$, 1.292, 1.850, 2.128|
  |3                                     | $$\pi$$                                                                              | $$d$$|
  |2                                     | $$\pi$$                                                                              | $$d$$|

Currently, only seasonal frequencies are tested, but the program allows you to manually plot the AR spectrum and focus your attention on both seasonal
and trading day frequencies. Agustin Maravall  has conducted a 
simulation experiment to calculate $$ CV(\lambda_{42}) $$ (trading day frequency) and proposes to set for all $$j$$ equal 
to the critical value associated to the trading frequency, but this is currently not part of the current automatic testing procedure of JDemetra+.



####  References

- Soukup, R.J., and D.F. Findley (1999) On the Spectrum Diagnosis used by X12-ARIMA to Indicate the Presence of Trading Day Effects After Modeling or Adjustment. In Proceedengs of the American Statistical Association. Business and Economic Statistics Section, 144-149, Alexandria, VA.


## Tukey Spectrum definition

The Tukey spectrum belongs to the class of lag-window estimators. A lag window estimator of the spectral density 
$$
f(\omega)=\frac{1}{2\pi}\sum_{k<-\infty}^{\infty}\gamma(k)e^{i k \omega}
$$
is defined as follows:
$$
\hat{f}_{L}(\omega)=\frac{1}{2\pi}\sum_{\left| h \right| \leq r } w(h/r)\hat{\gamma}(h)e^{i h \omega}
$$

where $$\hat{\gamma}(.) $$ is the sample autocovariance function, $$w(.)$$ is the lag window, and $$r$$ is the
truncation lag. $$\left| w(x)\right| $$ is always less than or equal to one, $$w(0)=1$$ and $$w(x)=0$$ for $$\left| x \right| > 1$$. The 
simple idea behind this formula is to down-weight the autocovariance function for high lags where $$\hat{\gamma}(h)$$  is more unreliable. This estimator 
requires choosing $$r$$ as a function of the sample size such that $$r/n \rightarrow 0 $$ and  $$r\rightarrow \infty $$ when $$ n \rightarrow \infty $$ . 
These conditions guarantee that the estimator converges to the true density.    

JDemetra+ implements the so-called Blackman-Tukey (or Tukey-Hanning) estimator, which is given 
by $$w(h/r)=0.5(1+cos(\pi h/r))$$ if $$\left| h/r \right| \leq 1$$ and $$0$$ otherwise. 

The choice of large truncation lags $$r$$  decreases the bias, of course, but it also increases the variance of the spectral estimate and decreases the bandwidth. 

JDemetra+ allows the user to modify all the parameters of this estimator, including the window function.




### Theoretical spectrum of the ARIMA model

link to graph display in GUI 

In the bottom part the panel [the ARIMA model](../theory/SA_lin.html) used by TRAMO is presented
using symbolic notation \\((P,D,Q)(PB,DB,QB)\\). Estimated
parameters’ coefficients (regular and seasonal AR and MA) are shown in
closed form (i.e. using the backshift operator[^3] \\(B\\)). For each
regular AR root (i.e. the solution of the characteristic equation) the
[argument and modulus](../theory/SA_SEATS.html#derivation-of-the-models-for-the-components) are given.



![Text](All_images/RM_C_pic03.jpg)

**The details of ARIMA model used for modelling**

For each regular AR root the argument and modulus are also reported (if
present, i.e. if \\(\mathbf{P > 0}\\)) to inform to which time series
component the regular roots would be assigned.



[^3]: A backshift operator \\(B\ \\)is defined as: ($B^{k}x_{t} = x_{t - k})$. It is used to denote lagged series.




