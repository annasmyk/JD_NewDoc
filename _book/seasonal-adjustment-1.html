<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Seasonal Adjustment | JDemetra+ online documentation</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Seasonal Adjustment | JDemetra+ online documentation" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Seasonal Adjustment | JDemetra+ online documentation" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Anna Smyk" />


<meta name="date" content="2022-05-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="main-functions-overview.html"/>
<link rel="next" href="high-frequency-data-seasonal-adjustment.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">JDemetra+ online documentation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="jdemetra-software.html"><a href="jdemetra-software.html"><i class="fa fa-check"></i><b>1</b> JDemetra+ Software</a>
<ul>
<li class="chapter" data-level="1.1" data-path="jdemetra-software.html"><a href="jdemetra-software.html#structure-of-this-book"><i class="fa fa-check"></i><b>1.1</b> Structure of this book</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="jdemetra-software.html"><a href="jdemetra-software.html#available-algorithms"><i class="fa fa-check"></i><b>1.1.1</b> Available algorithms</a></li>
<li class="chapter" data-level="1.1.2" data-path="jdemetra-software.html"><a href="jdemetra-software.html#tools-to-access-the-functions"><i class="fa fa-check"></i><b>1.1.2</b> Tools to access the functions</a></li>
<li class="chapter" data-level="1.1.3" data-path="jdemetra-software.html"><a href="jdemetra-software.html#underlying-statistical-methods"><i class="fa fa-check"></i><b>1.1.3</b> Underlying Statistical Methods</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="jdemetra-software.html"><a href="jdemetra-software.html#audience"><i class="fa fa-check"></i><b>1.2</b> Audience</a></li>
<li class="chapter" data-level="1.3" data-path="jdemetra-software.html"><a href="jdemetra-software.html#how-jdemetra-came-to-be"><i class="fa fa-check"></i><b>1.3</b> How Jdemetra+ came to be</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="quick-start-with.html"><a href="quick-start-with.html"><i class="fa fa-check"></i><b>2</b> Quick start with…</a>
<ul>
<li class="chapter" data-level="2.1" data-path="quick-start-with.html"><a href="quick-start-with.html#seasonal-adjustment"><i class="fa fa-check"></i><b>2.1</b> Seasonal Adjustment</a></li>
<li class="chapter" data-level="2.2" data-path="quick-start-with.html"><a href="quick-start-with.html#seasonal-adjustment-of-high-frequency-data"><i class="fa fa-check"></i><b>2.2</b> Seasonal Adjustment of High-Frequency Data</a></li>
<li class="chapter" data-level="2.3" data-path="quick-start-with.html"><a href="quick-start-with.html#use-of-jd-algorithms-in-r"><i class="fa fa-check"></i><b>2.3</b> Use of JD+ algorithms in R</a></li>
<li class="chapter" data-level="2.4" data-path="quick-start-with.html"><a href="quick-start-with.html#use-of-jd-graphical-interface"><i class="fa fa-check"></i><b>2.4</b> Use of JD+ graphical interface</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="main-functions-overview.html"><a href="main-functions-overview.html"><i class="fa fa-check"></i><b>3</b> Main functions overview</a>
<ul>
<li class="chapter" data-level="3.1" data-path="main-functions-overview.html"><a href="main-functions-overview.html#seasonal-adjustment-algorithms"><i class="fa fa-check"></i><b>3.1</b> Seasonal adjustment algorithms</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="main-functions-overview.html"><a href="main-functions-overview.html#data-frequencies"><i class="fa fa-check"></i><b>3.1.1</b> Data frequencies</a></li>
<li class="chapter" data-level="3.1.2" data-path="main-functions-overview.html"><a href="main-functions-overview.html#x-13"><i class="fa fa-check"></i><b>3.1.2</b> X-13</a></li>
<li class="chapter" data-level="3.1.3" data-path="main-functions-overview.html"><a href="main-functions-overview.html#stl"><i class="fa fa-check"></i><b>3.1.3</b> STL</a></li>
<li class="chapter" data-level="3.1.4" data-path="main-functions-overview.html"><a href="main-functions-overview.html#tramo-seats"><i class="fa fa-check"></i><b>3.1.4</b> Tramo-Seats</a></li>
<li class="chapter" data-level="3.1.5" data-path="main-functions-overview.html"><a href="main-functions-overview.html#basic-strcutural-models"><i class="fa fa-check"></i><b>3.1.5</b> Basic Strcutural models</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="main-functions-overview.html"><a href="main-functions-overview.html#trend-cycle-estimation"><i class="fa fa-check"></i><b>3.2</b> Trend-cycle estimation</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html"><i class="fa fa-check"></i><b>4</b> Seasonal Adjustment</a>
<ul>
<li class="chapter" data-level="4.1" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#motivation"><i class="fa fa-check"></i><b>4.1</b> Motivation</a></li>
<li class="chapter" data-level="4.2" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#unobserved-components"><i class="fa fa-check"></i><b>4.2</b> Unobserved Components</a></li>
<li class="chapter" data-level="4.3" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#seasonality-tests"><i class="fa fa-check"></i><b>4.3</b> Seasonality tests</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#overview"><i class="fa fa-check"></i><b>4.3.1</b> Overview</a></li>
<li class="chapter" data-level="4.3.2" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#f-test-on-seasonal-dummies"><i class="fa fa-check"></i><b>4.3.2</b> F-test on seasonal dummies</a></li>
<li class="chapter" data-level="4.3.3" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#qs-test-on-autocorrelation-at-seasonal-lags"><i class="fa fa-check"></i><b>4.3.3</b> QS Test on autocorrelation at seasonal lags</a></li>
<li class="chapter" data-level="4.3.4" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#qs-test-for-seasonality-bis-solve-this"><i class="fa fa-check"></i><b>4.3.4</b> QS Test for seasonality (BIS : solve this)</a></li>
<li class="chapter" data-level="4.3.5" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#kurskall-wallis"><i class="fa fa-check"></i><b>4.3.5</b> Kurskall-Wallis</a></li>
<li class="chapter" data-level="4.3.6" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#friedman-test-stable-seasonality-test"><i class="fa fa-check"></i><b>4.3.6</b> Friedman test (stable seasonality test)</a></li>
<li class="chapter" data-level="4.3.7" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#stable-seasonality-test-missing"><i class="fa fa-check"></i><b>4.3.7</b> Stable seasonality test (missing)</a></li>
<li class="chapter" data-level="4.3.8" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#moving-seasonality-test"><i class="fa fa-check"></i><b>4.3.8</b> Moving seasonality test</a></li>
<li class="chapter" data-level="4.3.9" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#identifiable-seasonality"><i class="fa fa-check"></i><b>4.3.9</b> Identifiable seasonality</a></li>
<li class="chapter" data-level="4.3.10" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#combined-seasonality-test"><i class="fa fa-check"></i><b>4.3.10</b> Combined seasonality test</a></li>
<li class="chapter" data-level="4.3.11" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#spectral-analysis"><i class="fa fa-check"></i><b>4.3.11</b> Spectral analysis</a></li>
<li class="chapter" data-level="4.3.12" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#example-of-non-seasonal-series"><i class="fa fa-check"></i><b>4.3.12</b> Example of non seasonal series</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#calendar-correction"><i class="fa fa-check"></i><b>4.4</b> Calendar correction</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#tests-for-residual-trading-days"><i class="fa fa-check"></i><b>4.4.1</b> Tests for residual trading days</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#outliers-and-intervention-variables"><i class="fa fa-check"></i><b>4.5</b> Outliers and intervention variables</a></li>
<li class="chapter" data-level="4.6" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#pre-adjustment"><i class="fa fa-check"></i><b>4.6</b> Pre-adjustment</a></li>
<li class="chapter" data-level="4.7" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#decomposition"><i class="fa fa-check"></i><b>4.7</b> Decomposition</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#x-11-moving-average-based-decomposition"><i class="fa fa-check"></i><b>4.7.1</b> X-11 moving average based decomposition</a></li>
<li class="chapter" data-level="4.7.2" data-path="seasonal-adjustment-1.html"><a href="seasonal-adjustment-1.html#model-based-decomposition"><i class="fa fa-check"></i><b>4.7.2</b> Model based decomposition</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="high-frequency-data-seasonal-adjustment.html"><a href="high-frequency-data-seasonal-adjustment.html"><i class="fa fa-check"></i><b>5</b> High Frequency data (seasonal adjustment)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="high-frequency-data-seasonal-adjustment.html"><a href="high-frequency-data-seasonal-adjustment.html#motivation-1"><i class="fa fa-check"></i><b>5.1</b> Motivation</a></li>
<li class="chapter" data-level="5.2" data-path="high-frequency-data-seasonal-adjustment.html"><a href="high-frequency-data-seasonal-adjustment.html#unobserved-components-1"><i class="fa fa-check"></i><b>5.2</b> Unobserved Components</a></li>
<li class="chapter" data-level="5.3" data-path="high-frequency-data-seasonal-adjustment.html"><a href="high-frequency-data-seasonal-adjustment.html#seasonality-tests-1"><i class="fa fa-check"></i><b>5.3</b> Seasonality tests</a></li>
<li class="chapter" data-level="5.4" data-path="high-frequency-data-seasonal-adjustment.html"><a href="high-frequency-data-seasonal-adjustment.html#calendar-correction-1"><i class="fa fa-check"></i><b>5.4</b> Calendar correction</a></li>
<li class="chapter" data-level="5.5" data-path="high-frequency-data-seasonal-adjustment.html"><a href="high-frequency-data-seasonal-adjustment.html#outliers-and-intervention-variables-1"><i class="fa fa-check"></i><b>5.5</b> Outliers and intervention variables</a></li>
<li class="chapter" data-level="5.6" data-path="high-frequency-data-seasonal-adjustment.html"><a href="high-frequency-data-seasonal-adjustment.html#pre-adjustment-1"><i class="fa fa-check"></i><b>5.6</b> Pre-adjustment</a></li>
<li class="chapter" data-level="5.7" data-path="high-frequency-data-seasonal-adjustment.html"><a href="high-frequency-data-seasonal-adjustment.html#decomposition-1"><i class="fa fa-check"></i><b>5.7</b> Decomposition</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="generating-calendar-regressors-and-other-input-variables.html"><a href="generating-calendar-regressors-and-other-input-variables.html"><i class="fa fa-check"></i><b>6</b> Generating Calendar regressors and other input variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="generating-calendar-regressors-and-other-input-variables.html"><a href="generating-calendar-regressors-and-other-input-variables.html#motivation-2"><i class="fa fa-check"></i><b>6.1</b> Motivation</a></li>
<li class="chapter" data-level="6.2" data-path="generating-calendar-regressors-and-other-input-variables.html"><a href="generating-calendar-regressors-and-other-input-variables.html#underlying-theory"><i class="fa fa-check"></i><b>6.2</b> Underlying theory</a></li>
<li class="chapter" data-level="6.3" data-path="generating-calendar-regressors-and-other-input-variables.html"><a href="generating-calendar-regressors-and-other-input-variables.html#available-tools"><i class="fa fa-check"></i><b>6.3</b> Available Tools</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="generating-calendar-regressors-and-other-input-variables.html"><a href="generating-calendar-regressors-and-other-input-variables.html#gui"><i class="fa fa-check"></i><b>6.3.1</b> GUI</a></li>
<li class="chapter" data-level="6.3.2" data-path="generating-calendar-regressors-and-other-input-variables.html"><a href="generating-calendar-regressors-and-other-input-variables.html#rjd3modelling-package"><i class="fa fa-check"></i><b>6.3.2</b> Rjd3modelling package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="outlier-detection.html"><a href="outlier-detection.html"><i class="fa fa-check"></i><b>7</b> Outlier detection</a>
<ul>
<li class="chapter" data-level="7.1" data-path="outlier-detection.html"><a href="outlier-detection.html#motivation-3"><i class="fa fa-check"></i><b>7.1</b> Motivation</a></li>
<li class="chapter" data-level="7.2" data-path="outlier-detection.html"><a href="outlier-detection.html#with-reg-arima-models"><i class="fa fa-check"></i><b>7.2</b> With Reg Arima models</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="outlier-detection.html"><a href="outlier-detection.html#part-of-preadjustment"><i class="fa fa-check"></i><b>7.2.1</b> Part of preadjustment</a></li>
<li class="chapter" data-level="7.2.2" data-path="outlier-detection.html"><a href="outlier-detection.html#specific-terror-tool"><i class="fa fa-check"></i><b>7.2.2</b> specific TERROR tool</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="outlier-detection.html"><a href="outlier-detection.html#with-structural-models"><i class="fa fa-check"></i><b>7.3</b> With structural models</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="modelling-time-series.html"><a href="modelling-time-series.html"><i class="fa fa-check"></i><b>8</b> Modelling Time Series</a>
<ul>
<li class="chapter" data-level="8.1" data-path="modelling-time-series.html"><a href="modelling-time-series.html#motivation-4"><i class="fa fa-check"></i><b>8.1</b> Motivation</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="benchmarking-and-temporal-disagreggation.html"><a href="benchmarking-and-temporal-disagreggation.html"><i class="fa fa-check"></i><b>9</b> Benchmarking and temporal disagreggation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="benchmarking-and-temporal-disagreggation.html"><a href="benchmarking-and-temporal-disagreggation.html#benchmarking-overview"><i class="fa fa-check"></i><b>9.1</b> Benchmarking overview</a></li>
<li class="chapter" data-level="9.2" data-path="benchmarking-and-temporal-disagreggation.html"><a href="benchmarking-and-temporal-disagreggation.html#underlying-theory-1"><i class="fa fa-check"></i><b>9.2</b> Underlying Theory</a></li>
<li class="chapter" data-level="9.3" data-path="benchmarking-and-temporal-disagreggation.html"><a href="benchmarking-and-temporal-disagreggation.html#tools"><i class="fa fa-check"></i><b>9.3</b> Tools</a></li>
<li class="chapter" data-level="9.4" data-path="benchmarking-and-temporal-disagreggation.html"><a href="benchmarking-and-temporal-disagreggation.html#references-4"><i class="fa fa-check"></i><b>9.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="trend-cycle-estimation-1.html"><a href="trend-cycle-estimation-1.html"><i class="fa fa-check"></i><b>10</b> Trend-cycle estimation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="trend-cycle-estimation-1.html"><a href="trend-cycle-estimation-1.html#motivation-5"><i class="fa fa-check"></i><b>10.1</b> Motivation</a></li>
<li class="chapter" data-level="10.2" data-path="trend-cycle-estimation-1.html"><a href="trend-cycle-estimation-1.html#underlying-theory-2"><i class="fa fa-check"></i><b>10.2</b> Underlying Theory</a></li>
<li class="chapter" data-level="10.3" data-path="trend-cycle-estimation-1.html"><a href="trend-cycle-estimation-1.html#tools-1"><i class="fa fa-check"></i><b>10.3</b> Tools</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="nowcasting.html"><a href="nowcasting.html"><i class="fa fa-check"></i><b>11</b> Nowcasting</a></li>
<li class="chapter" data-level="12" data-path="graphical-user-interface.html"><a href="graphical-user-interface.html"><i class="fa fa-check"></i><b>12</b> Graphical User Interface</a>
<ul>
<li class="chapter" data-level="12.1" data-path="graphical-user-interface.html"><a href="graphical-user-interface.html#structure-and-assets"><i class="fa fa-check"></i><b>12.1</b> Structure and assets</a></li>
<li class="chapter" data-level="12.2" data-path="graphical-user-interface.html"><a href="graphical-user-interface.html#main-functions"><i class="fa fa-check"></i><b>12.2</b> Main functions</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="graphical-user-interface.html"><a href="graphical-user-interface.html#seasonality-tests-2"><i class="fa fa-check"></i><b>12.2.1</b> Seasonality tests</a></li>
<li class="chapter" data-level="12.2.2" data-path="graphical-user-interface.html"><a href="graphical-user-interface.html#seasonal-adjustment-2"><i class="fa fa-check"></i><b>12.2.2</b> Seasonal adjustment</a></li>
<li class="chapter" data-level="12.2.3" data-path="graphical-user-interface.html"><a href="graphical-user-interface.html#benchmarking"><i class="fa fa-check"></i><b>12.2.3</b> Benchmarking</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="r-packages.html"><a href="r-packages.html"><i class="fa fa-check"></i><b>13</b> R packages</a>
<ul>
<li class="chapter" data-level="13.1" data-path="r-packages.html"><a href="r-packages.html#available-functions"><i class="fa fa-check"></i><b>13.1</b> Available functions</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="r-packages.html"><a href="r-packages.html#seasonal-adjustment-3"><i class="fa fa-check"></i><b>13.1.1</b> Seasonal Adjustment</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="r-packages.html"><a href="r-packages.html#interaction-with-gui"><i class="fa fa-check"></i><b>13.2</b> Interaction with GUI</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="plug-ins-for-jdemetra.html"><a href="plug-ins-for-jdemetra.html"><i class="fa fa-check"></i><b>14</b> Plug-ins for JDemetra+</a>
<ul>
<li class="chapter" data-level="14.1" data-path="plug-ins-for-jdemetra.html"><a href="plug-ins-for-jdemetra.html#main-functions-1"><i class="fa fa-check"></i><b>14.1</b> Main functions</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="production.html"><a href="production.html"><i class="fa fa-check"></i><b>15</b> Production</a></li>
<li class="chapter" data-level="16" data-path="tool-selection-issues.html"><a href="tool-selection-issues.html"><i class="fa fa-check"></i><b>16</b> Tool selection issues</a></li>
<li class="chapter" data-level="17" data-path="spectral-analysis-principles-and-tools.html"><a href="spectral-analysis-principles-and-tools.html"><i class="fa fa-check"></i><b>17</b> Spectral Analysis Principles and Tools</a>
<ul>
<li class="chapter" data-level="17.1" data-path="spectral-analysis-principles-and-tools.html"><a href="spectral-analysis-principles-and-tools.html#overview-1"><i class="fa fa-check"></i><b>17.1</b> Overview</a></li>
<li class="chapter" data-level="17.2" data-path="spectral-analysis-principles-and-tools.html"><a href="spectral-analysis-principles-and-tools.html#periodogram"><i class="fa fa-check"></i><b>17.2</b> Periodogram</a></li>
<li class="chapter" data-level="17.3" data-path="spectral-analysis-principles-and-tools.html"><a href="spectral-analysis-principles-and-tools.html#ar-spectrum-definition"><i class="fa fa-check"></i><b>17.3</b> AR Spectrum definition</a></li>
<li class="chapter" data-level="17.4" data-path="spectral-analysis-principles-and-tools.html"><a href="spectral-analysis-principles-and-tools.html#tukey-spectrum-definition"><i class="fa fa-check"></i><b>17.4</b> Tukey Spectrum definition</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="reg-arima-models.html"><a href="reg-arima-models.html"><i class="fa fa-check"></i><b>18</b> Reg-Arima models</a>
<ul>
<li class="chapter" data-level="18.1" data-path="reg-arima-models.html"><a href="reg-arima-models.html#overview-2"><i class="fa fa-check"></i><b>18.1</b> Overview</a></li>
<li class="chapter" data-level="18.2" data-path="reg-arima-models.html"><a href="reg-arima-models.html#autocorrelation-function"><i class="fa fa-check"></i><b>18.2</b> Autocorrelation function</a></li>
<li class="chapter" data-level="18.3" data-path="reg-arima-models.html"><a href="reg-arima-models.html#estimation-of-arma-models"><i class="fa fa-check"></i><b>18.3</b> Estimation Of Arma models</a></li>
<li class="chapter" data-level="18.4" data-path="reg-arima-models.html"><a href="reg-arima-models.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>18.4</b> Maximum likelihood estimation</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="reg-arima-models.html"><a href="reg-arima-models.html#likelihood-of-a-multivariate-normal-distribution"><i class="fa fa-check"></i><b>18.4.1</b> Likelihood of a multivariate normal distribution</a></li>
<li class="chapter" data-level="18.4.2" data-path="reg-arima-models.html"><a href="reg-arima-models.html#linear-model-with-gaussian-noises"><i class="fa fa-check"></i><b>18.4.2</b> Linear model with gaussian noises</a></li>
<li class="chapter" data-level="18.4.3" data-path="reg-arima-models.html"><a href="reg-arima-models.html#implementation-3"><i class="fa fa-check"></i><b>18.4.3</b> Implementation</a></li>
<li class="chapter" data-level="18.4.4" data-path="reg-arima-models.html"><a href="reg-arima-models.html#missing-values"><i class="fa fa-check"></i><b>18.4.4</b> Missing values</a></li>
<li class="chapter" data-level="18.4.5" data-path="reg-arima-models.html"><a href="reg-arima-models.html#perfect-collinearity-in-x"><i class="fa fa-check"></i><b>18.4.5</b> Perfect collinearity in X</a></li>
<li class="chapter" data-level="18.4.6" data-path="reg-arima-models.html"><a href="reg-arima-models.html#references-6"><i class="fa fa-check"></i><b>18.4.6</b> References</a></li>
<li class="chapter" data-level="18.4.7" data-path="reg-arima-models.html"><a href="reg-arima-models.html#x-13-implementation"><i class="fa fa-check"></i><b>18.4.7</b> X-13 implementation</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="reg-arima-models.html"><a href="reg-arima-models.html#handling-of-missing-observations-in-regarima-models"><i class="fa fa-check"></i><b>18.5</b> Handling of missing observations in (Reg)ARIMA models</a>
<ul>
<li class="chapter" data-level="18.5.1" data-path="reg-arima-models.html"><a href="reg-arima-models.html#skipping-approach"><i class="fa fa-check"></i><b>18.5.1</b> Skipping approach</a></li>
<li class="chapter" data-level="18.5.2" data-path="reg-arima-models.html"><a href="reg-arima-models.html#additive-outlier-approach"><i class="fa fa-check"></i><b>18.5.2</b> Additive outlier approach</a></li>
<li class="chapter" data-level="18.5.3" data-path="reg-arima-models.html"><a href="reg-arima-models.html#references-8"><i class="fa fa-check"></i><b>18.5.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="reg-arima-models.html"><a href="reg-arima-models.html#tests-on-residuals"><i class="fa fa-check"></i><b>18.6</b> Tests on residuals</a>
<ul>
<li class="chapter" data-level="18.6.1" data-path="reg-arima-models.html"><a href="reg-arima-models.html#autocorrelation"><i class="fa fa-check"></i><b>18.6.1</b> Autocorrelation</a></li>
<li class="chapter" data-level="18.6.2" data-path="reg-arima-models.html"><a href="reg-arima-models.html#normality"><i class="fa fa-check"></i><b>18.6.2</b> Normality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="moving-average-based-decomposition.html"><a href="moving-average-based-decomposition.html"><i class="fa fa-check"></i><b>19</b> Moving average based decomposition</a></li>
<li class="chapter" data-level="20" data-path="arima-model-based-decomposition.html"><a href="arima-model-based-decomposition.html"><i class="fa fa-check"></i><b>20</b> Arima Model based decomposition</a></li>
<li class="chapter" data-level="21" data-path="state-space-framework.html"><a href="state-space-framework.html"><i class="fa fa-check"></i><b>21</b> State Space Framework</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">JDemetra+ online documentation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="seasonal-adjustment-1" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> Seasonal Adjustment<a href="seasonal-adjustment-1.html#seasonal-adjustment-1" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="motivation" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Motivation<a href="seasonal-adjustment-1.html#motivation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The primary aim of the seasonal adjustment process is to remove seasonal fluctuations from the time series.
To achieve this goal, seasonal adjustment methods decompose the original time series into components that
capture specific movements. These components are: trend-cycle, seasonality and irregularity.
The trend-cycle component includes long-term and medium-term movements in the data.
For seasonal adjustment purposes there is no need to divide this component into two parts.
JDemetra+ refers to the trend-cycle as trend and consequently this convention is used here.</p>
<p>This section presents the options of the seasonal adjustment processes performed
by the methods implemented in JDemetra+ (X-12-ARIMA/X-13ARIMA-SEATS and TRAMO/SEATS)
and discusses the output displayed by JDemetra+. As these seasonal adjustment methods
use different approach to the decomposition, the output produced for both of them has
different structure and content. Therefore, the results for both methods are discussed separately.
However, in contrast to the original programs, in JDemetra+ some quality indicators have been implemented
for both methods, allowing for an easier compaison of the results.</p>
</div>
<div id="unobserved-components" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Unobserved Components<a href="seasonal-adjustment-1.html#unobserved-components" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The main components, each representing the impact
of certain types of phenomena on the time series (<span class="math inline">\(X_{t}\)</span>), are:</p>
<ul>
<li><p>The trend (<span class="math inline">\(T_{t}\)</span>) that captures long-term and medium-term behaviour;</p></li>
<li><p>The seasonal component (<span class="math inline">\(S_{t}\)</span>) representing intra-year fluctuations, monthly or quarterly, that are repeated more or less regularly year after year;</p></li>
<li><p>The irregular component (<span class="math inline">\(I_{t}\)</span>) combining all the other more or less erratic fluctuations not covered by the previous components.</p></li>
</ul>
<p>In general, the trend consists of 2 sub-components:</p>
<ul>
<li><p>The long-term evolution of the series;</p></li>
<li><p>The cycle, that represents the smooth, almost periodic movement around the long-term evolution of the series. It reveals a succession of phases of growth and recession.</p></li>
</ul>
<p>For seasonal adjustment purposes both TRAMO-SEATS and X-13ARIMA-SEATS do
not separate the long-term trend from the cycle as these two components
are usually too short to perform their reliable estimation.
Consequently, hereafter TRAMO-SEATS and X-13ARIMA-SEATS estimate the
trend component. However, the original TRAMO-SEATS may separate the
long-term trend from the cycle through the Hodrick-Precsott filter using
the output of the standard decomposition. It should be remembered that
JDemetra+ refers to the trend-cycle as trend (<span class="math inline">\(T_{t}\)</span>), and consequently
this convention is used in this document.</p>
<p>TRAMO-SEATS considers two decomposition models:</p>
<ul>
<li><p>The additive model: <span class="math inline">\(X_{t} = T_{t} + S_{t} + I_{t}\)</span>;</p></li>
<li><p>The log additive model:
<span class="math inline">\(log(X_{t}) = log(T_{t}) + log(S_{t}) + log(I_{t})\)</span>.</p></li>
</ul>
<p>Apart from these two decomposition types X-13ARIMA-SEATS allows the user
to apply also the multiplicative
model: <span class="math inline">\(X_{t} = T_{t} \times S_{t} \times I_{t}\)</span>.</p>
<p>A time series <span class="math inline">\(x_{t}\)</span>, which is a subject to a decomposition, is assumed
to be a realisation of a discrete-time stochastic, covariance-stationary
linear process, which is a collection of random variables
<span class="math inline">\(x_{t}\)</span>, where <span class="math inline">\(t\)</span> denotes time. It can be shown that
any stochastic, covariance-stationary process can be presented in the
form:</p>
<p><span class="math inline">\(x_{t} = \mu_{t} + {\widetilde{x}}_{t}\)</span>, <span class="math display">\[1\]</span></p>
<p>where <span class="math inline">\(\mu_{t}\)</span> is a linearly deterministic component and
<span class="math inline">\({\widetilde{x}}_{t}\)</span> is a linearly interderministic component, such as:</p>
<p><span class="math display">\[
  {\widetilde{x}}_{t} = {\sum_{j = 0}^{\infty}\psi_{j}a}_{t - j}
  \]</span>, <span class="math display">\[2\]</span></p>
<p>where <span class="math inline">\(\sum_{j = 0}^{\infty}\psi_{i}^{2} &lt; \infty\)</span> (coefficients
<span class="math inline">\(\psi_{j}\)</span> are absolutely summable), <span class="math inline">\(\psi_{0} = 1\)</span> and <span class="math inline">\(a_{t}\)</span> is the
white noise error with zero mean and constant variance <span class="math inline">\(V_{a}\)</span>. The
error term <span class="math inline">\(a_{t}\)</span> represents the one-period ahead forecast error of
<span class="math inline">\(x_{t}\)</span>, that is:</p>
<p><span class="math display">\[
  a_{t} = {\widetilde{x}}_{t} - {\widehat{x}}_{t|t - 1}
  \]</span>, <span class="math display">\[3\]</span></p>
<p>where <span class="math display">\[{\widehat{x}}_{t|t - 1}\]</span> is the forecast of <span class="math display">\[{\widetilde{x}}_{t}\]</span>
made at period <span class="math inline">\(t - 1\)</span>. As <span class="math inline">\(a_{t}\)</span> represents what is new in <span class="math display">\[{\widetilde{x}}_{t}\]</span> in point <span class="math inline">\(t\)</span>, i.e., not contained in the past values of <span class="math display">\[{\widetilde{x}}_{t}\]</span>, it is also called innovation of the process. From <span class="math display">\[3\]</span> <span class="math display">\[{\widetilde{x}}_{t}\]</span> can be viewed as a linear filter applied to the innovations.</p>
<p>The equation 7.1 is called a Wold representation. It presents a process
as a sum of linearly deterministic component <span class="math inline">\(\mu_{t}\)</span> and linearly
interderministic component <span class="math inline">\(\sum_{j = 0}^{\infty}\psi_{j}a_{t - j}\)</span>, the
first one is perfectly predictable once the history of the process
<span class="math inline">\(x_{t - 1}\)</span> is known and the second one is impossible to predict
perfectly. This explains why the stochastic process cannot be perfectly
predicted.</p>
<p>Under suitable conditions <span class="math display">\[{\widetilde{x}}_{t}\]</span> can be presented as a weighted sum of its past values and <span class="math inline">\(a_{t}\)</span>, i.e.:</p>
<p><span class="math display">\[
  { {\widetilde{x}}_{t} = \sum_{j = 0}^{\infty}\pi_{j}{\widetilde{x}}_{t - j} + a}_{t}
  \]</span>, <span class="math display">\[4\]</span></p>
<p>In general, for the observed time series, the assumptions concerning the
nature of the process <span class="math display">\[1\]</span> do not hold for various reasons. Firstly,
most observed time series display a mean that cannot be assumed to be
constant due to the presence of a trend and the seasonal movements.
Secondly, the variance of the time series may vary in time. Finally, the
observed time series usually contain outliers, calendar effects and
regression effects, which are treated as deterministic. Therefore, in
practice a prior transformation and an adjustment need to be applied to
the time series. The constant variance is usually achieved through
taking a logarithmic transformation and the correction for the
deterministic effects, while stationarity of the mean is achieved by
applying regular and seasonal differencing. These processes, jointly
referred to as preadjustment or linearization, can be performed with the
TRAMO or RegARIMA models. Besides the linearisation, forecasts and
backcasts of stochastic time series are estimated with the ARIMA model,
allowing for later application of linear filters at both ends of time
series. The estimation performed with these models delivers the
stochastic part of the time series, called the linearised series, which
is assumed to be an output of a linear stochastic process.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> The
deterministic effects are removed from the time series and used to form
the final components.</p>
<p>In the next step the linearised series is decomposed into its
components. There is a fundamental difference in how this process is
performed in TRAMO-SEATS and X-13ARIMA-SEATS. In TRAMO-SEATS the
decomposition is performed by the SEATS procedure, which follows a so
called ARIMA model based approach. In principle, it aims to derive the
components with statistical models. More information is given in the <a href="../theory/SA_SEATS.html">SEATS</a> section.
X-13ARIMA-SEATS offers two algorithms for decomposition: SEATS and X-11.
The X-11 algorithm, which is described in the <a href="../theory/SA_X11.html">X-11 section</a> section, decomposes a series by
means of linear filters. Finally, in both methods the final components
are derived by the assignment of the deterministic effects to the
stochastic components. Consequently, the role of the ARIMA models is
different in each method. TRAMO-SEATS applies the ARIMA models both in
the preadjustment step and in the decomposition procedure. On the
contrary, when the X-11 algorithm is used for decomposition,
X-13ARIMA-SEATS uses the ARIMA model only in the preadjustment step. In
summary, the decomposition procedure that results in an estimation of
the seasonal component requires prior identification of the
deterministic effects and their removal from the time series. This is
achieved through the linearisation process performed by the TRAMO and
the RegARIMA models, shortly discussed in the <a href="../theory/SA_lin.html">Linearisation with the TRAMO and RegARIMA models</a> section.The linearised series is
then decomposed into the stochastic components with <a href="../theory/SA_SEATS.html">SEATS</a> or
<a href="../theory/SA_X11.html">X-11</a> algorithms.</p>
</div>
<div id="seasonality-tests" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Seasonality tests<a href="seasonal-adjustment-1.html#seasonality-tests" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="overview" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Overview<a href="seasonal-adjustment-1.html#overview" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="f-test-on-seasonal-dummies" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> F-test on seasonal dummies<a href="seasonal-adjustment-1.html#f-test-on-seasonal-dummies" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The F-test on seasonal dummies checks for the presence of deterministic
seasonality. The model used here uses seasonal dummies (mean effect and
11 seasonal dummies for monthly data, mean effect and 3 for quarterly
data) to describe the (possibly transformed) time series behaviour. The
test statistic checks if the seasonal dummies are jointly statistically
not significant. When this hypothesis is rejected, it is assumed that
the deterministic seasonality is present and the test results are
displayed in green.</p>
<p>This test refers to Model-Based <span class="math inline">\(\chi^{2}\ \)</span>and F-tests for Fixed
Seasonal Effects proposed by LYTRAS, D.P., FELDPAUSCH, R.M., and BELL,
W.R. (2007) that is based on the estimates of the regression dummy
variables and the corresponding t-statistics of the RegARIMA model, in
which the ARIMA part of the model has a form (0,1,1)(0,0,0). The
consequences of a misspecification of a model are discussed in LYTRAS,
D.P., FELDPAUSCH, R.M., and BELL, W.R. (2007).</p>
<p>For a monthly time series the RegARIMA model structure is as follows:</p>
<p><span class="math display">\[\left( 1 - B \right)\left( y_{t} - \beta_{1}M_{1,t} - \ldots - \beta_{11}M_{11,t} - \gamma X_{t} \right) = \mu + (1 - B)a_{t}
\]</span></p>
<p>where:</p>
<p><span class="math display">\[
M_{j,t} =
\begin{cases}
1 &amp; \text{ in month } j = 1, \ldots, 11 \\
- 1 &amp; \text{ in December}\\
0 &amp; \text{ otherwise}
\end{cases} \text{ - dummy variables;}
\]</span></p>
<p><span class="math inline">\(y_{t}\)</span> – the original time series;</p>
<p><span class="math inline">\(B\)</span> – a backshift operator;</p>
<p><span class="math inline">\(X_{t}\)</span> – other regression variables used in the model (e.g. outliers,
calendar effects, user-defined regression variables, intervention
variables);</p>
<p><span class="math inline">\(\mu\)</span> – a mean effect;</p>
<p><span class="math inline">\(a_{t}\)</span> – a white-noise variable with mean zero and a constant
variance.</p>
<p>In the case of a quarterly series the estimated model has a form:</p>
<p><span class="math display">\[\left( 1 - B \right)\left( y_{t} - \beta_{1}M_{1,t} - \ldots - \beta_{3}M_{3,t} - \gamma X_{t} \right) = \mu + (1 - B)a_{t}\]</span>, <span class="math display">\[2\]</span> <!--- \[7.156\]     --></p>
<p>where:</p>
<p><span class="math display">\[
M_{j,t} =
\begin{cases}
1 &amp; \text{ in quarter} j = 1, \ldots, 3 \\
- 1 &amp; \text{ in the fourth quarter}\\
0 &amp; \text{ otherwise}
\end{cases} \text{ - dummy variables;}
\]</span></p>
<p>One can use the individual t-statistics to assess whether seasonality
for a given month is significant, or a chi-squared test statistic if the
null hypothesis is that the parameters are collectively all zero. The
chi-squared test statistic is
<span class="math inline">\({\widehat{\chi}}^{2} = {\widehat{\beta}}^{&#39;}{\lbrack Var(\widehat{\beta})}^{\ })^{- 1}\rbrack{\widehat{\beta}}^{\ }\)</span>
in this case compared to critical values from a
<span class="math inline">\(\chi^{2}\left( \text{df} \right)\)</span>-distribution, with degrees of freedom
<span class="math inline">\(df = 11\ \)</span>(monthly series) or <span class="math inline">\(df = 3\)</span> (quarterly series). Since the
<span class="math inline">\({Var(\widehat{\beta})}^{\ }\)</span> computed using the estimated variance of
<span class="math inline">\(\alpha_{t}\)</span> may be very different from the actual variance in small
samples, this test is corrected using the proposed
<span class="math inline">\(\text{F}\)</span> statistic:</p>
<p><span class="math display">\[
  F = \frac{ {\widehat{\chi}}^{2}}{s - 1} \times \frac{n - d - k}{n - d}
  \]</span><em>,</em> <span class="math display">\[3\]</span> <!--- \[7.157\]     --></p>
<p>where <span class="math inline">\(n\)</span> is the sample size, <span class="math inline">\(d\)</span> is the degree of differencing, s is
time series frequency (12 for a monthly series, 4 for a quarterly
series) and <span class="math inline">\(k\)</span> is the total number of regressors in the RegARIMA model
(including the seasonal dummies <span class="math inline">\(\text{M}_{j,t}\)</span> and the intercept).</p>
<p>This statistic follows a <span class="math display">\[F_{s - 1,n - d - k}\]</span> distribution under the
null hypothesis.</p>
</div>
<div id="qs-test-on-autocorrelation-at-seasonal-lags" class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> QS Test on autocorrelation at seasonal lags<a href="seasonal-adjustment-1.html#qs-test-on-autocorrelation-at-seasonal-lags" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The QS test is a variant of the <a href="../theory/Tests_LB.html">Ljung-Box</a> test computed on seasonal lags, where we only consider positive auto-correlations</p>
<p>More exactly,</p>
<p><span class="math display">\[ QS=n \left(n+2\right)\sum_{i=1}^k\frac{\left[ \max  \left(0, \hat\gamma_{i \cdot l}\right)\right]^2}{n-i \cdot l}\]</span></p>
<p>where <span class="math display">\[k=2\]</span>, so only the first and second seasonal lags are considered. Thus, the test would checks the correlation between the
actual observation and the observations lagged by one and two years. Note that <span class="math display">\[l=12\]</span> when dealing with monthly observations,
so we consider the autocovariances <span class="math display">\[\hat\gamma_{12}\]</span> and <span class="math display">\[\hat\gamma_{24}\]</span> alone. In turn, <span class="math display">\[k=4\]</span> in the case of quarterly data.</p>
<p>Under H0, which states that the data are independently distributed, the statistics follows a <span class="math display">\[\chi \left(k\right)\]</span> distribution. However,
the elimination of negative correlations makes it a bad approximation. The p-values would be given
by <span class="math inline">\(P(\chi^{2}\left( k \right) &gt; Q)\)</span> for <span class="math inline">\(k = 2\)</span>. As <span class="math inline">\({P(\chi}^{2}(2)) &gt; 0.05 = 5.99146\)</span> and
<span class="math inline">\({P(\chi}^{2}(2)) &gt; 0.01 = 9.21034\)</span>, <span class="math inline">\(QS &gt; 5.99146\)</span> and <span class="math inline">\(QS &gt; 9.21034\)</span>
would suggest rejecting the null hypothesis at <span class="math inline">\(95\%\)</span> and <span class="math inline">\(99\%\)</span>
significance levels, respecively.</p>
<div id="modification" class="section level5 hasAnchor" number="4.3.3.0.1">
<h5><span class="header-section-number">4.3.3.0.1</span> Modification<a href="seasonal-adjustment-1.html#modification" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Maravall (2012) proposes approximate the correct distribution (p-values) of the QS statistic using simulation techniques. Using 1000K replications of sample size 240,
the correct critical values would be 3.83 and 7.09 with confidence levels of <span class="math inline">\(95\%\)</span> and <span class="math inline">\(99\%\)</span>, respectively (lower than the 5.99146 and 9.21034 shown above). For
each of the simulated series,
he obtains the distribution by assuming <span class="math inline">\(QS=0\)</span> when <span class="math display">\[\hat\gamma_{12}\]</span>, so in practice this test will detect seasonality only when
any of these conditions hold:
- Statistically significant positive autocorrelation at lag 12
- Nonnegative sample autocorrelation at lag 12 and statistically significant positive autocorrelation at lag 24</p>
</div>
<div id="implementation" class="section level4 hasAnchor" number="4.3.3.1">
<h4><span class="header-section-number">4.3.3.1</span> Implementation<a href="seasonal-adjustment-1.html#implementation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div id="in-the-graphical-user-interface-gui" class="section level5 hasAnchor" number="4.3.3.1.1">
<h5><span class="header-section-number">4.3.3.1.1</span> In the graphical user interface (GUI)<a href="seasonal-adjustment-1.html#in-the-graphical-user-interface-gui" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The test can be applied directly to any series by selecting the
option <em>Statistical Methods &gt;&gt; Seasonal Adjustment &gt;&gt; Tools &gt;&gt; Seasonality Tests</em>. This is
an example of how results are displayed for the case of a monthly series:</p>
<div class="figure">
<img src="All_images/qs.png" alt="" />
<p class="caption">qs</p>
</div>
<p>The test can be applied to the input series before any seasonal adjustment method has been applied. It can also be applied to the seasonally
adjusted series or to the irreguar component.</p>
</div>
<div id="via-r-package-rjd3toolkit-blank" class="section level5 hasAnchor" number="4.3.3.1.2">
<h5><span class="header-section-number">4.3.3.1.2</span> Via R package: RJD3toolkit (blank)<a href="seasonal-adjustment-1.html#via-r-package-rjd3toolkit-blank" class="anchor-section" aria-label="Anchor link to header"></a></h5>
</div>
<div id="java-library" class="section level5 hasAnchor" number="4.3.3.1.3">
<h5><span class="header-section-number">4.3.3.1.3</span> Java Library<a href="seasonal-adjustment-1.html#java-library" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>This test is implemented in the class <code>ec.satoolkit.diagnostics.QsTest</code></p>
</div>
<div id="references" class="section level5 hasAnchor" number="4.3.3.1.4">
<h5><span class="header-section-number">4.3.3.1.4</span> References<a href="seasonal-adjustment-1.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>LJUNG G. M. and G. E. P. BOX (1978). “On a Measure of a Lack of Fit in Time Series Models”. Biometrika 65 (2): 297–303. <a href="doi:10.1093/biomet/65.2.297" class="uri">doi:10.1093/biomet/65.2.297</a></li>
<li>MARAVALL, A. (2011). ”Seasonality Tests and Automatic Model Identification in Tramo-Seats”. Manuscript</li>
<li>MARAVALL, A. (2012). “Update of Seasonality Tests and Automatic Model Identification in TRAMO-SEATS”. Bank of Spain (November 2012)</li>
</ul>
</div>
</div>
</div>
<div id="qs-test-for-seasonality-bis-solve-this" class="section level3 hasAnchor" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> QS Test for seasonality (BIS : solve this)<a href="seasonal-adjustment-1.html#qs-test-for-seasonality-bis-solve-this" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<!-- The QS test is a variant of the [Ljung-Box](../wn/ljungbox.md) test computed on seasonal lags, where we only consider positive auto-correlations -->
<p>More exactly,</p>
<p><span class="math display">\[ qs=n \left(n+2\right)\sum_{i=1}^k\frac{\left[ \max  \left(0, \hat\gamma_{i \cdot l}\right)\right]^2}{n-i \cdot l}\]</span></p>
<p>The current implementation still considers that the statistics is distributed as a
<span class="math display">\[\chi \left(k\right)\]</span>
even if it is obvioulsly incorrect.</p>
</div>
<div id="kurskall-wallis" class="section level3 hasAnchor" number="4.3.5">
<h3><span class="header-section-number">4.3.5</span> Kurskall-Wallis<a href="seasonal-adjustment-1.html#kurskall-wallis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Kruskal-Wallis test is a non-parametric test used for testing whether samples originate from the same distribution.
The parametric equivalent of the Kruskal-Wallis test is the one-way analysis of variance (ANOVA).
When rejecting the null hypothesis of the Kruskal-Wallis test, then at least one sample stochastically dominates at least one other sample.
The test does not identify where this stochastic dominance occurs or for how many pairs of groups stochastic dominance obtains.
The null hypothesis states that all months (or quarters, respectively) have the same mean.
Under this hypothesis the test statistic follows a <span class="math display">\[ \chi^2 \]</span> distribution.
When this hypothesis is rejected, it is assumed that time series values differ significantly between periods and the test results are displayed in green</p>
<p>The test is typically applied to <span class="math display">\[ k  \]</span> groups of data <span class="math display">\[ \left\{x_{i}\right\}_{j} \]</span>. Each group <span class="math display">\[ j=1,…,k \]</span> is composed of <span class="math display">\[ n_j \]</span> observations,
which are indexed by <span class="math display">\[ i=1,…,n_j \]</span>. Each month (or quarter) groups all the observations available for a certain number of years.</p>
<p>As opposed to the notation used in the <a href="../theory/Tests_Friedman.html">Friedman test</a>, number of observations here is not necessarily equal for each group.
The ranking of each data point, represented by variable <span class="math display">\[ r_{ij} \]</span>., is now defined different than in Friedman test,
since it considers all observables <span class="math display">\[ N=n_1+ \dots + n_g \]</span>, thereby ignoring group membership.</p>
<p>The test statistic is given by</p>
<p><span class="math display">\[
Q=\frac{SS_t}{SS_e}
\]</span></p>
<p>where <span class="math display">\[ SS_t=(N-1)\sum_{j=1}^{g}n_i(\bar{r}_{.j}-\bar{r})^2 \]</span> and <span class="math display">\[ SS_e=\sum_{j=1}^{g}\sum_{i=1}^{n_j}(r_{ij}-\bar{r})^2 \]</span>
- <span class="math display">\[ n_j \]</span> is the number of observations in group <span class="math display">\[ j  \]</span>
- <span class="math display">\[ \bar{r}_{.j} \]</span> is the average of the absolute ranks of the data in group <span class="math display">\[ j  \]</span>
- The average rank is <span class="math display">\[ \bar{r} =\frac{1}{2}(N+1) \]</span></p>
<p>Under the null hypothesis that all groups are generated from the same distribution, the test statistic Q is approximated by a chi-squared distribution.
Thus, the p-value is given by <span class="math display">\[ P( \chi^2_{g-1}&gt;Q) \]</span>. This approximation can be misleading if some of the groups are very small (i.e. less than five elements). If the statistic is not significant, then there is no evidence of stochastic dominance between the samples.
However, if the test is significant then at least one sample <a href="http://en.wikipedia.org/wiki/Stochastic_dominance">stochastically
dominates</a> another sample.</p>
<div id="use" class="section level4 hasAnchor" number="4.3.5.1">
<h4><span class="header-section-number">4.3.5.1</span> Use<a href="seasonal-adjustment-1.html#use" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The test can be applied directly to any series by selecting the
option <em>Statistical Methods &gt;&gt; Seasonal Adjustment &gt;&gt; Tools &gt;&gt; Seasonality Tests</em>. This is
an example of how results are displayed for the case of a monthly series:</p>
<div class="figure">
<img src="All_images/kw.png" alt="" />
<p class="caption">kwResults</p>
</div>
<p>The test can be applied to the input series before any seasonal adjustment method has been applied. It can also be applied to the seasonally adjusted series or to the irreguar component.</p>
</div>
<div id="implementation-1" class="section level4 hasAnchor" number="4.3.5.2">
<h4><span class="header-section-number">4.3.5.2</span> Implementation<a href="seasonal-adjustment-1.html#implementation-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>This test is implemented in the class <code>ec.satoolkit.diagnostics.KruskallWallisTest</code></p>
</div>
<div id="references-1" class="section level4 hasAnchor" number="4.3.5.3">
<h4><span class="header-section-number">4.3.5.3</span> References<a href="seasonal-adjustment-1.html#references-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Kruskal; Wallis (1952). “Use of ranks in one-criterion variance analysis”. Journal of the American Statistical Association 47 (260): 583–621. <a href="doi:10.1080/01621459.1952.10483441" class="uri">doi:10.1080/01621459.1952.10483441</a>.</li>
</ul>
</div>
</div>
<div id="friedman-test-stable-seasonality-test" class="section level3 hasAnchor" number="4.3.6">
<h3><span class="header-section-number">4.3.6</span> Friedman test (stable seasonality test)<a href="seasonal-adjustment-1.html#friedman-test-stable-seasonality-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Friedman test is a non-parametric method for testing that samples are drawn from the same population or from populations with equal medians.
The significance of the month (or quarter) effect is tested. The Friedman test requires no distributional assumptions. It uses the rankings of the observations.
If the null hypothesis of no stable seasonality is rejected at the 0.10% significance level then the series is considered to be seasonal
and the test’s outcome is displayed in green.</p>
<p>The test statistic is constructed as follows. Consider first the matrix of data <span class="math display">\[ \left\{x_{ij}\right\}_{n \times k} \]</span> with <span class="math display">\[ n \]</span> rows (the blocks,
i.e. number of years in the sample), <span class="math display">\[ k \]</span> columns (the treatments, i.e. either 12 months or 4 quarters, depending on the frequency of the data).<br />
The data matrix needs to be replaced by a new matrix <span class="math display">\[ \left\{r_{ij}\right\}_{n \times k} \]</span>, where the entry <span class="math display">\[ r_{ij} \]</span> is the rank of <span class="math display">\[ x_{ij} \]</span>
within block <span class="math display">\[ i \]</span> .</p>
<p>The test statistic is given by</p>
<p><span class="math display">\[
Q=\frac{SS_t}{SS_e}
\]</span></p>
<p>where <span class="math display">\[ SS_t=n \sum_{j=1}^{k}(\bar{r}_{.j}-\bar{r})^2 \]</span> and <span class="math display">\[ SS_e=\frac{1}{n(k-1)} \sum_{i=1}^{n}\sum_{j=1}^{k}(r_{ij}-\bar{r})^2 \]</span>
It represents the variance of the average ranking across treatments j relative to the total.</p>
<p>Under the hypothesis of no seasonality, all months can be equally treated. For the sake of completeness:
- <span class="math display">\[ \bar{r}_{.j} \]</span> is the average ranks of each treatment (month) j within each block (year)
- The average rank is given by <span class="math display">\[ \bar{r}= \frac{1}{nk}\sum_{i=1}^{n}\sum_{j=1}^{k}(r_{ij})\]</span></p>
<p>For large <span class="math display">\[ n \]</span> or <span class="math display">\[ k \]</span> , i.e. n &gt; 15 or k &gt; 4, the probability distribution of <span class="math display">\[ Q \]</span> can be approximated by that of
a chi-squared distribution. Thus, the p-value is given by <span class="math display">\[ P( \chi^2_{k-1}&gt;Q) \]</span> .</p>
<div id="use-1" class="section level4 hasAnchor" number="4.3.6.1">
<h4><span class="header-section-number">4.3.6.1</span> Use<a href="seasonal-adjustment-1.html#use-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The test can be applied directly to any series by selecting the
option <em>Statistical Methods &gt;&gt; Seasonal Adjustment &gt;&gt; Tools &gt;&gt; Seasonality Tests</em>. This is
an example of how results are displayed for the case of a monthly series:</p>
<div class="figure">
<img src="All_images/friedman.png" alt="" />
<p class="caption">friedman</p>
</div>
<p>If the null hypothesis of no stable seasonality is rejected at the 1% significance level, then the series is
considered to be seasonal and the outcome of the test is displayed in green.</p>
<p>The test can be applied to the input series before any seasonal adjustment method has been
applied. It can also be applied to the seasonally adjusted series or to the irreguar component. In the case of
X-13ARIMA-SEATS, the test is applied to the preliminary estimate
of the unmodified Seasonal-Irregular component<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> (time series shown
in Table B3). In this estimate, the number of observations is lower than
in the final estimate of the unmodified Seasonal-Irregular component.
Thus, the number of degrees of freedom in the stable
seasonality test is lower than the number of degrees of freedom in the
test for the <a href="../theory/Tests_presence_stability.html">presence of seasonality assuming stability</a>. For
example, X-13ARIMA-SEATS uses a centred moving average of order 12 to
calculate the preliminary estimation of trend. Consequently, the first
six and last six points in the series are not computed at this stage of
calculation. The preliminary estimation of the trend is then used for
the calculation of the preliminary estimation of the unmodified Seasonal-Irregular.</p>
</div>
<div id="related-tests" class="section level4 hasAnchor" number="4.3.6.2">
<h4><span class="header-section-number">4.3.6.2</span> Related tests<a href="seasonal-adjustment-1.html#related-tests" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>When using this kind of design for a binary response, one instead uses the Cochran’s Q test.</li>
<li>Kendall’s W is a normalization of the Friedman statistic between 0 and 1.</li>
<li>The Wilcoxon signed-rank test is a nonparametric test of non-independent data from only two groups.</li>
</ul>
</div>
<div id="implementation-2" class="section level4 hasAnchor" number="4.3.6.3">
<h4><span class="header-section-number">4.3.6.3</span> Implementation<a href="seasonal-adjustment-1.html#implementation-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>This test is implemented in the class <code>ec.satoolkit.diagnostics.FriedmanTest</code></p>
</div>
<div id="references-2" class="section level4 hasAnchor" number="4.3.6.4">
<h4><span class="header-section-number">4.3.6.4</span> References<a href="seasonal-adjustment-1.html#references-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>Friedman, Milton (December 1937). “The use of ranks to avoid the assumption of normality implicit in the analysis of variance”. Journal of the American Statistical Association (American Statistical Association) 32 (200): 675–701. <a href="doi:10.2307/2279372" class="uri">doi:10.2307/2279372</a>. JSTOR 2279372.</p></li>
<li><p>Friedman, Milton (March 1939). “A correction: The use of ranks to avoid the assumption of normality implicit in the analysis of variance”. Journal of the American Statistical Association (American Statistical Association) 34 (205): 109. <a href="doi:10.2307/2279169" class="uri">doi:10.2307/2279169</a>. JSTOR 2279169.</p></li>
<li><p>Friedman, Milton (March 1940). “A comparison of alternative tests of significance for the problem of m rankings”. The Annals of Mathematical Statistics 11 (1): 86–92. <a href="doi:10.1214/aoms/1177731944" class="uri">doi:10.1214/aoms/1177731944</a>. JSTOR 2235971.</p></li>
</ul>
</div>
</div>
<div id="stable-seasonality-test-missing" class="section level3 hasAnchor" number="4.3.7">
<h3><span class="header-section-number">4.3.7</span> Stable seasonality test (missing)<a href="seasonal-adjustment-1.html#stable-seasonality-test-missing" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="moving-seasonality-test" class="section level3 hasAnchor" number="4.3.8">
<h3><span class="header-section-number">4.3.8</span> Moving seasonality test<a href="seasonal-adjustment-1.html#moving-seasonality-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The evolutive seasonality test is based on a two-way analysis of
variance model. The model uses the values from complete years only.
Depending on the decomposition type for the Seasonal – Irregular
component it uses <span class="math display">\[1\]</span> (in the case of a multiplicative model) or
<span class="math display">\[2\]</span> (in the case of an additive model):</p>
<p><span class="math display">\[
  \left|\text{SI}_{\text{ij}} - 1 \right| = X_{\text{ij}} = b_{i} + m_{j} + e_{\text{ij}}
  \]</span>, <span class="math display">\[1\]</span> <!---  \[7.148\]     --></p>
<p><span class="math display">\[
  \left| \text{SI}_{\text{ij}} \right| = X_{\text{ij}} = b_{i} + m_{j} + e_{\text{ij}}
  \]</span>, <span class="math display">\[2\]</span> <!---  \[7.149\]     --></p>
<p>where:</p>
<p><span class="math inline">\(m_{j}\)</span> – the monthly or quarterly effect for <span class="math inline">\(j\)</span>-th period,
<span class="math inline">\(j = (1,\ldots,k)\)</span>, where <span class="math inline">\(k = 12\)</span> for a monthly series and <span class="math inline">\(k = 4\)</span> for
a quarterly series;</p>
<p><span class="math inline">\(b_{j}\)</span> – the annual effect <span class="math inline">\(i\)</span>, <span class="math inline">\((i = 1,\ldots,N)\)</span> where <span class="math inline">\(N\)</span> is the
number of complete years;</p>
<p><span class="math inline">\(e_{\text{ij}}\)</span> – the residual effect.</p>
<p>The test is based on the following decomposition:</p>
<p><span class="math display">\[S^{2} = S_{A}^{2} + S_{B}^{2} + S_{R}^{2},\]</span> <span class="math display">\[3\]</span> <!---  \[7.150\]     --></p>
<p>where:</p>
<p><span class="math display">\[
S^{2} = \sum_{j = 1}^{k}{\sum_{i = 1}^{N}\left( {\overline{X}}_{\text{ij}} - {\overline{X}}_{\bullet \bullet} \right)^{2}}\
\]</span> –the total sum of squares;</p>
<p><span class="math display">\[
S_{A}^{2} = N\sum_{j = 1}^{k}\left( {\overline{X}}_{\bullet j} - {\overline{X}}_{\bullet \bullet} \right)^{2}
\]</span> – the inter-month (inter-quarter, respectively) sum of squares, which
mainly measures the magnitude of the seasonality;</p>
<p><span class="math display">\[
S_{B}^{2} = k\sum_{i = 1}^{N}\left( {\overline{X}}_{i \bullet} - {\overline{X}}_{\bullet \bullet} \right)^{2}
\]</span> – the inter-year sum of squares, which mainly measures the year-to-year
movement of seasonality;</p>
<p><span class="math display">\[
S_{R}^{2} = \sum_{i = 1}^{N}{\sum_{j = 1}^{k}\left( {\overline{X}}_{\text{ij}} - {\overline{X}}_{i \bullet} - {\overline{X}}_{\bullet j} - {\overline{X}}_{\bullet \bullet} \right)^{2}}
\]</span> – the residual sum of squares.</p>
<p>The null hypothesis <span class="math inline">\(H_{0}\ \)</span>is that <span class="math inline">\(b_{1} = b_{2} = ... = b_{N}\)</span> which
means that there is no change in seasonality over the years. This
hypothesis is verified by the following test statistic:</p>
<p><span class="math display">\[
   F_{M} = \frac{\frac{S_{B}^{2}}{(n - 1)}}{\frac{S_{R}^{2}}{(n - 1)(k - 1)}}
   \]</span>, <span class="math display">\[4\]</span> <!---   \[7.151\]     --></p>
<p>which follows an <span class="math inline">\(F\)</span>-distribution with <span class="math inline">\(k - 1\)</span> and <span class="math inline">\(n - k\)</span> degrees of
freedom.</p>
</div>
<div id="identifiable-seasonality" class="section level3 hasAnchor" number="4.3.9">
<h3><span class="header-section-number">4.3.9</span> Identifiable seasonality<a href="seasonal-adjustment-1.html#identifiable-seasonality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This test combines the values of the <span class="math inline">\(F\)</span>-statistic of the parametric
test for stable seasonality and the values of the moving seasonality
test, which was described above.</p>
<p>The test statistic is:</p>
<p><span class="math display">\[
  T = \left( \frac{\frac{7}{F_{S}} + \frac{3F_{M}}{F_{S}}}{2} \right)^{\frac{1}{2}}
  \]</span>, <span class="math display">\[1\]</span> <!---\[7.152\]     --></p>
<p>where <span class="math inline">\(F_{S}\)</span> is a stable seasonality test statistic and <span class="math inline">\(F_{M}\)</span> is
moving seasonality test statistic. The test checks if the stable
seasonality is not dominated by moving seasonality. In such a case the
seasonality is regarded as identifiable. This test statistic is used in
the combined seasonality tests (see section <a href="../theory/Tests_combined.html">Combined seasonality test</a>. The detailed description of the test is available in LOTHIAN, J., and MORRY, M. (1978).</p>
</div>
<div id="combined-seasonality-test" class="section level3 hasAnchor" number="4.3.10">
<h3><span class="header-section-number">4.3.10</span> Combined seasonality test<a href="seasonal-adjustment-1.html#combined-seasonality-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This test combines the Kruskal-Wallis test along with test for the
presence of seasonality assuming stability (<span class="math inline">\(F_{S}\)</span>), and evaluative
seasonality test for detecting the presence of identifiable seasonality
(<span class="math inline">\(F_{M}\)</span>). Those three tests are calculated using the final unmodified
SI component. The main purpose of the combined seasonality test is to
check whether the seasonality of the series is identifiable. For
example, the identification of the seasonal pattern is problematic if
the process is dominated by highly moving seasonality<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>. The testing
procedure is shown in the figure below.</p>
<div class="figure">
<img src="All_images/UG_A_image18.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>Combined seasonality test, source: LADIRAY, D., QUENNEVILLE, B. (2001)</strong></p>
</div>
<div id="spectral-analysis" class="section level3 hasAnchor" number="4.3.11">
<h3><span class="header-section-number">4.3.11</span> Spectral analysis<a href="seasonal-adjustment-1.html#spectral-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In order to decide whether a series has a seasonal component that is
predictable (stable) enough, these tests use visual criteria and formal
tests for the periodogram. The periodogram is calculated using complete
years, so that the set of Fourier frequencies contains exactly all
seasonal frequencies<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>.</p>
<p>The tests rely on two basic principles:</p>
<ul>
<li><p>The peaks associated with seasonal frequencies should be larger than
&gt; the median spectrum for all frequencies and;</p></li>
<li><p>The peaks should exceed the spectrum of the two adjacent values by
&gt; more than a critical value.</p></li>
</ul>
<blockquote>
<p>JDemetra+ performs this test on the original series. If these two
requirements are met, the test results are displayed in green. The
statistical significance of each of the seasonal peaks (i.e.
frequencies
<span class="math inline">\(\frac{\pi}{6},\ \frac{\pi}{3},\ \frac{\pi}{2},\ \frac{2\pi}{3}\text{ and } \frac{5\pi}{6}\ \)</span>corresponding
to 1, 2, 3, 4 and 5 cycles per year) is also displayed. The seasonal
and trading days frequencies depends on the frequency of time series.
They are shown in the table below. The symbol <span class="math inline">\(d\)</span> denotes a default
frequency and is described below the table.</p>
</blockquote>
<p><strong>The seasonal and trading day frequencies by time series
frequency</strong></p>
<table>
<colgroup>
<col width="23%" />
<col width="53%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Number of months per full period</strong></th>
<th><strong>Seasonal frequency</strong></th>
<th><strong>Trading day frequency (radians)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>12</td>
<td><span class="math inline">\(\frac{\pi}{6},\frac{\pi}{3},\ \frac{\pi}{2},\frac{2\pi}{3},\ \frac{5\pi}{6},\ \pi\)</span></td>
<td><span class="math inline">\(d\)</span>, 2.714</td>
</tr>
<tr class="even">
<td>6</td>
<td><span class="math inline">\(\frac{\pi}{3},\frac{2\pi}{3}\)</span>, <span class="math inline">\(\pi\)</span></td>
<td><span class="math display">\[d\]</span></td>
</tr>
<tr class="odd">
<td>4</td>
<td><span class="math inline">\(\frac{\pi}{2}\)</span>, <span class="math inline">\(\pi\)</span></td>
<td><span class="math inline">\(d\)</span>, 1.292, 1.850, 2.128</td>
</tr>
<tr class="even">
<td>3</td>
<td><span class="math display">\[\pi\]</span></td>
<td><span class="math display">\[d\]</span></td>
</tr>
<tr class="odd">
<td>2</td>
<td><span class="math display">\[\pi\]</span></td>
<td><span class="math display">\[d\]</span></td>
</tr>
</tbody>
</table>
<p>The calendar (trading day or working day) effects, related to the
variation in the number of different days of the week per period, can
induce periodic patterns in the data that can be similar to those
resulting from pure seasonal effects. From the theoretical point of
view, trading day variability is mainly due to the fact that the average
number of days in the months or quarters is not equal to a multiple of
<span class="math inline">\(7\)</span> (the average number of days of a month in the year of <span class="math inline">\(365.25\ \)</span>days
is equal to <span class="math inline">\(\frac{365.25}{12} = 30.4375\)</span> days). This effect occurs
<span class="math inline">\(\frac{365.25}{12} \times \frac{1}{7} = 4.3482\)</span> times per month: one
time for each one of the four complete weeks of each month, and a
residual of <span class="math inline">\(0.3482\)</span> cycles per month, i.e.
<span class="math inline">\(0.3482 \times 2\pi = 2.1878\ radians\)</span>. This turns out to be a
fundamental frequency for the effects associated with monthly data. In
JDemetra+ the fundamental frequency corresponding to <span class="math inline">\(0.3482\)</span> cycles per
month is used in place of the closest frequency<span class="math inline">\(\ \frac{\text{πk}}{60}\)</span>.
Thus, the quantity <span class="math inline">\(\frac{\pi \times 42}{60}\)</span> is replaced
by <span class="math display">\[\omega_{42} = 0.3482 \times 2\pi = 2.1878\]</span>. The frequencies
neighbouring <span class="math inline">\(\omega_{42}\)</span>, i.e. <span class="math display">\[\omega_{41}\]</span> and <span class="math display">\[\omega_{43}\]</span> are set
to, respectively, <span class="math display">\[2.1865 - \frac{1}{60}\]</span> and <span class="math display">\[2.1865 + \frac{1}{60}\]</span>.</p>
<p>The default frequencies (<span class="math inline">\(d)\ \)</span>for calendar effect are: 2.188 (monthly
series) and 0.280 (quarterly series). They are computed as:</p>
<p><span class="math inline">\(\omega_{\text{ce}} = \frac{2\pi}{7}\left( n - 7 \times \left\lbrack \frac{n}{7} \right\rbrack \right)\)</span>, <span class="math display">\[1\]</span> <!---\[7.158\]      -->
where:</p>
<p><span class="math inline">\(n = \frac{365.25}{s}\)</span>, <span class="math inline">\(s = 4\)</span> for quarterly series and <span class="math inline">\(s = 12\)</span> for
monthly series.</p>
<p>Other frequencies that correspond to trading day frequencies are: 2.714
(monthly series) and 1.292, 1.850, 2.128 (quarterly series).</p>
<p>In particular, the calendar frequency in monthly data (marked in red on the figure below) is very close to the seasonal frequency corresponding to 4
cycles per year <span class="math inline">\(\text{ω}_{40} = \frac{2}{3}\pi = 2.0944\)</span>.</p>
<div class="figure">
<img src="All_images/UG_A_image19.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>Periodogram with seasonal (grey) and calendar (red)
frequencies highlighted</strong></p>
<p>This implies that it may be hard to disentangle both effects using the
frequency domain techniques.</p>
<div id="defining-a-f-test" class="section level4 hasAnchor" number="4.3.11.1">
<h4><span class="header-section-number">4.3.11.1</span> Defining a F-test<a href="seasonal-adjustment-1.html#defining-a-f-test" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>link to the definition of the periodogram in the methods part</p>
<p>Brockwell and Davis (1991, section 10.2) exploit the fact that the periodogram can be expressed as
the projection on the orthonormal basis defined above to derive a test. Thus, under the null hypothesis:</p>
<ul>
<li><span class="math display">\[ 2I(\omega_{k})= \| P_{\bar{sp}_{\left\{ c_{k},s_{k} \right\}}} \mathbf{X} \|^{2}  \sim \sigma^{2} \chi^{2}(2) \]</span>, for Fourier frequencies
<span class="math display">\[ 0 &lt; \omega_{k}=2\pi k/n &lt; \pi \]</span></li>
<li><span class="math display">\[ I(\pi)= \| P_{\bar{sp}_{\left\{ e_{n/2} \right\}}} \mathbf{X} \|^{2}  \sim \sigma^{2} \chi^{2}(1) \]</span>, for <span class="math display">\[ \pi \]</span></li>
</ul>
<p>Because <span class="math display">\[ I(\omega_{k}) \]</span> is independent from the projection error sum of squares, we can define our F-test statistic as follows:</p>
<ul>
<li><span class="math display">\[ \frac{ 2I(\omega_{k})}{\|\mathbf{X}-P_{\bar{sp}_{\left\{ e_0,c_{k},s_{k} \right\}}} \mathbf{X}\|^2} \frac{n-3}{2} \sim F(2,n-3) \]</span>, for Fourier frequencies
<span class="math display">\[ 0 &lt; \omega_{k}=2\pi k/n &lt; \pi \]</span></li>
<li><span class="math display">\[ \frac{ I(\pi)}{\|\mathbf{X}-P_{\bar{sp}_{\left\{ e_0,e_{n/2} \right\}}} \mathbf{X}\|^2} \frac{n-2}{1} \sim F(1,n-2)\]</span>, for <span class="math display">\[ \pi \]</span></li>
</ul>
<p>where
- <span class="math display">\[ \|\mathbf{X}-P_{\bar{sp}_{\left\{ e_0,c_{k},s_{k} \right\}}} \mathbf{X}\|^2  = \sum_{i=1}^{n}\mathbf{X^2_i}-I(0)-2I(\omega_{k}) \sim \sigma^{2} \chi^{2}(n-3)\]</span> for Fourier frequencies
<span class="math display">\[ 0 &lt; \omega_{k}=2\pi k/n &lt; \pi \]</span>
- <span class="math display">\[ \|\mathbf{X}-P_{\bar{sp}_{\left\{ e_0,e_{n/2} \right\}}} \mathbf{X}\|^2 = \sum_{i=1}^{n}\mathbf{X^2_i}-I(0)-I(\pi) \sim \sigma^{2} \chi^{2}(n-2)  \]</span> for <span class="math display">\[ \pi \]</span></p>
<p>Thus, we reject the null if our F-test statistic computed at a given seasonal frequency (different from <span class="math display">\[ \pi \]</span>) is larger than <span class="math display">\[ F_{1-α}(2,n-3)\]</span>.
If we consider <span class="math display">\[ \pi  \]</span>, our test statistic follows a <span class="math display">\[ F_{1-α}(1,n-2)\]</span> distribution.</p>
</div>
<div id="implementation-of-f-test" class="section level4 hasAnchor" number="4.3.11.2">
<h4><span class="header-section-number">4.3.11.2</span> Implementation of F-test<a href="seasonal-adjustment-1.html#implementation-of-f-test" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The implementation of JDemetra+ considers simultaneously the whole set of seasonal frequencies (1, 2, 3, 4, 5 and 6 cycles per year). Thus, the resulting test-statistic is:</p>
<p><span class="math display">\[
\frac{ 2I(\pi/6)+ 2I(\pi/3)+ 2I(2\pi/3)+ 2I(5\pi/6)+ \delta I(\pi)}{\left\|\mathbf{X}-P_{\bar{sp}_{\left\{ e_0,c_{1},s_{1},c_{2},s_{2},c_{3},s_{3},c_{4},s_{4},c_{5},s_{5}, \delta e_{n/2} \right\}}} \mathbf{X} \right\|^2} \frac{n-12}{11} \sim F(11-\delta,n-12+\delta)
\]</span>
where <span class="math display">\[ \delta=1 \]</span> if <span class="math display">\[ n \]</span> is even and 0 otherwise.</p>
<p>In small samples, the test performs better when the periodogram is evaluated as the exact seasonal frequencies. JDemetra+ modifies the sample size
to ensure the seasonal frequencies belong to the set of Fourier frequencies. This strategy provides a very simple and effective way to eliminate the leakage problem.</p>
<p>Example of how results are displayed:</p>
<p><img src="All_images/periodogram.png" alt="periodtest" />
#### Identification of seasonal peaks in a Tukey periodogram and in an autoregressive spectrum
In order to decide whether a series has a seasonal component that is
predictable (stable) enough, these tests use visual criteria and formal
tests for the periodogram. The periodogram is calculated using complete
years, so that the set of Fourier frequencies contains exactly all
seasonal frequencies<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>.</p>
<p>The tests rely on two basic principles:</p>
<ul>
<li><p>The peaks associated with seasonal frequencies should be larger than the median spectrum for all frequencies and;</p></li>
<li><p>The peaks should exceed the spectrum of the two adjacent values by more than a critical value.</p></li>
</ul>
<blockquote>
<p>JDemetra+ performs this test on the original series. If these two
requirements are met, the test results are displayed in green. The
statistical significance of each of the seasonal peaks (i.e.
frequencies
<span class="math inline">\(\frac{\pi}{6},\ \frac{\pi}{3},\ \frac{\pi}{2},\ \frac{2\pi}{3}\)</span> and $$ corresponding
to 1, 2, 3, 4 and 5 cycles per year) is also displayed. The seasonal
and trading days frequencies depends on the frequency of time series.
They are shown in the table below. The symbol <span class="math inline">\(d\)</span> denotes a default
frequency and is described below the table.</p>
</blockquote>
<p><strong>The seasonal and trading day frequencies by time series
frequency</strong></p>
<table>
<colgroup>
<col width="23%" />
<col width="53%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Number of months per full period</strong></th>
<th><strong>Seasonal frequency</strong></th>
<th><strong>Trading day frequency (radians)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>12</td>
<td><span class="math inline">\(\frac{\pi}{6},\frac{\pi}{3},\ \frac{\pi}{2},\frac{2\pi}{3},\ \frac{5\pi}{6},\ \pi\)</span></td>
<td><span class="math inline">\(d\)</span>, 2.714</td>
</tr>
<tr class="even">
<td>6</td>
<td><span class="math inline">\(\frac{\pi}{3},\frac{2\pi}{3}\)</span>, <span class="math inline">\(\pi\)</span></td>
<td><span class="math display">\[d\]</span></td>
</tr>
<tr class="odd">
<td>4</td>
<td><span class="math inline">\(\frac{\pi}{2}\)</span>, <span class="math inline">\(\pi\)</span></td>
<td><span class="math inline">\(d\)</span>, 1.292, 1.850, 2.128</td>
</tr>
<tr class="even">
<td>3</td>
<td><span class="math display">\[\pi\]</span></td>
<td><span class="math display">\[d\]</span></td>
</tr>
<tr class="odd">
<td>2</td>
<td><span class="math display">\[\pi\]</span></td>
<td><span class="math display">\[d\]</span></td>
</tr>
</tbody>
</table>
<p>The calendar (trading day or working day) effects, related to the
variation in the number of different days of the week per period, can
induce periodic patterns in the data that can be similar to those
resulting from pure seasonal effects. From the theoretical point of
view, trading day variability is mainly due to the fact that the average
number of days in the months or quarters is not equal to a multiple of
7 (the average number of days of a month in the year of 365.25 days
is equal to <span class="math inline">\(\frac{365.25}{12} =\)</span> 30.4375 days). This effect occurs
<span class="math inline">\(\frac{365.25}{12} \times \frac{1}{7} =\)</span> 4.3482 times per month: one
time for each one of the four complete weeks of each month, and a
residual of 0.3482 cycles per month, i.e.
<span class="math inline">\(0.3482 \times 2\pi = 2.1878\)</span> radians. This turns out to be a
fundamental frequency for the effects associated with monthly data. In
JDemetra+ the fundamental frequency corresponding to 0.3482 cycles per
month is used in place of the closest frequency <span class="math inline">\(\frac{\text{πk}}{60}\)</span>.
Thus, the quantity <span class="math inline">\(\frac{\pi \times 42}{60}\)</span> is replaced
by <span class="math inline">\(\omega_{42} = 0.3482 \times 2\pi = 2.1878\)</span>. The frequencies
neighbouring <span class="math inline">\(\omega_{42}\)</span>, i.e. <span class="math inline">\(\omega_{41}\)</span> and <span class="math inline">\(\omega_{43}\)</span> are set
to, respectively, <span class="math inline">\(2.1865 - \frac{1}{60}\)</span> and <span class="math inline">\(2.1865 + \frac{1}{60}\)</span>.</p>
<p>The default frequencies (<span class="math inline">\(d)\ \)</span>for calendar effect are: 2.188 (monthly
series) and 0.280 (quarterly series). They are computed as:</p>
<p><span class="math display">\[
\omega_{\text{ce}} = \frac{2\pi}{7}\left( n - 7 \times \left\lbrack \frac{n}{7} \right\rbrack \right)
\]</span>, <span class="math display">\[1\]</span> <!---\[7.158\]      --></p>
<p>where:</p>
<p><span class="math inline">\(n = \frac{365.25}{s}\)</span>, <span class="math inline">\(s = 4\)</span> for quarterly series and <span class="math inline">\(s = 12\)</span> for
monthly series.</p>
<p>Other frequencies that correspond to trading day frequencies are: 2.714
(monthly series) and 1.292, 1.850, 2.128 (quarterly series).</p>
<p>In particular, the calendar frequency in monthly data (marked in red on the figure below) is very close to the seasonal frequency corresponding to 4
cycles per year <span class="math inline">\(\text{ω}_{40} = \frac{2}{3}\pi = 2.0944\)</span>.</p>
<div class="figure">
<img src="All_images/UG_A_image19.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>Periodogram with seasonal (grey) and calendar (red)
frequencies highlighted</strong></p>
<p>This implies that it may be hard to disentangle both effects using the
frequency domain techniques.</p>
</div>
<div id="graphical-test-based-on-ar-spectrum" class="section level4 hasAnchor" number="4.3.11.3">
<h4><span class="header-section-number">4.3.11.3</span> Graphical Test based on AR spectrum<a href="seasonal-adjustment-1.html#graphical-test-based-on-ar-spectrum" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>for AR spectrum definition link to methods part</p>
<div class="figure">
<img src="All_images/UG_A_image19.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>Periodogram with seasonal (grey) and calendar (red)
frequencies highlighted</strong></p>
<p>The statistical significance of the peaks associated to a given frequency can be informally tested using a visual criterion, which has proved to perform well in
simulation experiments. Visually significant peaks for a frequency <span class="math display">\[\lambda_{j}\]</span> satisfy both conditions:</p>
<ul>
<li><span class="math display">\[ \frac{f_{x}(\lambda_{j})- \max \left\{f_{x}(\lambda_{j+1}),f_{x}(\lambda_{j-1}) \right\}}{\left[ \max_{k}f_{x}(\lambda_{k})-\min_{i}f_{x}(\lambda_{i}) \right]}\ge CV(\lambda_{j}) \]</span>, where
<span class="math display">\[ CV(\lambda_{j})\]</span> can be set equal to <span class="math display">\[6/52 \]</span> for all <span class="math display">\[j\]</span></li>
<li><span class="math display">\[ f_{x}(\lambda_{j})&gt; median_{j} \left\{ f_{x}(\lambda_{j}) \right\}\]</span>, which guarantees <span class="math display">\[ f_{x}(\lambda_{j}) \]</span> it is not a local peak.</li>
</ul>
<p>The first condition implies that if we divide the range <span class="math display">\[\max_{k}f_{x}(\lambda_{k})-\min_{i}f_{x}(\lambda_{i})\]</span> in
52 parts (traditionally represented by stars) the height of each pick should be at least 6 stars.</p>
</div>
<div id="graphical-test-based-on-tukey-spectrum" class="section level4 hasAnchor" number="4.3.11.4">
<h4><span class="header-section-number">4.3.11.4</span> Graphical Test based on Tukey spectrum<a href="seasonal-adjustment-1.html#graphical-test-based-on-tukey-spectrum" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>link to methods/spectral analysis section for Tukeys definition</p>
<p>The current JDemetra+ implementation of the seasonality test is based on a <span class="math display">\[F(d_{1},d_{2})\]</span> approximation that has been originally proposed by Maravall (2012) for
TRAMO-SEATS. This test is has been designed for a Blackman-Tukey window based on a particular choices of the truncation lag <span class="math display">\[r\]</span> and sample size. Following
this approach, we determine visually significant peaks for a frequency <span class="math display">\[\omega_{j}\]</span> when</p>
<p><span class="math display">\[
\frac{2 f_{x}(\omega_{j})}{\left[ f_{x}(\omega_{j+1})+ f_{x}(\omega_{j-1}) \right]} \ge CV(\omega_{j})
\]</span></p>
<p>where <span class="math display">\[ CV(\omega_{j})\]</span> is the critical value of a <span class="math display">\[F(d_{1},d_{2})\]</span> distribution, where the degrees of freedom are determined using simulations. For
<span class="math display">\[\omega_{j}= \pi\]</span>, we have a significant peak when <span class="math display">\[\frac{f_{x}(\omega_{[n/2]})}{\left[ f_{x}(\omega_{[(n-1)/2]})\right]} \ge CV(\omega_{j}) \]</span></p>
<p>Two significant levels for this test are considered: <span class="math display">\[\alpha=0.05\]</span> (code “t”) and <span class="math display">\[\alpha=0.01\]</span> (code “T”).</p>
<p>As opposed to the <a href="%7B%7B%20site.baseurl%20%7D%7D/pages/theory/Tests_ARspectrum.html">AR spectrum</a>, which is computed on the basis of the
last <span class="math display">\[120\]</span> data points, we will use here all available
observations. Those critical values have been calculated given the recommended truncation lag <span class="math display">\[r=79\]</span> for a sample size within the interval <span class="math display">\[n \in [80,119]\]</span>
and <span class="math display">\[r=112\]</span> for <span class="math display">\[n \in [120,300]\]</span> . The <span class="math display">\[F\]</span> approximation is less accurate for sample sizes larger than <span class="math display">\[300\]</span>. For quarterly data, <span class="math display">\[r=44 \]</span>, but there
are no recommendations regarding the required sample size</p>
<p>JDemetra+ considers critical values for <span class="math display">\[ \alpha=1\%\]</span> (code “T”) and <span class="math display">\[ \alpha=5\%\]</span> (code “t”) at each one of the seasonal
frequencies represented in the table below, e.g. frequencies <span class="math inline">\(\frac{\pi}{6},\ \frac{\pi}{3},\ \frac{\pi}{2},\ \frac{2\pi}{3}\text{ and } \frac{5\pi}{6}\ \)</span> corresponding
to 1, 2, 3, 4, 5 and 6 cycles per year in this example, since we are dealing with monthly
data. The codes “a” and “A” correpond to the so-called
<a href="%7B%7B%20site.baseurl%20%7D%7D/pages/theory/Tests_ARspectrum.html">AR spectrum</a>, so ignore them for the moment.</p>
<p><strong>The seasonal and trading day frequencies by time series
frequency</strong></p>
<table>
<colgroup>
<col width="23%" />
<col width="53%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Number of months per full period</strong></th>
<th><strong>Seasonal frequency</strong></th>
<th><strong>Trading day frequency (radians)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>12</td>
<td><span class="math inline">\(\frac{\pi}{6},\frac{\pi}{3},\ \frac{\pi}{2},\frac{2\pi}{3},\ \frac{5\pi}{6},\ \pi\)</span></td>
<td><span class="math inline">\(d\)</span>, 2.714</td>
</tr>
<tr class="even">
<td>6</td>
<td><span class="math inline">\(\frac{\pi}{3},\frac{2\pi}{3}\)</span>, <span class="math inline">\(\pi\)</span></td>
<td><span class="math display">\[d\]</span></td>
</tr>
<tr class="odd">
<td>4</td>
<td><span class="math inline">\(\frac{\pi}{2}\)</span>, <span class="math inline">\(\pi\)</span></td>
<td><span class="math inline">\(d\)</span>, 1.292, 1.850, 2.128</td>
</tr>
<tr class="even">
<td>3</td>
<td><span class="math display">\[\pi\]</span></td>
<td><span class="math display">\[d\]</span></td>
</tr>
<tr class="odd">
<td>2</td>
<td><span class="math display">\[\pi\]</span></td>
<td><span class="math display">\[d\]</span></td>
</tr>
</tbody>
</table>
<p>Currently, only seasonal frequencies are tested, but the program allows you to manually plot the Tukey spectrum and focus your attention on both seasonal
and trading day frequencies.</p>
</div>
<div id="references-3" class="section level4 hasAnchor" number="4.3.11.5">
<h4><span class="header-section-number">4.3.11.5</span> References<a href="seasonal-adjustment-1.html#references-3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Tukey, J. (1949). The sampling theory of power spectrum estimates., Proceedings Symposium on Applications of Autocorrelation Analysis to Physical Problems, NAVEXOS-P-735, Office of Naval Research, Washington, 47-69</p>
<p>Brockwell, P.J., and R.A. Davis (1991). Times Series: Theory and Methods. Springer Series in Statistics.</p>
</div>
</div>
<div id="example-of-non-seasonal-series" class="section level3 hasAnchor" number="4.3.12">
<h3><span class="header-section-number">4.3.12</span> Example of non seasonal series<a href="seasonal-adjustment-1.html#example-of-non-seasonal-series" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <a href="https://ec.europa.eu/eurostat/documents/3859598/6830795/KS-GQ-15-001-EN-N.pdf/d8f1e5f5-251b-4a69-93e3-079031b74bd3">ESS Guidelines on Seasonal Adjustment (2015)</a>
recommend to apply seasonal adjustment only to those time series for which the seasonal
and/or calendar effects can be properly explained, identified and
estimated. Therefore, seasonal adjustment of non-seasonal time series is
an inappropriate treatment. This case study explains how to recognize a
non-seasonal time series using the tools and functionalities implemented
in JDemetra+.</p>
<ol style="list-style-type: decimal">
<li><p>The picture below shows the results from the seasonal adjustment
of a stock market turnover series from Greece using the RSA4c
specification. The test diagnostics do not indicate any problems in
the modelling phase (residual seasonality statistics and
out-of-sample tests are displayed in green). The seasonality seems
to be removed from the time series, but the overall assessment is
uncertain, due to the failure of the m-statistics and the visual
spectral analysis.</p>
<div class="figure">
<img src="All_images/UG_SA_image5.jpg" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>The diagnostic results for stock market turnover in Greece</strong></p></li>
<li><p>The inspection of a graph hints at the source of the problem. The
original time series does not manifest any seasonal movements (left
panel). It should be noted that when the X-13ARIMA-SEATS method is used
for seasonal adjustment, the seasonal component is estimated
regardless of the properties of the original time series (right panel).
It means that the seasonal component is estimated even if there are
no signs of the presence of seasonal fluctuations in the time
series. In the picture below the seasonal component (blue line) is
moving rather than being stable and the averages for the specific months
(red lines) are not at the same level, suggesting some intra-year
differences between seasons. Nevertheless, the SI ratios (dots) are
rather far from the seasonal component, indicating that the irregular
movements dominate over the seasonal ones.</p>
<div class="figure">
<img src="All_images/UG_SA_image6.jpg" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>Original and seasonally adjusted time series and the trend-cycle component (left) and SI ratios (right)</strong></p></li>
<li><p>The seasonality tests performed for the original time series<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> are
ambiguous. Some suggest that seasonality is not present (the
outcomes of three tests: the auto-correlation at seasonal lags, the
spectral peaks test and the seasonal dummies test all indicate no
seasonality in the original time series). These tests are available
in the <em>Diagnostic</em> section of the output tree. The seasonality tests can be
executed independently from the seasonal adjustment proces. The descriptions of
these tests are given in the <a href="../case-studies/seasonalitytests.html"><em>Seasonality tests</em></a> scenario.</p>
<div class="figure">
<img src="All_images/UG_SA_image7.jpg" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>Seasonality test for the original (transformed) series</strong></p></li>
<li><p>Another sign indicating that the presence of seasonality is uncertain
should be addressed : the non-seasonal ARIMA model chosen by the
automatic model identification procedure. The details of the
RegARIMA model are available in the <em>Pre-processing</em> node.</p>
<div class="figure">
<img src="All_images/UG_SA_image8.jpg" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>Estimation results for the RegARIMA model</strong></p></li>
<li><p>For X-13ARIMA-SEATS the most relevant tool to assess the presence
of seasonal movement in the time series is a combined seasonality
test. For the series presented in this case study the result of the
combined seasonality test confirms that the movements observed in
the time series are not stable and regular enough to be recognized
as seasonal ones.</p>
<div class="figure">
<img src="All_images/UG_SA_image9.jpg" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>Combined seasonality test result</strong></p></li>
<li><p>Regardless of the presence and/or significance of seasonal movements
in the original time series the seasonal component is always
estimated by X-13ARIMA-SEATS, as shown in the picture below (from
the panel on the left choose <em>Main results</em> → <em>Table</em>). Therefore
X-13ARIMA-SEATS users should always check the outcome of the
combined seasonality test.</p>
<div class="figure">
<img src="All_images/UG_SA_image10.jpg" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>Decomposition’s results</strong></p></li>
<li><p>In general, in the case of a non-seasonal time series the TRAMO-SEATS
method produces more coherent results than X-13ARIMA-SEATS. When no
seasonal movements are detected the non-seasonal ARIMA model is used
and the seasonal component is not estimated.</p>
<div class="figure">
<img src="All_images/UG_SA_image11.jpg" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>Decomposition result for a non-seasonal time series - TRAMO-SEATS</strong></p></li>
<li><p>Consequently, the <em>SI ratios</em> (dots) estimated by TRAMO-SEATS are
equal to the irregular component and for each month the seasonal
component is equal to the mean (red, horizontal line), which is
one.</p>
<div class="figure">
<img src="All_images/UG_SA_image12.jpg" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>SI ratios for a non-seasonal time series - TRAMO-SEATS</strong></p></li>
</ol>
</div>
</div>
<div id="calendar-correction" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Calendar correction<a href="seasonal-adjustment-1.html#calendar-correction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>here defintions, test in the pre adj part ?</p>
<div id="tests-for-residual-trading-days" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Tests for residual trading days<a href="seasonal-adjustment-1.html#tests-for-residual-trading-days" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We consider below tests on the seasonally adjusted series (<span class="math inline">\(sa_t\)</span>) or on the irregular component (<span class="math inline">\(irr_t\)</span>).
When the reasoning applies on both components, we will use <span class="math inline">\(y_t\)</span>.
The functions <span class="math inline">\(stdev\)</span> stands for “standard deviation” and <span class="math inline">\(rms\)</span> for “root mean squares”</p>
<p>The tests are computed on the log-transformed components in the case of multiplicative decomposition.</p>
<p>TD are the usual contrasts of trading days, 6 variables (no specific calendar).</p>
<div id="non-significant-irregular" class="section level4 hasAnchor" number="4.4.1.1">
<h4><span class="header-section-number">4.4.1.1</span> Non significant irregular<a href="seasonal-adjustment-1.html#non-significant-irregular" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>When <span class="math inline">\(irr_t\)</span> is not significant, we don’t compute the test on it, to avoid irrelevant results.
We consider that <span class="math inline">\(irr_t\)</span> is significant if <span class="math inline">\(stdev( irr_t)&gt;0.01\)</span> (multiplicative case) or if <span class="math inline">\(stdev(irr_t)/rms(sa_t) &gt;0.01\)</span> (additive case).</p>
</div>
<div id="f-test" class="section level4 hasAnchor" number="4.4.1.2">
<h4><span class="header-section-number">4.4.1.2</span> F test<a href="seasonal-adjustment-1.html#f-test" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The test is the usual joint F-test on the TD coefficients, computed on the following models:</p>
<div id="autoregressive-model-ar-modelling-option" class="section level5 hasAnchor" number="4.4.1.2.1">
<h5><span class="header-section-number">4.4.1.2.1</span> Autoregressive model (AR modelling option)<a href="seasonal-adjustment-1.html#autoregressive-model-ar-modelling-option" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>We compute by OLS:</p>
<p><span class="math display">\[y_t=\mu + \alpha y_{t-1} + \beta TD_t + \epsilon_t \]</span></p>
</div>
<div id="difference-model" class="section level5 hasAnchor" number="4.4.1.2.2">
<h5><span class="header-section-number">4.4.1.2.2</span> Difference model<a href="seasonal-adjustment-1.html#difference-model" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>We compute by OLS:</p>
<p><span class="math display">\[\Delta y_t - \overline{\Delta y_t}=\beta TD_t + \epsilon_t \]</span></p>
<p>So, the latter model is a restriction of the first one (<span class="math inline">\(\alpha =1, \mu =μ=\overline{\Delta y_t}\)</span>)</p>
<p>The tests are the usual joint F-tests on <span class="math inline">\(\beta \quad (H_0:\beta=0)\)</span>.</p>
<p>By default, we compute the tests on the 8 last years of the components, so that they might highlight moving calendar effects.</p>
<p>Remark:</p>
<p>In Tramo, a similar test is computed on the residuals of the Arima model. More exactly, the F-test is computed on <span class="math inline">\(e_t=\beta TD_t + \epsilon_t\)</span>, where <span class="math inline">\(e_t\)</span> are the one-step-ahead forecast errors.</p>
</div>
</div>
</div>
</div>
<div id="outliers-and-intervention-variables" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Outliers and intervention variables<a href="seasonal-adjustment-1.html#outliers-and-intervention-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="pre-adjustment" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Pre-adjustment<a href="seasonal-adjustment-1.html#pre-adjustment" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="decomposition" class="section level2 hasAnchor" number="4.7">
<h2><span class="header-section-number">4.7</span> Decomposition<a href="seasonal-adjustment-1.html#decomposition" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="x-11-moving-average-based-decomposition" class="section level3 hasAnchor" number="4.7.1">
<h3><span class="header-section-number">4.7.1</span> X-11 moving average based decomposition<a href="seasonal-adjustment-1.html#x-11-moving-average-based-decomposition" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A complete documentation of the X-11 method is available in LADIRAY, D.,
and QUENNEVILLE, B. (2001). The X-11 program is the result of a long
tradition of non-parametric smoothing based on moving averages, which
are weighted averages of a moving span of a time series (see hereafter).
Moving averages have two important drawbacks:</p>
<ul>
<li><p>They are not resistant and might be deeply impacted by outliers;</p></li>
<li><p>The smoothing of the ends of the series cannot be done except with asymmetric moving averages which introduce phase-shifts and delays in the detection of turning points.</p></li>
</ul>
<p>These drawbacks adversely affect the X-11 output and stimulate the
development of this method. To overcome these flaws first the series are
modelled with a RegARIMA model that calculates forecasts and estimates
the regression effects. Therefore, the seasonal adjustment process is
divided into two parts.</p>
<ul>
<li><p>In a first step, the RegARIMA model is used to clean the series from
&gt; non-linearities, mainly outliers and calendar effects. A global
&gt; ARIMA model is adjusted to the series in order to compute the
&gt; forecasts.</p></li>
<li><p>In a second step, an enhanced version of the X-11 algorithm is used
&gt; to compute the trend, the seasonal component and the irregular
&gt; component.</p></li>
</ul>
<div class="figure">
<img src="All_images/UG_A_image13.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>The flow diagram for seasonal adjustment with X-13ARIMA-SEATS using the X-11 algorithm.</strong></p>
<div id="moving-averages" class="section level4 hasAnchor" number="4.7.1.1">
<h4><span class="header-section-number">4.7.1.1</span> Moving averages<a href="seasonal-adjustment-1.html#moving-averages" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The moving average of coefficient <span class="math inline">\(\theta_{i}\)</span> is
defined as:</p>
<p><span class="math display">\[M\left( X_{t} \right) = \sum_{k = - p}^{+ f}\theta_{k}X_{t + k}\]</span> <span class="math display">\[1\]</span><!---\[7.61\]--></p>
<p>The value at time <span class="math inline">\(t\)</span> of the series is therefore replaced by a weighted
average of <span class="math inline">\(p\)</span> "past" values of the series, the current value, and <span class="math inline">\(f\)</span>
"future" values of the series. The quantity <span class="math inline">\(p + f + 1\ \)</span>is called the
moving average order. When <span class="math inline">\(p\)</span> is equal to <span class="math inline">\(f\)</span>, that is, when
the number of points in the past is the same as the number of points in
the future, the moving average is said to be centred. If, in addition,
<span class="math inline">\(\theta_{- k} = \theta_{k}\)</span> for any <span class="math inline">\(k\)</span>, the moving average <span class="math inline">\(M\)</span>
is said to be symmetric. One of the simplest moving averages is the
symmetric moving average of order <span class="math inline">\(P = 2p + 1\)</span> where all the weights are
equal to<span class="math inline">\(\ \frac{1}{P}\)</span>.</p>
<p>This moving average formula works well for all time series observations,
except for the first <span class="math inline">\(p\)</span> values and last <span class="math inline">\(f\)</span> values. Generally, with a
moving average of order <span class="math inline">\(p + f + 1\ \)</span>calculated for instant
<span class="math inline">\(t\)</span>nwith points <span class="math inline">\(p\)</span> in the past and points <span class="math inline">\(f\)</span> in the
future, it will be impossible to smooth out the first <span class="math inline">\(p\)</span> values and the
last <span class="math inline">\(f\)</span> values of the series because of lack of input to the moving
average formula.</p>
<p>In the X-11 method, symmetric moving averages play an important role as
they do not introduce any phase-shift in the smoothed series. But, to
avoid losing information at the series ends, they are either
supplemented by <em>ad hoc</em> asymmetric moving averages or applied on the
series extended by forecasts.</p>
<p>For the estimation of the seasonal component, X-13ARIMA-SEATS uses
<span class="math inline">\(P \times Q\)</span> composite moving averages, obtained by composing a simple
moving average of order <span class="math inline">\(P\)</span>, which coefficients are all equal to
<span class="math inline">\(\frac{1}{P}\)</span>, and a simple moving average of order <span class="math inline">\(Q\)</span>, which
coefficients are all equal to <span class="math inline">\(\frac{1}{Q}\)</span>.</p>
<p>The composite moving averages are widely used by the X-11 method. For an
initial estimation of trend X-11 method uses a <span class="math inline">\(2 \times 4\)</span> moving
average in case of a quarterly time series while for a monthly time
series a <span class="math inline">\(2 \times 12\ \)</span>moving average is applied. The <span class="math inline">\(2 \times 4\)</span>
moving average is an average of order 5 with coefficients
<span class="math display">\[\frac{1}{8}\left\{1, 2, 2, 2, 1\right\}\]</span>. It eliminates frequency
<span class="math inline">\(\frac{\pi}{2}\)</span> corresponding to period 4 and therefore it is suitable
for seasonal adjustment of the quarterly series with a constant
seasonality. The <span class="math inline">\(2 \times 12\)</span> moving average, with coefficients
<span class="math display">\[\frac{1}{24}\left\{1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1\right\} \]</span>that
retains linear trends, eliminates order-<span class="math inline">\(12\)</span> constant seasonality and
minimises the variance of the irregular component. The <span class="math inline">\(2 \times 4\)</span> and
<span class="math inline">\(2 \times 12\)</span> moving averages are also used in the X-11 method to
normalise the seasonal factors. The composite moving averages are also
used to extract the seasonal component. These, which are used in the
purely automatic run of the X-11 method (without any intervention from
the user) are <span class="math inline">\(3 \times 3\)</span>, <span class="math inline">\(3 \times 5\)</span> and <span class="math inline">\(3 \times 9\)</span>.</p>
<p>In the estimation of the trend also Henderson moving averages are used.
These filters have been chosen for their smoothing properties. The
coefficients of a Henderson moving average of order <span class="math inline">\(2p + 1\)</span> may be
calculated using the formula:</p>
<p><span class="math inline">\(\theta_{i} = \frac{315\left\lbrack \left( n - 1 \right)^{2} - i^{2} \right\rbrack\left\lbrack n^{2} - i^{2} \right\rbrack\left\lbrack \left( n + 1 \right)^{2} - i^{2} \right\rbrack\left\lbrack {3n}^{2} - 16 - 11i^{2} \right\rbrack}{8n\left( n^{2} - 1 \right)\left( {4n}^{2} - 1 \right)\left( {4n}^{2} - 9 \right)\left( 4n^{2} - 25 \right)}\)</span>, <span class="math display">\[2\]</span><!---\[7.62\]--></p>
<p>where: <span class="math inline">\(n = p + 2\)</span><span class="math inline">\(n = p + 2\)</span>.</p>
</div>
<div id="the-basic-algorithm-of-the-x-11-method" class="section level4 hasAnchor" number="4.7.1.2">
<h4><span class="header-section-number">4.7.1.2</span> The basic algorithm of the X-11 method<a href="seasonal-adjustment-1.html#the-basic-algorithm-of-the-x-11-method" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The X-11 method is based on an iterative principle of estimation of the
different components using appropriate moving averages at each step of
the algorithm. The successive results are saved in tables. The list of
the X-11 tables displayed in JDemetra+ is included at the end of this
section.</p>
<p>The basic algorithm of the X-11 method will be presented for a monthly
time series <span class="math inline">\(X_{t}\)</span> that is assumed to be decomposable into trend,
seasonality and irregular component according to an additive model
<span class="math inline">\(X_{t} = TC_{t} + S_{t} + I_{t}\)</span>.</p>
<p>A simple seasonal adjustment algorithm can be thought of in eight steps.
The steps presented below are designed for the monthly time series. In
the algorithm that is run for the quarterly time series the <span class="math inline">\(2 \times 4\)</span>
moving average instead of the <span class="math inline">\(2 \times 12\)</span> moving average is used.</p>
<p><strong><em>Step 1: Estimation of Trend by</em></strong> <span class="math inline">\(\mathbf{2 \times 12}\)</span> <strong><em>moving
average:</em></strong></p>
<p><span class="math inline">\(TC_{t}^{(1)} = M_{2 \times 12}(X_{t})\)</span> <span class="math display">\[3\]</span><!---\[7.63\]--></p>
<p><strong><em>Step 2: Estimation of the Seasonal-Irregular component:</em></strong></p>
<p><span class="math inline">\(\left( S_{t} + I_{t} \right)^{(1)} = X_{t} - \text{TC}_{t}^{(1)}\)</span> <span class="math display">\[4\]</span><!---\[7.64\]--></p>
<p><strong><em>Step 3: Estimation of the Seasonal component by</em></strong> <span class="math inline">\(\mathbf{3 \times 3}\)</span>
<strong><em>moving average over each month:</em></strong></p>
<p><span class="math inline">\(S_{t}^{(1)} - M_{3 \times 3}\left\lbrack \left( S_{t} + I_{t} \right)^{(1)} \right\rbrack\)</span> <span class="math display">\[5\]</span><!---\[7.65\]--></p>
<p>The moving average used here is a <span class="math inline">\(3 \times 3\)</span> moving average over
<span class="math inline">\(5\)</span> terms, with coefficients
<span class="math display">\[\frac{1}{9} \left\{1, 2, 3, 2, 1 \right\}\]</span>. The seasonal component
is then centred using a <span class="math inline">\(2 \times 12\)</span> moving average.</p>
<p><span class="math display">\[
   \widetilde{S}_{t}^{(1)} = S_{t}^{(1)} - M_{2 \times 12}\left( S_{t}^{(1)} \right)
  \]</span> <span class="math display">\[6\]</span><!---\[7.66\]--></p>
<p><strong><em>Step 4: Estimation of the seasonally adjusted series:</em></strong></p>
<p><span class="math display">\[
  SA_{t}^{\left( 1 \right)} = \left( \text{TC}_{t} + I_{t} \right)^{(1)} = X_{t} - {\widetilde{S}}_{t}^{(1)}
  \]</span> <span class="math display">\[7\]</span><!---\[7.67\]--></p>
<p>This first estimation of the seasonally adjusted series must, by
construction, contain less seasonality. The X-11 method again executes
the algorithm presented above, changing the moving averages to take this
property into account.</p>
<p><strong><em>Step 5: Estimation of Trend by 13-term Henderson moving average:</em></strong></p>
<p><span class="math display">\[
  TC_{t}^{(2)} = H_{13}\left( \text{SA}_{t}^{\left( 1 \right)} \right)
  \]</span> <span class="math display">\[8\]</span><!---\[7.68\]--></p>
<p>Henderson moving averages, while they do not have special properties in
terms of eliminating seasonality (limited or none at this stage), have a
very good smoothing power and retain a local polynomial trend of degree
<span class="math inline">\(2\)</span> and preserve a local polynomial trend of degree <span class="math inline">\(3\)</span>.</p>
<p><strong><em>Step 6: Estimation of the Seasonal-Irregular component:</em></strong></p>
<p><span class="math display">\[
  \left( S_{t} + I_{t} \right)^{(2)} = X_{t} - \text{TC}_{t}^{(2)}
  \]</span> <span class="math display">\[9\]</span><!---\[7.69\]--></p>
<p><strong><em>Step 7: Estimation of the Seasonal component by</em></strong> <span class="math inline">\(\mathbf{3 \times 5}\)</span>
<strong><em>moving average over each month:</em></strong></p>
<p><span class="math display">\[S_{t}^{(2)} - M_{3 \times 3}\left\lbrack \left( S_{t} + I_{t} \right)^{(2)} \right\rbrack\]</span> <span class="math display">\[10\]</span><!---\[7.70\]--></p>
<p>The moving average used here is a <span class="math inline">\(3 \times 5\)</span> moving average over <span class="math inline">\(7\)</span>
terms, of coefficients
<span class="math display">\[\frac{1}{15} \left\{ 1,\ 2,\ 3,\ 3,\ 3,\ 2,\ 1 \right\}\]</span> and retains
linear trends. The coefficients are then normalised such that their sum
over the whole <span class="math inline">\(12\)</span>-month period is approximately cancelled out:</p>
<p><span class="math display">\[{ \widetilde{S}}_{t}^{(2)} = S_{t}^{(2)} - M_{2 \times 12}\left( S_{t}^{(2)} \right)\]</span> <span class="math display">\[11\]</span><!---\[7.71\]--></p>
<p><strong><em>Step 8: Estimation of the seasonally adjusted series:</em></strong></p>
<p><span class="math display">\[SA_{t}^{\left( 2 \right)} = \left(TC_{t} + I_{t} \right)^{(2)} = X_{t} - {\widetilde{S}}_{t}^{(2)}\]</span> <span class="math display">\[12\]</span><!---\[7.72\]--></p>
<p>The whole difficulty lies, then, in the choice of the moving averages
used for the estimation of the trend in steps <span class="math inline">\(1\)</span> and <span class="math inline">\(5\)</span> on the one
hand, and for the estimation of the seasonal component in steps <span class="math inline">\(3\)</span> and
<span class="math inline">\(5\)</span>. The course of the algorithm in the form that is implemented in
JDemetra+ is presented in the figure below. The adjustment for trading day
effects, which is present in the original X-11 program, is omitted here,
as since calendar correction is performed by the RegARIMA model,
JDemetra+ does not perform further adjustment for these effects in the
decomposition step.</p>
<p><strong>A workflow diagram for the X-11 algorithm based upon training material from the Deutsche Bundesbank</strong></p>
<div id="the-iterative-principle-of-x-11" class="section level5 hasAnchor" number="4.7.1.2.1">
<h5><span class="header-section-number">4.7.1.2.1</span> <strong>The iterative principle of X-11</strong><a href="seasonal-adjustment-1.html#the-iterative-principle-of-x-11" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>To evaluate the different components of a series, while taking into
account the possible presence of extreme observations, X-11 will proceed
iteratively: estimation of components, search for disruptive effects in
the irregular component, estimation of components over a corrected
series, search for disruptive effects in the irregular component, and so
on.</p>
<p>The Census X-11 program presents four processing stages (A, B, C, and
D), plus 3 stages, E, F, and G, that propose statistics and charts and
are not part of the decomposition per se. In stages B, C and D the basic
algorithm is used as is indicated in the figure below.</p>
<p><strong>A workflow diagram for the X-11 algorithm implemented in
JDemetra+. Source: Based upon training material from the Deutsche
Bundesbank</strong></p>
<ul>
<li><strong>Part A: Pre-adjustments</strong></li>
</ul>
<p>This part, which is not obligatory, corresponds in X-13ARIMA-SEATS to
the first cleaning of the series done using the RegARIMA facilities:
detection and estimation of outliers and calendar effects (trading day
and Easter), forecasts and backcasts[^61] of the series. Based on these
results, the program calculates prior adjustment factors that are
applied to the raw series. The series thus corrected, Table B1 of the
printouts, then proceeds to part B.</p>
<ul>
<li><strong>Part B: First automatic correction of the series</strong></li>
</ul>
<p>This stage consists of a first estimation and down-weighting of the
extreme observations and, if requested, a first estimation of the
calendar effects. This stage is performed by applying the basic
algorithm detailed earlier. These operations lead to Table B20,
adjustment values for extreme observations, used to correct the
unadjusted series and result in the series from Table C1.</p>
<ul>
<li><strong>Part C: Second automatic correction of the series</strong></li>
</ul>
<p>Applying the basic algorithm once again, this part leads to a more
precise estimation of replacement values of the extreme observations
(Table C20). The series, finally "cleaned up", is shown in Table D1 of
the printouts.</p>
<ul>
<li><strong>Part D: Seasonal adjustment</strong></li>
</ul>
<p>This part, at which our basic algorithm is applied for the last time, is
that of the seasonal adjustment, as it leads to final estimates:</p>
<ul>
<li><p>of the seasonal component (Table D10);</p></li>
<li><p>of the seasonally adjusted series (Table D11);</p></li>
<li><p>of the trend component (Table D12);</p></li>
<li><p>of the irregular component (Table D13).</p></li>
</ul>
<!-- -->
<ul>
<li><strong>Part E: Components modified for large extreme values</strong></li>
</ul>
<p>Parts E includes:</p>
<ul>
<li><p>Components modified for large extreme values;</p></li>
<li><p>Comparison the annual totals of the raw time series and seasonally adjusted time series;</p></li>
<li><p>Changes in the final seasonally adjusted series;</p></li>
<li><p>Changes in the final trend;</p></li>
<li><p>Robust estimation of the final seasonally adjusted series.</p></li>
</ul>
<p>The results from part E are used in part F to calculate the quality measures.</p>
<ul>
<li><strong>Part F: Seasonal adjustment quality measures</strong></li>
</ul>
<p>Part F contains statistics for judging the quality of the seasonal
adjustment. JDemetra+ presents selected output for part F, i.e.:</p>
<ul>
<li><p>M and Q statistics;</p></li>
<li><p>Tables.</p></li>
</ul>
<!-- -->
<ul>
<li><strong>Part G: Graphics</strong></li>
</ul>
<p>Part G presents spectra estimated for:</p>
<ul>
<li><p>Raw time series adjusted a priori (Table B1);</p></li>
<li><p>Seasonally adjusted time series modified for large extreme values
(Table E2);</p></li>
<li><p>Final irregular component adjusted for large extreme values (Table
E3).</p></li>
</ul>
<p>Originally, graphics were displayed in character mode. In JDemetra+,
these graphics are replaced favourably by the usual graphics software.</p>
<p><strong>The Henderson moving average and the trend estimation</strong></p>
<p>In iteration B (Table B7), iteration C (Table C7) and iteration D (Table
D7 and Table D12) the trend component is extracted from an estimate of
the seasonally adjusted series using Henderson moving averages. The
length of the Henderson filter is chosen automatically by
X-13ARIMA-SEATS in a two-step procedure.</p>
<p>It is possible to specify the length of the Henderson moving average to
be used. X-13ARIMA-SEATS provides an automatic choice between a 9-term,
a 13-term or a 23-term moving average. The automatic choice of the order
of the moving average is based on the value of an indicator called
<span class="math inline">\(\frac{\overline{I}}{\overline{C}}\ \)</span>ratio which compares the magnitude
of period-on-period movements in the irregular component with those in
the trend. The larger the ratio, the higher the order of the moving
average selected. Moreover, X-13ARIMA-SEATS allows the user to choose
manually any odd‑numbered Henderson moving average. The procedure used
in each part is very similar; the only differences are the number of
options available and the treatment of the observations in the both ends
of the series. The procedure below is applied for a monthly time series.</p>
<p>In order to calculate <span class="math inline">\(\frac{\overline{I}}{\overline{C}}\ \)</span> ratio a
first decomposition of the SA series (seasonally adjusted) is computed
using a 13-term Henderson moving average.</p>
<p>For both the trend (<span class="math inline">\(C\)</span>) and irregular (<span class="math inline">\(I\)</span>) components, the average of
the absolute values for monthly growth rates (multiplicative model) or
for monthly growth (additive model) are computed. They are denoted as
<span class="math inline">\(\overline{C}\ \)</span>and <span class="math inline">\(\overline{I}\)</span>, receptively, where
<span class="math inline">\(\overline{C} = \frac{1}{n - 1}\sum_{t = 2}^{n}\left| C_{t} - C_{t - 1} \right|\)</span>
and
<span class="math inline">\(\overline{I} = \frac{1}{n - 1}\sum_{t = 2}^{n}\left| I_{t} - I_{t - 1} \right|\)</span>.</p>
<p>Then the value of <span class="math inline">\(\frac{\overline{I}}{\overline{C}}\ \)</span> ratio is checked
and in iteration B:</p>
<ul>
<li><p>If the ratio is smaller than 1, a 9-term Henderson moving average is selected;</p></li>
<li><p>Otherwise, a 13-term Henderson moving average is selected.</p></li>
</ul>
<p>Then the trend is computed by applying the selected Henderson filter to
the seasonally adjusted series from Table B6. The observations at the
beginning and at the end of the time series that cannot be computed by
means of symmetric Henderson filters are estimated by ad hoc asymmetric
moving averages.</p>
<p>In iterations C and D:</p>
<ul>
<li><p>If the ratio is smaller than 1, a 9-term Henderson moving average is selected;</p></li>
<li><p>If the ratio is greater than 3.5, a 23-term Henderson moving average is selected.</p></li>
<li><p>Otherwise, a 13-term Henderson moving average is selected.</p></li>
</ul>
<p>The trend is computed by applying selected Henderson filter to the
seasonally adjusted series from Table C6, Table D7 or Table D12,
accordingly. At the both ends of the series, where a central Henderson
filter cannot be applied, the asymmetric ends weights for the 7 term
Henderson filter are used.</p>
</div>
<div id="choosing-the-composite-moving-averages-when-estimating-the-seasonal-component" class="section level5 hasAnchor" number="4.7.1.2.2">
<h5><span class="header-section-number">4.7.1.2.2</span> <strong>Choosing the composite moving averages when estimating the seasonal component</strong><a href="seasonal-adjustment-1.html#choosing-the-composite-moving-averages-when-estimating-the-seasonal-component" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>In iteration D, Table D10 shows an estimate of the seasonal factors
implemented on the basis of the modified SI (Seasonal – Irregular)
factors estimated in Tables D4 and D9bis. This component will have to be
smoothed to estimate the seasonal component; depending on the importance
of the irregular in the SI component, we will have to use moving
averages of varying length as in the estimate of the Trend/Cycle where
the <span class="math inline">\(\frac{\overline{I}}{\overline{C}}\ \)</span> ratio was used to select the
length of the Henderson moving average. The estimation includes several
steps.</p>
<p><strong><em>Step 1: Estimating the irregular and seasonal components</em></strong></p>
<p>An estimate of the seasonal component is obtained by smoothing, month by
month and therefore column by column, Table D9bis using a simple 7-term
moving average, i.e. of coefficients
<span class="math display">\[\frac{1}{7} \left\{1,\ 1,\ 1,\ 1,\ 1,\ 1,\ 1\right\}\]</span>. In order not to
lose three points at the beginning and end of each column, all columns
are completed as follows. Let us assume that the column that corresponds
to the month is composed of <span class="math inline">\(N\)</span> values
<span class="math display">\[
\left\{ x_{1},\ x_{2},\ x_{3},\ \ldots x_{N - 1},\ x_{N} \right\}.
\]</span>
It
will be transformed into a series
<span class="math display">\[\left\{ {x_{- 2},x_{- 1}{,x}_{0},x}_{1},\ x_{2},\ x_{3},\ \ldots x_{N - 1},\ x_{N},x_{N + 1},\ x_{N + 1},\ x_{N + 2},\ x_{N + 3} \right\}\\]</span> with <span class="math display">\[x_{- 2} = x_{- 1} = x_{0} = \frac{x_{1} + x_{2} + x_{3}}{3}\]</span> and <span class="math display">\[x_{N + 1} = x_{N + 2} = x_{N + 3} = \frac{x_{N} + x_{N - 1} + x_{N - 2}}{3}\]</span>.
We then have the required estimates: <span class="math inline">\(S = M_{7}(D9bis)\)</span> and
<span class="math inline">\(I = D9bis - S\)</span>.</p>
<p><strong><em>Step 2: Calculating the Moving Seasonality Ratios</em></strong></p>
<p>For each <span class="math inline">\(i^{\text{th}}\)</span> month the mean annual changes for each
component is obtained by calculating
<span class="math display">\[{\overline{S}}_{i} = \frac{1}{N_{i} - 1}\sum_{t = 2}^{N_{i}}\left| S_{i,t} - S_{i,t - 1} \right|\]</span>
and
<span class="math display">\[{\overline{I}}_{i} = \frac{1}{N_{i} - 1}\sum_{t = 2}^{N_{i}}\left| I_{i,t} - I_{i,t - 1} \right|\]</span>,
where <span class="math inline">\(N_{i}\)</span> refers to the number of months <span class="math inline">\(\text{i}\)</span>in the data,
and the moving seasonality ratio of month <span class="math inline">\(i\)</span>:
<span class="math display">\[MSR_{i} = \frac{\ {\overline{I}}_{i}}{ {\overline{S}}_{i}}\]</span>.
These ratios are presented in <em>Details</em> of the <em>Quality Measures</em> node
under the <em>Decomposition (X11)</em> section. These ratios are used to
compare the year-on-year changes in the irregular component with those
in the seasonal component. The idea is to obtain, for each month, an
indicator capable of selecting the appropriate moving average for the
removal of any noise and providing a good estimate of the seasonal
factor. The higher the ratio, the more erratic the series, and the
greater the order of the moving average should be used. As for the rest,
by default the program selects the same moving average for each month,
but the user can select different moving averages for each month.</p>
<p><strong><em>Step 3: Calculating the overall Moving Seasonality Ratio</em></strong></p>
<p>The overall Moving Seasonality Ratio is calculated as follows:</p>
<p><span class="math display">\[\text{MSR}_{i} = \frac{\sum_{i}^{}{N_{i}\ }\ {\overline{I}}_{i}}{\sum_{i}^{}N_{i}{\overline{S}}_{i}}\]</span> <span class="math display">\[13\]</span><!---\[7.73\]--></p>
<p><strong><em>Step 4: Selecting a moving average and estimating the seasonal
component</em></strong></p>
<p>Depending on the value of the ratio, the program automatically selects a
moving average that is applied, column by column (i.e. month by month)
to the Seasonal/Irregular component in Table D8 modified, for extreme
values, using values in Table D9.</p>
<p>The default selection procedure of a moving average is based on the
Moving Seasonality Ratio in the following way:</p>
<ul>
<li><p>If this ratio occurs within zone A (MSR &lt; 2.5), a <span class="math inline">\(3 \times 3\)</span> moving average is used; if it occurs within zone C (3.5 &lt; MSR &lt; 5.5), a <span class="math inline">\(3 \times 5\)</span> moving average is selected; if it occurs within zone E (MSR &gt; 6.5), a <span class="math inline">\(3 \times 9\)</span> moving average is used;</p></li>
<li><p>If the MSR occurs within zone B or D, one year of observations is removed from the end of the series, and the MSR is recalculated.
&gt; If the ratio again occurs within zones B or D, we start over
&gt; again, removing a maximum of five years of observations. If this
&gt; does not work, i.e. if we are again within zones B or D, a
&gt; <span class="math inline">\(3 \times 5\)</span> moving average is selected.</p></li>
</ul>
<p>The chosen symmetric moving average corresponds, as the case may be 5
(<span class="math inline">\(3 \times 3\)</span>), 7 <span class="math inline">\((3 \times 5)\ \)</span>or 11 (<span class="math inline">\(3 \times 9\)</span><span class="math inline">\(3 \times 9)\)</span>
terms, and therefore does not provide an estimate for the values of
seasonal factors in the first 2 (or 3 or 5) and the last 2 (or 3 or 5)
years. These are then calculated using associated asymmetric moving
averages.</p>
<p><strong>Moving average selection procedure, source: DAGUM, E. B.(1999)</strong></p>
</div>
<div id="identification-and-replacement-of-extreme-values" class="section level5 hasAnchor" number="4.7.1.2.3">
<h5><span class="header-section-number">4.7.1.2.3</span> <strong>Identification and replacement of extreme values</strong><a href="seasonal-adjustment-1.html#identification-and-replacement-of-extreme-values" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>X-13ARIMA-SEATS detects and removes outliers in the RegARIMA part.
However, if there is a seasonal heteroscedasticity in a time series i.e.
the variance of the irregular component is different in different
calendar months. Examples for this effect could be the weather and
snow-dependent output of the construction sector in Germany during
winter, or changes in Christmas allowances in Germany and resulting from
this a transformation in retail trade turnover before Christmas. The
ARIMA model is not on its own able to cope with this characteristic. The
practical consequence is given by the detection of additional extreme
values by X-11. This may not be appropriate if the seasonal
heteroscedasticity is produced by political interventions or other
influences. The ARIMA models assume a constant variance and are
therefore not by themselves able to cope with this problem. Choosing
longer (in the case of diverging weather conditions in the winter time
for the construction sector) or shorter filters (in the case of a
changing pattern of retail trade turnover in the Christmas time) may be
reasonable in such cases. It may even be sensible to take into account
the possibility of period-specific (e.g. month-specific) standard
deviations, which can be done by changing the default settings of the
<strong>calendarsigma</strong> parameter (see <a href="../reference-manual/sa-spec-X13.html">Specifications-X13</a> section). The value of the
<strong>calendarsigma</strong> parameter will have an impact on the method of
calculation of the moving standard deviation in the procedure for
extreme values detection presented below.</p>
<p><strong><em>Step 1: Estimating the seasonal component</em></strong></p>
<p>The seasonal component is estimated by smoothing the SI component
separately for each period using a <span class="math inline">\(3 \times 3\)</span> moving average, i.e.:</p>
<p><span class="math display">\[
  \frac{1}{9} \times \begin{Bmatrix}   
  1,0,0,0,0,0,0,0,0,0,0,0, \\           
  2,0,0,0,0,0,0,0,0,0,0,0, \\           
  3,0,0,0,0,0,0,0,0,0,0,0, \\           
  2,0,0,0,0,0,0,0,0,0,0,0, \\           
  1,0,0,0,0,0,0,0,0,0,0,0, \\           
  \end{Bmatrix}
  \]</span> <span class="math display">\[14\]</span><!---\[7.74\]--></p>
<p><strong><em>Step 2: Normalizing the seasonal factors</em></strong></p>
<p>The preliminary seasonal factors are normalized in such a way that for
one year their average is equal to zero (additive model) or to unity
(multiplicative model).</p>
<p><strong><em>Step 3: Estimating the irregular component</em></strong></p>
<p>The initial normalized seasonal factors are removed from the
Seasonal-Irregular component to provide an estimate of the irregular
component.</p>
<p><strong><em>Step 4: Calculating a moving standard deviation</em></strong></p>
<p>By default, a moving standard deviation of the irregular component is
calculated at five-year intervals. Each standard deviation is associated
with the central year used to calculate it. The values in the central
year, which in the absolute terms deviate from average by more than the
<strong>Usigma</strong> parameter
are marked as extreme values and assigned a zero weight. After excluding
the extreme values the moving standard deviation is calculated once
again.</p>
<p><strong><em>Step 5: Detecting extreme values and weighting the irregular</em></strong></p>
<p>The default settings for assigning a weight to each value of irregular
component are:</p>
<ul>
<li><p>Values which are more than <strong>Usigma</strong> (2.5, by default) standard
deviations away (in the absolute terms) from the 0 (additive) or 1
(multiplicative) are assigned a zero weight;</p></li>
<li><p>Values which are less than 1.5 standard deviations away (in the
absolute terms) from the 0 (additive) or 1 (multiplicative) are
assigned a full weight (equal to one);</p></li>
<li><p>Values which lie between 1.5 and 2.5 standard deviations away (in the absolute terms) from the 0 (additive) or 1 (multiplicative) are assigned a weight that varies linearly between 0 and 1 depending on their position.</p></li>
</ul>
<p>The default boundaries for the detection of the extreme values can be
changed with <strong>LSigma</strong> and <strong>USigma</strong> parameters</p>
<p><strong><em>Step 6: Adjusting extreme values of the seasonal-irregular
component</em></strong></p>
<p>Values of the SI component are considered extreme when a weight less
than 1 is assigned to their irregular. Those values are replaced by a
weighted average of five values:</p>
<ul>
<li><p>The value itself with its weight;</p></li>
<li><p>The two preceding values, for the same period, having a full weight(if available);</p></li>
<li><p>The next two values, for the same period, having full a weight (if available).</p></li>
</ul>
<p>When the four full-weight values are not available, then a simple
average of all the values available for the given period is taken.</p>
<p>This general algorithm is used with some modification in parts B and C
for detection and replacement of extreme values.</p>
</div>
<div id="x-11-tables" class="section level5 hasAnchor" number="4.7.1.2.4">
<h5><span class="header-section-number">4.7.1.2.4</span> <strong>X-11 tables</strong><a href="seasonal-adjustment-1.html#x-11-tables" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The list of tables produced by JDemetra+ is presented below. It is not
identical to the output produced by the original X-11 program.</p>
<p><strong>Part A – Preliminary Estimation of Outliers and Calendar Effects.</strong></p>
<p>This part includes prior modifications to the original data made in the
RegARIMA part:</p>
<ul>
<li><p>Table A1 – Original series;</p></li>
<li><p>Table A1a – Forecast of Original Series;</p></li>
<li><p>Table A2 – Leap year effect;</p></li>
<li><p>Table A6 – Trading Day effect (1 or 6 variables);</p></li>
<li><p>Table A7 – The Easter effect;</p></li>
<li><p>Table A8 – Total Outlier Effect;</p></li>
<li><p>Table A8i – Additive outlier effect;</p></li>
<li><p>Table A8t – Level shift effect;</p></li>
<li><p>Table A8s – Transitory effect;</p></li>
<li><p>Table A9 – Effect of user-defined regression variables assigned to the seasonally adjusted series or for which the component has not been defined;</p></li>
<li><p>Table 9sa – Effect of user-defined regression variables assigned to the seasonally adjusted series;</p></li>
<li><p>Table9u – Effect of user-defined regression variables for which the component has not been defined.</p></li>
</ul>
<p><strong>Part B – Preliminary Estimation of the Time Series Components:</strong></p>
<ul>
<li><p>Table B1 – Original series after adjustment by the RegARIMA model;</p></li>
<li><p>Table B2 – Unmodified Trend (preliminary estimation using composite moving average);</p></li>
<li><p>Table B3 – Unmodified Seasonal – Irregular Component (preliminary estimation);</p></li>
<li><p>Table B4 – Replacement Values for Extreme SI Values;</p></li>
<li><p>Table B5 – Seasonal Component;</p></li>
<li><p>Table B6 – Seasonally Adjusted Series;</p></li>
<li><p>Table B7 – Trend (estimation using Henderson moving average);</p></li>
<li><p>Table B8 – Unmodified Seasonal – Irregular Component;</p></li>
<li><p>Table B9 – Replacement Values for Extreme SI Values;</p></li>
<li><p>Table B10 – Seasonal Component;</p></li>
<li><p>Table B11 – Seasonally Adjusted Series;</p></li>
<li><p>Table B13 – Irregular Component;</p></li>
<li><p>Table B17 – Preliminary Weights for the Irregular;</p></li>
<li><p>Table B20 – Adjustment Values for Extreme Irregulars.</p></li>
</ul>
<p><strong>Part C – Final Estimation of Extreme Values and Calendar Effects:</strong></p>
<ul>
<li><p>Table C1 – Modified Raw Series;</p></li>
<li><p>Table C2 – Trend (preliminary estimation using composite moving average);</p></li>
<li><p>Table C4 – Modified Seasonal – Irregular Component;</p></li>
<li><p>Table C5 – Seasonal Component;</p></li>
<li><p>Table C6 – Seasonally Adjusted Series;</p></li>
<li><p>Table C7 – Trend (estimation using Henderson moving average);</p></li>
<li><p>Table C9 – Seasonal – Irregular Component;</p></li>
<li><p>Table C10 – Seasonal Component;</p></li>
<li><p>Table C11 – Seasonally Adjusted Series;</p></li>
<li><p>Table C13 – Irregular Component;</p></li>
<li><p>Table C20 – Adjustment Values for Extreme Irregulars.</p></li>
</ul>
<p><strong>Part D – Final Estimation of the Different Components:</strong></p>
<ul>
<li><p>Table D1 – Modified Raw Series;</p></li>
<li><p>Table D2 – Trend (preliminary estimation using composite moving average);</p></li>
<li><p>Table D4 – Modified Seasonal – Irregular Component;</p></li>
<li><p>Table D5 – Seasonal Component;</p></li>
<li><p>Table D6 – Seasonally Adjusted Series;</p></li>
<li><p>Table D7 – Trend (estimation using Henderson moving average);</p></li>
<li><p>Table D8 – Unmodified Seasonal – Irregular Component;</p></li>
<li><p>Table D9 – Replacement Values for Extreme SI Values;</p></li>
<li><p>Table D10 – Final Seasonal Factors;</p></li>
<li><p>Table D10A – Forecast of Final Seasonal Factors;</p></li>
<li><p>Table D11 – Final Seasonally Adjusted Series;</p></li>
<li><p>Table D11A – Forecast of Final Seasonally Adjusted Series;</p></li>
<li><p>Table D12 – Final Trend (estimation using Henderson moving average);</p></li>
<li><p>Table D12A – Forecast of Final Trend Component;</p></li>
</ul>
<!-- -->
<ul>
<li><p>Table D13 – Final Irregular Component;</p></li>
<li><p>Table D16 – Seasonal and Calendar Effects;</p></li>
<li><p>Table D16A – Forecast of Seasonal and Calendar Component;</p></li>
<li><p>Table D18 – Combined Calendar Effects Factors.</p></li>
</ul>
<p><strong>Part E – Components Modified for Large Extreme Values:</strong></p>
<ul>
<li><p>Table E1 – Raw Series Modified for Large Extreme Values;</p></li>
<li><p>Table E2 – SA Series Modified for Large Extreme Values;</p></li>
<li><p>Table E3 – Final Irregular Component Adjusted for Large Extreme Values;</p></li>
<li><p>Table E11 – Robust Estimation of the Final SA Series.</p></li>
</ul>
<p><strong>Part F – Quality indicators:</strong></p>
<ul>
<li><p>Table F2A – Changes, in the absolute values, of the principal components;</p></li>
<li><p>Table F2B – Relative contribution of components to changes in the raw series;</p></li>
<li><p>Table F2C – Averages and standard deviations of changes as a function of the time lag;</p></li>
<li><p>Table F2D – Average duration of run;</p></li>
<li><p>Table F2E – I/C ratio for periods span;</p></li>
<li><p>Table F2F – Relative contribution of components to the variance of the stationary part of the original series;</p></li>
<li><p>Table F2G – Autocorrelogram of the irregular component.</p></li>
</ul>
</div>
</div>
<div id="filter-length-choice" class="section level4 hasAnchor" number="4.7.1.3">
<h4><span class="header-section-number">4.7.1.3</span> Filter length choice<a href="seasonal-adjustment-1.html#filter-length-choice" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A seasonal filter is a weighted average of a moving span of fixed length
within a time series that can be used to remove a fixed seasonal pattern.
X-13ARIMA-SEATS uses several of these filters, according to the needs of
the different stages of the program. As only X-13ARIMA-SEATS allows the
user to manually select seasonal filters, this case study can be
applied only to the X-13ARIMA-SEATS specifications.</p>
<p>The automatic seasonal adjustment procedure uses the default
options to select the most appropriate moving average. However there are
occasions when the user will need to specify a different seasonal moving<br />
average to that identified by the program. For example, if the SI values
do not closely follow the seasonal component, it may be appropriate to
use a shorter moving average. Also the presence of sudden breaks in
the seasonal pattern – e.g. due to changes in the methodology – can
negatively impact on the automatic selection of the most appropriate
seasonal filter. In such cases the usage of short seasonal filters in
the selected months or quarters can be considered. Usually, a shorter
seasonal filter <span class="math inline">\((3 \times 1)\)</span> allows seasonality to change very rapidly
over time. However, a very short seasonal filter should not normally be
used, as it might often lead to large revisions as new data becomes
available. If a short filter is to be used it will usually be limited to one
month/quarter with a known reason for wanting to capture
a rapidly changing seasonality.</p>
<p>In the standard situation one seasonal filter is applied to all
individual months/quarters. The estimation of seasonal movements is
therefore based on the sample windows of equal lengths for each
individual month/quarter (i.e. for each month/quarter the seasonal
filter length or the number of years representing the major part of the
seasonal filter weights is identical). This approach relies on the
assumption that the number of past periods in which the conditions
causing seasonal behaviour are sufficiently homogenous is the same in
all months/quarters. However, this assumption does not always hold.
Seasonal causes may change in one month, while staying the same in
others<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>. For instance, seasonal heteroskedasticity might require
different filter lengths in different months or quarters.</p>
<p>Another interesting example is industrial production in Germany. It can
be influenced by school holidays, since many employees have
school-age children, which interrupt their working pattern during these
school holidays. Consequently, businesses may temporarily suspend or lower
production during these periods. Since school holidays do not occur at the same time
throughout Germany and their timing varies from year to year in the
individual federal states, the effect is not completely captured by
seasonal adjustment. And since school holidays are treated as usual
working days, these effects are not captured by calendar adjustment
either. The majority of school holidays in Germany can take place either
in July or in August. This yields higher variances in the irregular
component for these months compared to the rest of the year. Therefore,
in this case a longer seasonal filter is used for these months to account for
this.</p>
<p>Another example might be given by German retail trade. Due to changes in
the consumers’ behaviour around Christmas – possibly more gifts of money
– the seasonal peak in December has become steadily less pronounced. To
account for this moving seasonality, shorter seasonal filters in
December than during the rest of the year need to be applied.</p>
<p>JDemetra+ offers the options to assign a different seasonal filter
length to each period (month or quarter). The program offers these
options in the <em>single spec</em> mode as well as in the <em>multispec</em> mode,
albeit they are available only in the <em>Specifications</em> window, after a
document is created.</p>
</div>
</div>
<div id="model-based-decomposition" class="section level3 hasAnchor" number="4.7.2">
<h3><span class="header-section-number">4.7.2</span> Model based decomposition<a href="seasonal-adjustment-1.html#model-based-decomposition" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>SEATS is a program for estimating unobserved components in a time
series. It follows the ARIMA-model-based (AMB) method, developed from
the work of CLEVELAND, W.P., and TIAO, G.C. (1976), BURMAN, J.P. (1980),
HILLMER, S.C., and TIAO, G.C. (1982), BELL, W.R., and HILLMER, S.C.
(1984) and MARAVALL, A., and PIERCE, D.A. (1987).</p>
<p>In JDemetra+ the input for the model based signal extraction procedure
is always provided by TRAMO and includes the original series <span class="math inline">\(y_{t}\)</span>,
the linearized series <span class="math inline">\(x_{t}\)</span> (i.e. the original series <span class="math inline">\(y_{t}\ \)</span>with
the deterministic effects removed), the ARIMA model for the stochastic
(linearized) time series <span class="math inline">\(x_{t}\)</span> and the deterministic effects (calendar
effects, outliers and other regression variable effects)<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>. SEATS
decomposes the linearized series (and the ARIMA model) into trend,
seasonal, transitory and irregular components, provides forecasts for
these components, together with the associated standard errors, and
finally assign the deterministic effects to each component yielding the
<em>final</em> components<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>. The Minimum Mean Square Error (MMSE)
estimators of the components are computed with a Wiener-Kolmogorov
filter applied to the finite series extended with forecasts and
backcasts<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>.</p>
<p>One of the fundamental assumptions made by SEATS is that the linearized
time series <span class="math inline">\(x_{t}\)</span> follows the ARIMA model</p>
<p><span class="math display">\[\phi(B)\delta\left( B \right)x_{t} = \theta(B)a_{t}\]</span> <span class="math display">\[1\]</span> <!---\[7.25\]--></p>
<p>where:</p>
<p><span class="math inline">\(B\)</span> – the backshift operator <span class="math inline">\((Bx_{t} = x_{t - 1})\)</span>;</p>
<p><span class="math inline">\(\delta\left( B \right)\)</span> – a non-stationary autoregressive (AR)
polynomial in <span class="math inline">\(B\)</span> (unit roots);</p>
<p><span class="math inline">\(\theta\left( B \right)\)</span> – an invertible moving average (MA) polynomial
in <span class="math inline">\(B\)</span> and in <span class="math inline">\(B^{S}\)</span>, which can be expressed in the multiplicative form</p>
<p><span class="math inline">\(\left( 1 + \vartheta_{1}B + \ldots{+ \ \vartheta}{q}B^{q} \right)\left( \ 1 + \Theta{1}B^{s} + \ldots{+ \ \Theta}_{Q}B^{\text{sQ}} \right)\)</span> ;</p>
<p><span class="math inline">\(\phi(B)\)</span> – a stationary autoregressive (AR) polynomial in <span class="math inline">\(B\)</span> and in
<span class="math inline">\(B^{S}\ \)</span>containing regular and seasonal unit roots, with <em>s</em>
representing the number of observations per year;</p>
<p><span class="math inline">\(a_{t}\)</span> – a white-noise variable with the variance<span class="math inline">\(\ V(a)\)</span>.</p>
<p>It should be noted that the stochastic time series can be predicted
using its past observations and making an error. The variable <span class="math inline">\(a_{t}\)</span>,
which is assumed to be white noise, is the fundamental <em>innovation</em> to
the series at time <em>t</em>, that is the part that cannot be predicted based
on the past history of the series.</p>
<p>Denoting
<span class="math inline">\(\varphi\left( B \right) = \phi\left( B \right)\delta\left( B \right),\ \)</span>
<span class="math display">\[1\]</span> <!---\[7.25\]--> can be written in a more concise form as</p>
<p><span class="math display">\[\varphi\left( B \right)x_{t} = \theta(B)a_{t}\]</span>, <span class="math display">\[2\]</span> <!---\[7.26\]--></p>
<p>where <span class="math inline">\(\varphi\left( B \right)\)</span> contains both the stationary and the
nonstationary roots.</p>
<div id="derivation-of-the-models-for-the-components" class="section level4 hasAnchor" number="4.7.2.1">
<h4><span class="header-section-number">4.7.2.1</span> Derivation of the models for the components<a href="seasonal-adjustment-1.html#derivation-of-the-models-for-the-components" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let us consider the additive decomposition model</p>
<p><span class="math display">\[x_{t} = \sum_{i = 1}^{k}x_{\text{it}}\]</span>, <span class="math display">\[3\]</span> <!---\[7.27\]--></p>
<p>where <em>i</em> refers to the orthogonal components: trend, seasonal,
transitory or irregular. Apart from the irregular component, supposed to
be a white noise, it is assumed that each component follows the ARIMA
model which can be represented, using the notation of <span class="math display">\[2\]</span> <!---\[7.26\]-->, as:</p>
<p><span class="math display">\[\varphi_{i}\left( B \right)\ x_{\text{it}} = \theta_{i}(B)a_{\text{it}}\]</span>, <span class="math display">\[4\]</span> <!---\[7.28\]--></p>
<p>where
<span class="math inline">\(\varphi_{i}\left( B \right) = \phi_{i}\left( B \right)\delta_{i}\left( B \right),\ \ x_{\text{it}}\)</span>
is the <em>i</em>-<em>th</em> unobserved component, <span class="math inline">\(\varphi_{i}\left( B \right)\)</span> and
<span class="math inline">\(\theta_{i}\left( B \right)\)</span> are finite polynomials of order <span class="math inline">\(p_{i}\)</span> and
<span class="math inline">\(q_{i}\)</span>, respectively, and <span class="math inline">\(a_{\text{it}},\)</span> the disturbance associated
with such component, is a white noise process with zero mean and
constant variance <span class="math inline">\(V(a_{i})\)</span> and <span class="math inline">\(a_{\text{it}}\)</span> and
<span class="math inline">\(a_{\text{jt}}\ \)</span>are not correlated for <span class="math inline">\(i \neq j\ \)</span>and for any <span class="math inline">\(t\)</span>..
These disturbances are functions of the innovations in the series and
are called "pseudo-innovations" in the literature concerning the AMB
decomposition as they refer to the components that are never observed
<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a>. In the JDemetra+ documentation the term "innovations" is used to
refer to the "pseudo-innovations".</p>
<p>The following assumptions hold for <span class="math display">\[4\]</span> <!---\[7.28\]-->. For each <span class="math inline">\(\text{i}\)</span> the
polynomials <span class="math inline">\(\phi_{i}\left( B \right)\)</span>, <span class="math inline">\(\delta_{i}\left( B \right)\)</span> and
<span class="math inline">\(\theta_{i}(B)\)</span> are prime and of finite order. The roots of
<span class="math inline">\(\delta_{i}\left( B \right)\)</span> lies on the unit circle; those of
<span class="math inline">\(\phi_{i}\left( B \right)\)</span> lie outside, while all the roots of
<span class="math inline">\(\theta_{i}\left( B \right)\ \)</span>are on or outside the unit circle. This
means that nonstationary and noninvertible components are allowed. Since
different roots of the AR polynomial induce peaks in the spectrum<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a>
of the series at different frequencies, and given that different
components are associated with the spectral peaks for different
frequencies, it is assumed that for <span class="math inline">\(i \neq j\)</span> the
polynomials<span class="math inline">\(\ \phi_{i}\left( B \right)\)</span> and <span class="math inline">\(\phi_{j}\left( B \right)\)</span>
do not share any common root (they are coprime). Finally, it is assumed
that the polynomials <span class="math inline">\(\theta_{i}\left( B \right),\ i = 1,\ldots,k\)</span> are
prime share no unit root in common, guaranteeing the invertibility of
the overall series. In fact, since the unit root of
<span class="math inline">\(\theta_{i}\left( B \right)\)</span> induce a spectral zero, when the
polynomials <span class="math inline">\(\theta_{i}\left( B \right),\ i = 1,\ldots,k\)</span> share no unit
root in common, there is no frequency for which all component spectra
become zero<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a>.</p>
<p>Since aggregation of ARIMA models yields ARIMA models, the series
<span class="math inline">\(x_{t}\ \)</span>will also follow an ARIMA model, as in <span class="math display">\[2\]</span> <!---\[7.26\]-->, and
consequently the following identity can be derived:</p>
<p><span class="math display">\[\frac{\theta(B)}{\varphi(B)}a_{t} = \sum_{i = 1}^{k}{\frac{\theta_{i}(B)}{\varphi_{i}(B)}a_{\text{it}}}\]</span>. <span class="math display">\[5\]</span> <!---\[7.29\]--></p>
<p>In the ARIMA model based approach implemented in SEATS, the ARIMA model
identified and estimated for the observed series <span class="math inline">\(x_{t}\)</span> is
decomposed to derive the models for the components. In particular, the
AR polynomials for the components, <span class="math inline">\(\varphi_{i}\left( B \right),\)</span> are
easily derived through the factorization of the AR polynomial
<span class="math inline">\(\varphi\left( B \right)\)</span>:</p>
<p><span class="math display">\[\varphi\left( B \right) = \prod_{i = 1}^{k}{\varphi_{i}\left( B \right)}\]</span>, <span class="math display">\[6\]</span> <!---\[7.30\]--></p>
<p>while the MA polynomials for the components, together with the
innovation variances <span class="math inline">\(V(a_{i})\)</span>, cannot simply be obtained through the
relationship:</p>
<p><span class="math display">\[\theta(B)a_{t} = \sum_{i = 1}^{k}{\varphi_{\text{ni}}\left( B \right)}\theta_{i}(B)a_{\text{it}}\]</span>, <span class="math display">\[7\]</span> <!---\[7.31\]--></p>
<p>where <span class="math inline">\(\varphi_{\text{ni}}\left( B \right)\)</span> is the product of all
<span class="math inline">\(\varphi_{j}\left( B \right),\ j = 1,\ldots,k\)</span>, except from
<span class="math inline">\(\varphi_{i}\left( B \right)\)</span>. Further assumptions are therefore needed
to cope with the underidentification problem: i) <span class="math inline">\(p_{i} \geq q_{i}\)</span> and
ii) the canonical decomposition, i.e. the decomposition that allocate
all additive white noise to the irregular component (yielding
noninvertible components except the irregular).</p>
<p>To understand how SEATS factorizes the AR polynomials, first a concept
of a root will be explored<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a>.</p>
<p>The equation <span class="math display">\[2\]</span> <!---\[7.26\]--> can be expressed as:</p>
<p><span class="math display">\[\psi^{- 1}(B)x_{t} = a_{t}(1 + \varphi_{1}B + \ldots\varphi_{p}B^{p})x_{t} =(1 + \theta_{1}B + \ldots\theta_{q}B^{q})a_{t}\]</span>, <span class="math display">\[8\]</span> <!---\[7.32\]--></p>
<p>Let us now consider <span class="math display">\[2\]</span> <!---\[7.26\]--> in the inverted form:</p>
<p><span class="math display">\[\theta\left( B \right)y_{t} = \varphi(B)a_{t}\]</span>, <span class="math display">\[9\]</span> <!---\[7.33\]--></p>
<p>If both sides of <span class="math display">\[8\]</span> <!---\[7.32\]--> are multiplied by <span class="math inline">\(x_{t - k}\)</span> with <span class="math inline">\(k &gt; q\)</span>,
and expectations are taken, the right hand side of the equation vanishes
and the left hand side becomes:</p>
<p><span class="math display">\[\varphi(B)\gamma_{k} = \gamma_{k} + \varphi_{1}\gamma_{k - 1} + \ldots\varphi_{p}\gamma_{k - p} = 0 \]</span>, <span class="math display">\[10\]</span> <!---\[7.34\]--></p>
<p>where <span class="math inline">\(B\)</span> operates on the subindex <span class="math inline">\(k\)</span>.</p>
<p>The autocorrelation function <span class="math inline">\(\gamma_{k}\)</span> is a solution of <span class="math display">\[10\]</span> <!---\[7.34\]--> with
the characteristic equation:</p>
<p><span class="math display">\[z^{p} + \varphi_{1}z^{p - 1} + \ldots\varphi_{p - 1}z + \varphi_{p} = 0\]</span>. <span class="math display">\[11\]</span> <!---\[7.35\]--></p>
<p>If <span class="math inline">\(z_{1}\)</span>,…,<span class="math inline">\(\ z_{p}\)</span> are the roots of <span class="math display">\[11\]</span> <!---\[7.35\]-->, the solutions of
<span class="math display">\[10\]</span> <!---\[7.34\]--> can be expressed as:</p>
<p><span class="math inline">\(\gamma_{k} = \sum_{i = 1}^{p}z_{i}^{k}\)</span>, <span class="math display">\[12\]</span> <!---\[7.36\]--></p>
<p>and will converge to zero as <span class="math inline">\(k \rightarrow \infty\)</span> when
<span class="math inline">\(\left| r_{i} \right| &lt; 1,\ i = 1,\ldots,p\)</span>. From <span class="math display">\[10\]</span> <!---\[7.34\]--> and <span class="math display">\[12\]</span> <!---\[7.36\]-->
it can be noticed that <span class="math inline">\(z_{1} = B_{i}^{- 1}\)</span>, meaning that
<span class="math inline">\(z_{1}\)</span>,…,<span class="math inline">\(\ z_{p}\)</span> are the inverses of the roots <span class="math inline">\(B_{1},\ldots,B_{p}\)</span>
of the polynomial <span class="math inline">\(\varphi(B)\)</span>. The convergence of <span class="math inline">\(\gamma_{k}\)</span> implies
that the roots of the <span class="math inline">\(\varphi(B)\)</span> are larger than 1 in modulus (lie
outside the unit circle). Therefore, from the equation</p>
<p><span class="math display">\[
  {\varphi(B)}^{- 1} = \frac{1}{(1 - z_{1})\ldots(1 - z_{1})}
  \]</span> <span class="math display">\[13\]</span> <!---\[7.37\]--></p>
<p>it can be derived that <span class="math inline">\({\varphi(B)}^{- 1}\)</span> is convergent and all its
inverse roots are less than 1 in modulus.</p>
<p>Equation <span class="math display">\[11\]</span> <!---\[7.35\]--> has real and complex roots (solutions). Complex number
<span class="math inline">\(x = a + bi\)</span>, with <span class="math inline">\(a\)</span> and <span class="math inline">\(\text{b}\)</span> both real numbers, can be
represented as <span class="math inline">\(x = r\left( cos(\omega) + i\ sin(\omega \right))\)</span>, where
<span class="math inline">\(i\)</span> is the imaginary unit<span class="math inline">\({\ (i}^{2} = - 1)\)</span>, <span class="math inline">\(r\)</span> is the modulus of <span class="math inline">\(x\)</span>,
that is <span class="math inline">\(\ r = \left| x \right| = \sqrt{a^{2} + b^{2}}\)</span> and <span class="math inline">\(\omega\)</span> is
the argument (frequency). When roots are complex, they are always in
pairs of complex conjugates. The representation of the complex number
<span class="math inline">\(x = a + bi\)</span> has a geometric interpretation in the complex plane
established by the real axis and the orthogonal imaginary axis.</p>
<div class="figure">
<img src="All_images/UG_A_image3.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>Geometric representation of a complex number and of its conjugate</strong></p>
<p>Representing the roots of the characteristic equation <span class="math display">\[11\]</span> <!---\[7.35\]--> in the
complex plane enhances understanding how they are allocated to the
components. When the modulus <span class="math inline">\(r\)</span> of the roots in <span class="math inline">\(\text{z}\)</span> are greater
than 1 (i.e. modulus of the roots in <span class="math inline">\(\varphi(B)\  &lt; 1\)</span>), the solution
of the characteristic equation has a systematic explosive process, which
means that the impact of the given impulse on the time series is more
and more pronounced in time. This behaviour is not in line with the
developments that can be identified in actual economic series.
Therefore, the models estimated by TRAMO-SEATS (and X-13ARIMA-SEATS)
have never inverse roots in <span class="math inline">\(B\)</span> with modulus greater than 1.</p>
<p>The characteristic equations associated with the regular and the
seasonal differences have roots in <span class="math inline">\(\varphi(B)\)</span> with modulus <span class="math inline">\(r = 1\)</span>.
They are called non-stationary roots and can be represented on the unit
circle. Let us consider the seasonal differencing operator applied to a
quarterly time series <span class="math inline">\((1 - B^{4})\)</span>. Its characteristic equation is
<span class="math inline">\({(z}^{4} - 1) = 0\)</span> with solutions given by<span class="math inline">\(\ z = \sqrt[4]{1}\)</span>, i.e.
<span class="math inline">\(z_{1,2} = \pm 1\)</span> and <span class="math inline">\(z_{3,4} = \pm i1\)</span>. The first two solutions are
real and the last two are complex conjugates. They are represented by
the black points on the unit circle on the figure below.</p>
<div class="figure">
<img src="All_images/UG_A_image4.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>Unit roots on the unit circle</strong></p>
<p>For the seasonal differencing operator <span class="math inline">\((1 - B^{12})\)</span> applied to the
monthly time series the characteristic equation <span class="math inline">\({\ (z}^{12} - 1) = 0\)</span>
has twelve non-stationary solutions given by<span class="math inline">\(\ z = \sqrt[12]{1}:\)</span> two
real and ten complex conjugates, represented by the white circles in
unit roots figure above.</p>
<p>The complex conjugates roots generate the periodic movements of the
type:</p>
<p><span class="math display">\[z_{t} = A^{t}\cos\left( \omega t + W \right).\]</span> <span class="math display">\[14\]</span> <!---\[7.38\]--></p>
<p>where:</p>
<p><span class="math inline">\(A\)</span> – amplitude;</p>
<p><span class="math inline">\(\omega\)</span> – angular frequency (in radians);</p>
<p><span class="math inline">\(W\)</span> – phase (angle at <span class="math inline">\(t = 0)\)</span>.</p>
<p>The frequency <span class="math inline">\(f\)</span>, i.e. the number of cycles per unit time, is
<span class="math inline">\(\frac{\omega}{2\pi}\)</span>. If it is multiplied by <em>s</em>, the number of
observations per year, the number of cycles completed in one year is
derived. The period of function <span class="math display">\[14\]</span> <!---\[7.38\]-->, denoted by <span class="math inline">\(\tau\)</span>, is the
number of units of time (months/quarters) it takes for a full circle to
be completed.</p>
<p>For quarterly series the seasonal movements are produced by complex
conjugates roots with angular frequencies at <span class="math inline">\(\frac{\pi}{2}\)</span> (one cycle
per year) and <span class="math inline">\(\pi\)</span> (two cycles per year). The corresponding number of
cycles per year and the length of the movements are presented in the table below.</p>
<p><strong>Seasonal frequencies for a quarterly time series</strong></p>
<p>{: .table .table-style}
| <strong>Angular frequency (<span class="math inline">\(\omega\)</span>)</strong> | <strong>Frequency (cycles per unit time) (<span class="math inline">\(f\)</span>)</strong> | <strong>Cycles per year</strong> | <strong>Length of the movement measured in quarters (<span class="math inline">\(\tau\)</span>)</strong> |
|—————–|—————–|—————–|—————–|
| <span class="math inline">\(\frac{\pi}{2}\)</span> | 0.25 | 1 | 4 |
| <span class="math inline">\(\pi\)</span> | 0.5 | 2 | 2 |</p>
<p>For monthly time series the seasonal movements are produced by complex
conjugates roots at the angular frequencies:
<span class="math inline">\(\ \frac{\pi}{6},\frac{\pi}{3},\ \frac{\pi}{2},\ \frac{2\pi}{3},\ \frac{5\pi}{6}\ \)</span>and
<span class="math inline">\(\pi\)</span>. The corresponding number of cycles per year and the length of the
movements are presented in the table below: Seasonal frequencies for a monthly
time series.</p>
<p><strong>Seasonal frequencies for a monthly time series</strong></p>
<p>{: .table .table-style}
| <strong>Angular frequency (<span class="math inline">\(\omega\)</span>)</strong> | <strong>Frequency (cycles per unit time) (<span class="math inline">\(f\)</span>)</strong> | <strong>Cycles per year</strong> | <strong>Length of the movement measured in months (<span class="math inline">\(\tau\)</span>)</strong> |
|—————–|—————–|—————–|—————–|
| <span class="math inline">\(\frac{\pi}{6}\)</span> | 0.083 | 1 | 12 |
| <span class="math inline">\(\frac{\pi}{3}\)</span> | 0.167 | 2 | 6 |
| <span class="math inline">\(\frac{\pi}{2}\)</span> | 0.250 | 3 | 4 |
| <span class="math inline">\(\frac{2\pi}{3}\)</span> | 0.333 | 4 | 3 |
| <span class="math inline">\(\frac{5\pi}{6}\)</span> | 0.417 | 5 | 2.4 |
| <span class="math display">\[\pi\]</span> | 0.500 | 6 | 2 |</p>
<p>In JDemetra+ SEATS assigns the roots of the AR full polynomial to the
components according to their associated modulus and frequency,
i.e.:<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a></p>
<ul>
<li><p>Roots of <span class="math inline">\(\left( 1 - B \right)^{d}\)</span> are assigned to trend component.</p></li>
<li><p>Roots of
<span class="math inline">\(\ \left( 1 - B^{s} \right)^{d_{s}} = {((1 - B)(1 + B + \ldots + B^{s - 1}))}^{d_{s}}\ \)</span>are
assigned to the trend component (root
of<span class="math inline">\({\ \left( 1 - B \right)}^{d_{s}}\)</span>) and to the seasonal component
(roots of<span class="math inline">\({\ (1 + B + \ldots + B^{s - 1})}^{d_{s}}\)</span>).</p></li>
<li><p>When the modulus of the inverse of a real positive root of
<span class="math inline">\(\varphi(B)\)</span> is greater than <span class="math inline">\(k\)</span> or equal to <span class="math inline">\(k\)</span>, where <span class="math inline">\(k\)</span> is the
threshold value controlled by the <em>Trend boundary</em> parameter(in the
original SEATS it is controlled by <em>rmod</em>)<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a>, then the root is
assigned to the trend component. Otherwise it is assigned to the
transitory component.</p></li>
<li><p>Real negative inverse roots of
<span class="math inline">\(\text{ ϕ}_{p}\left( B \right)\ \)</span>associated with the seasonal
two-period cycle are assigned to the seasonal component if their
modulus is greater than <em>k</em>, where <span class="math inline">\(k\)</span> is the threshold value
controlled by the <em>Seasonal boundary</em> and the <em>Seas. boundary
(unique)</em> parameters. Otherwise they are assigned to the transitory
component.</p></li>
<li><p>Complex roots, for which the argument (angular frequency) is close
enough to the seasonal frequency are assigned to the seasonal
component. Closeness is controlled by the <em>Seasonal tolerance</em> and
<em>Seasonal tolerance (unique)</em> parameters (in the original SEATS it
is controlled by <em>epsphi</em>). Otherwise they are assigned to the
transitory component.</p></li>
<li><p>If <span class="math inline">\(d_{s}\ \)</span>(seasonal differencing order) is present<span class="math inline">\(\ \)</span>and
<span class="math inline">\(\text{Bphi} &lt; 0\)</span> (<span class="math inline">\(\text{Bphi}\)</span> is the estimate of the seasonal
autoregressive parameter), the real positive inverse root is
assigned to the trend component and the other (<span class="math inline">\(s - 1\)</span>) inverse
roots are assigned to the seasonal component. When <span class="math inline">\(d_{s} = 0\)</span>, the
root is assigned to the seasonal when <span class="math inline">\(\text{Bphi} &lt; - 0.2\)</span> and/or
the overall test for seasonality indicates presence of seasonality.
Otherwise it goes to the transitory component. Also, when
<span class="math inline">\(\text{Bphi} &gt; 0\)</span>, roots are assigned to the transitory component.</p></li>
</ul>
<p>For further details about JDemetra+ parameters see section <a href="../reference-manual/sa-spec-tramo.html">TramoSeats</a>.</p>
<p>It should be highlighted that when<span class="math inline">\(\ Q &gt; P\)</span>, where <span class="math inline">\(Q\)</span> and <span class="math inline">\(P\)</span> denote
the orders of the polynomials <span class="math inline">\(\varphi\left( B \right)\)</span> and <span class="math inline">\(\theta(B)\)</span>,
the SEATS decomposition yields a pure MA <span class="math inline">\((Q - P)\)</span> component (hence
transitory). In this case the transitory component will appear even when
there is no AR factor allocated to it.</p>
<p>Once these rules are applied, the factorization of the AR polynomial
presented by <span class="math display">\[2\]</span> <!---\[7.26\]--> yields to the identification of the AR polynomials
for the components which contain, respectively, the AR roots associated
with the trend component, the seasonal component and the transitory
component.<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a></p>
<p>Then with the partial fraction expansion the spectrum of the final
components are obtained.</p>
<p>For example, the Airline model for a monthly time series:</p>
<p><span class="math display">\[(1 - B)(1 - B^{12})x_{t} = (1 + \theta_{1}B)(1 + \Theta_{1}B^{12})\ a_{t}\]</span>, <span class="math display">\[15\]</span> <!---\[7.39\]--></p>
<p>is decomposed by SEATS into the model for the trend component:</p>
<p><span class="math display">\[(1 - B)(1 - B)c_{t} = (1 + \theta_{c,1}B + \theta_{c,2}B^{2})a_{c,t}\]</span>, <span class="math display">\[16\]</span> <!---\[7.40\]--></p>
<p>and the model for the seasonal component:</p>
<p><span class="math display">\[\left( 1 + B + \ldots + B^{11} \right)s_{t} = \left( 1 + \theta_{s,1}B + \ldots + {\theta_{s,11}B}^{11} \right)a_{s,t},\]</span> <span class="math display">\[17\]</span> <!---\[7.41\]--></p>
<p>As a result, the Airline model is decomposed as follows:</p>
<p><span class="math display">\[\frac{(1 + \theta_{1}B)(1 + \Theta_{1}B^{12})}{(1 - B)(1 - B)}a_{t} = \frac{\left( 1 + \theta_{s,1}B + \ldots + {\theta_{s,11}B}^{11} \right)}{\left( 1 + B + \ldots + B^{11} \right)}a_{s,t} + \frac{(1 + \theta_{c,1}B + \theta_{c,2}B^{2})}{(1 - B)(1 - B)}a_{c,t} + u_{t}\]</span>. <span class="math display">\[18\]</span> <!---\[7.42\]--></p>
<p>The transitory component is not present in this case and the irregular
component is the white noise.</p>
<p>The partial fractions decomposition is performed in a frequency domain.
In essence, it consists in portioning of the pseudo-spectrum<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a>
of <span class="math inline">\(x_{t}\)</span> into additive spectra of the components. When the AMB
decomposition of the ARIMA model results in the non-negative spectra for
all components, the decomposition is called admissible<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a>. In such
case an infinite number of admissible decompositions exists, i.e.
decompositions that yield the non-negative spectra of all components.
Therefore, the MA polynomials and the innovation variances cannot be yet
identified from the model of <span class="math inline">\(x_{t}\)</span>. As sketched above, to
solve this underidentification problem and identify a unique
decomposition, it is assumed that for each component the order of the MA
polynomial is no greater than the order of the AR polynomial and the
canonical solution of S.C. Hillmer and G.C. Tiao is applied<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a>, i.e.
all additive white noise is added to the irregular component As a
consequence all components derived from the canonical decomposition,
except from the irregular, have a spectral minimum of zero and are thus
noninvertible<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a>. Given the stochastic features of the series, it can
be shown by that the canonical decomposition produces as stable as
possible trend and seasonal components since it maximizes the variance
of the irregular and minimizes the variance of the other
components<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a>. However, there is a price to be paid as canonical
components can produce larger revisions in the preliminary estimators of
the component<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a> than any other admissible decomposition.</p>
<p>The figure below represents the pseudo-spectrum for the canonical trend and an
admissible trend.</p>
<div class="figure">
<img src="All_images/UG_A_image5.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>A comparison of canonical trend and admissible trend</strong></p>
<p>A pseudo-spectrum is denoted by<span class="math inline">\(\ g_{i}(\omega)\)</span>, where <span class="math inline">\(\omega\)</span>
represents the angular frequency. The pseudo-spectrum of <span class="math inline">\(x_{\text{it}}\)</span>
is defined as the Fourier transform of ACGF of<span class="math inline">\(\ x_{t}\)</span> which is
expressed as:</p>
<p><span class="math display">\[\frac{\psi_{i}\left( B \right)\psi_{i}\left( F \right)}{\delta_{i}\left( B \right)\delta_{i}\left( F \right)}V(a_{i})\]</span>, <span class="math display">\[19\]</span> <!---\[7.43\]--></p>
<p>where:</p>
<p><span class="math inline">\(\psi_{i}\left( F \right) = \frac{\theta_{i}\left( F \right)}{\phi_{i}\left( F \right)}\)</span></p>
<p><span class="math inline">\(\psi_{i}\left( B \right) = \frac{\theta_{i}\left( B \right)}{\phi_{i}\left( B \right)}\)</span></p>
<p><span class="math inline">\(B\)</span> is the backward operator,</p>
<p><span class="math inline">\(F\)</span> is the forward operator.</p>
<p>A pseudo-spectrum for a monthly time series <span class="math inline">\(x_{t}\ \)</span>is presented in
the figure below: The pseudo-spectrum for a monthly series. The frequency
<span class="math inline">\(\omega = 0\)</span> is associated with the trend, frequencies in the range
<span class="math display">\[$0 + \epsilon_{1},\ \frac{\pi}{6} - \epsilon_{2}$\]</span> with
<span class="math inline">\(\left[0 + \epsilon_{1},\ \frac{\pi}{6} - \epsilon_{2}\right]\)</span>
<span class="math inline">\(\epsilon_{1},\ \epsilon_{2} &gt; 0\)</span> and
<span class="math inline">\(\epsilon_{1} &lt; \ \frac{\pi}{6} - \epsilon_{2}\ \)</span> are usually associated
with the business-cycle and correspond to a period longer than a year
and bounded<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a>. The frequencies in the range <span class="math display">\[$\frac{\pi}{6},\ \pi$\]</span>
are associated with the short term movements, whose cycle is completed
in less than a year. If a series contains an important periodic
component, its spectrum reveals a peak around the corresponding
frequency and in the ARIMA model it is captured by an AR root. In the
example below spectral peaks occur at the frequency <span class="math inline">\(\omega = 0\)</span> and at
the seasonal frequencies ( <span class="math inline">\(\frac{\pi}{6}\)</span>,
<span class="math inline">\(\frac{2\pi}{6},\ \frac{3\pi}{6},\ \frac{4\pi}{6},\frac{5\pi}{6},\pi\)</span>).
<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a></p>
<div class="figure">
<img src="All_images/UG_A_image6.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>The pseudo-spectrum for a monthly series</strong></p>
<p>In the decomposition procedure, the pseudo-spectrum of the time series
<span class="math inline">\(x_{t}\)</span> is divided into the spectra of its components (in the
example figure below, four components were obtained).</p>
<div class="figure">
<img src="All_images/UG_A_image7.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>The pseudo-spectra for the components</strong></p>
</div>
<div id="estimation-of-the-components-with-the-wiener-kolmogorow-filter" class="section level4 hasAnchor" number="4.7.2.2">
<h4><span class="header-section-number">4.7.2.2</span> Estimation of the components with the Wiener-Kolmogorow filter<a href="seasonal-adjustment-1.html#estimation-of-the-components-with-the-wiener-kolmogorow-filter" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The various components are estimated using Wiener-Kolmogorow (WK)
filters. JDemetra+ includes three options to estimate the WK filter,
namely <em>Burman</em>, <em>KalmanSmoother</em> and <em>MCElroyMatrix</em><a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a>. Here the
first of abovementioned options, proposed by BURMAN, J.P. (1980) will be
explained.</p>
<p>The estimation procedure and the properties of the WK filter are easier
to explain with a two-component model. Let the seasonally adjusted
series (<span class="math inline">\(s_{t}\)</span>) be the signal of interest and the seasonal component
(<span class="math inline">\(n_{t}\)</span>) be the remainder, "the noise". The series is given by the
model <span class="math display">\[2\]</span> <!---\[7.26\]--> and from <span class="math display">\[4\]</span> <!---\[7.28\]--> the models for theoretical components
are:</p>
<p><span class="math display">\[\varphi_{s}(B)s_{t} = \theta_{s}(B)a_{\text{st}}\]</span> <span class="math display">\[20\]</span> <!---\[7.44\]--></p>
<p>and</p>
<p><span class="math display">\[\varphi_{n}(B)n_{t} = \theta_{n}(B)a_{\text{nt}}\]</span>. <span class="math display">\[21\]</span> <!---\[7.45\]--></p>
<p>From <span class="math display">\[6\]</span> <!---\[7.30\]--> and <span class="math display">\[7\]</span> <!---\[7.31\]--> it is clear that
<span class="math inline">\(\varphi\left( B \right) = \varphi_{s}(B)\varphi_{n}(B)\)</span> and
<span class="math inline">\(\theta\left( B \right)a_{t} = \theta_{s}(B)a_{\text{st}}+\theta_{n}(B)a_{\text{nt}}\)</span>.</p>
<p>As the time series components are never observed, their estimators have
to be used. Let us note <span class="math inline">\(X_{T}\)</span> an infinite realization of the
time series <span class="math inline">\(x_{t}\)</span>. SEATS computes the Minimum Mean Square Error (MMSE)
estimator of <span class="math inline">\(s_{t}\)</span>, e.g. the estimator <span class="math display">\[\widehat{s}_{t}\]</span> that
minimizes <span class="math display">\[E\lbrack\left({s_{t}-{\widehat{s}}_{t})}^{2}|X_{T} \right)\rbrack\]</span>.
Under the normality assumption <span class="math display">\[{\widehat{s}}_{t|T}\]</span> is also equal to
the conditional expectation <span class="math display">\[E\left(s_{t}|X_{T}\right)\]</span>, so it
can be presented as a linear function of the elements
in <span class="math display">\[X_{T}\]</span>.<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a> WHITTLE (1963) shows that the MMSE estimator of
<span class="math display">\[{\widehat{s}}_{t}\]</span> is:</p>
<p><span class="math display">\[{\widehat{s}}_{t} = k_{s}\frac{\psi_{s}(B)\psi_{s}(F)}{\psi(B)\psi(F)}x_{t}\]</span>, <span class="math display">\[22\]</span> <!---\[7.46\]--></p>
<p>where <span class="math display">\[\psi(B)= \frac{\theta(B)}{\phi(B)}\]</span>,</p>
<p><span class="math display">\[F = B^{- 1}\]</span> and <span class="math display">\[k_{s}=\frac{V(a_{s})}{V(a)}\]</span>,</p>
<p><span class="math display">\[V(a_{s})\]</span> is the variance of <span class="math display">\[a_{st}\]</span> and <span class="math display">\[V(a)\]</span> is
the variance of <span class="math display">\[a_{t}\]</span>.</p>
<p>Expressing the <span class="math display">\[\psi\left(B\right)\]</span> polynomials as functions of the AR
and MA polynomials, after cancelation of roots, the estimator
of <span class="math display">\[s_{t}\]</span> can be expressed as:</p>
<p><span class="math display">\[{\widehat{s}}_{t} = k_{s}\frac{\theta_{s}\left(B\right)\theta_{s}\left(F\right)\varphi_{n}\left(B \right)\delta_{n}\left(B\right)\varphi_{n}\left(F\right)\delta_{n}\left(F\right)}{\theta\left(B\right)\theta\left(F \right)}x_{t}\]</span>, <span class="math display">\[23\]</span> <!---\[7.47\]--></p>
<p>where:</p>
<p><span class="math display">\[\nu_{s}\left( B,F \right) = k_{s}\frac{\theta_{s}\left( B \right)\theta_{s}\left( F \right)\varphi_{n}\left( B \right)\delta_{n}\left( B \right)\varphi_{n}\left( F \right)\delta_{n}\left( F \right)}{\theta\left( B \right)\theta\left( F \right)}\]</span> <span class="math display">\[24\]</span> <!---\[7.48\]--></p>
<p>is a WK filter.</p>
<p>Equation <span class="math display">\[24\]</span> <!---\[7.48\]--> shows that the WK filter is two-sided (uses
observations both from the past and from the future), centered (the
number of points in the past is the same as in the future) and symmetric
(for any <span class="math inline">\(k\)</span> the weight applied to <span class="math inline">\(x_{t - k}\)</span> and <span class="math inline">\(x_{t + k}\)</span> is the
same), which allows the phase effect to be avoided. Due to invertibility
of <span class="math inline">\(\theta\left( B \right)\)</span> (and <span class="math inline">\(\theta\left( F \right)\)</span>) the filter is
convergent in the past and in the future.</p>
<p>The estimator can be presented as</p>
<p><span class="math display">\[{\widehat{s}}_{t} = \nu_{i}\left(B,F\right)x_{t}\]</span>, <span class="math display">\[25\]</span> <!---\[7.49\]--></p>
<p>where</p>
<p><span class="math display">\[\nu_{i}\left(B,F\right)=\nu_{0}+ \sum_{j = 1}^{\infty}\nu_{ij}(B^{j}+F^{j})\]</span></p>
<p>is the WK filter.</p>
<p>The example of the WK filters obtained for the pseudo-spectra of the
series illustrated above is shown on the figure below: WK filters for components.</p>
<div class="figure">
<img src="All_images/UG_A_image8.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>WK filters for components</strong></p>
<p>The WK filter from <span class="math display">\[24\]</span> <!---\[7.48\]--> can also be expressed as a ratio of two
pseudo-autocovariance generating functions (p-ACGF). The p-ACGF function
summarizes the sequence of absolutely summable autocovariances of a
stationary process <span class="math inline">\(x_{t}\)</span> (see section section <a href="..\theory\spectral.html">Spectral Analysis</a>).</p>
<p>The ACGF function of an ARIMA process is expressed as:</p>
<p><span class="math display">\[acgf(B) = \frac{\theta\left( B \right)\theta\left( F \right)}{\phi\left( B \right)\delta\left( B \right)\phi\left( F \right)\delta\left( F \right)}V(a)\]</span> <span class="math display">\[26\]</span> <!---\[7.50\]--></p>
<p>And, the WK filter can be rewritten as:</p>
<p><span class="math display">\[\nu_{s}\left( B,F \right) = \frac{\gamma_{s}(B,F)}{\gamma(B,F)}\]</span>, <span class="math display">\[27\]</span> <!---\[7.51\]--></p>
<p>where:</p>
<p><span class="math display">\[\gamma_{s}\left( B,F \right) = \frac{\theta_{s}\left( B \right)\theta_{s}\left( F \right)}{\phi_{s}\left( B \right)\delta_{s}\left( B \right)\phi_{s}\left( F \right)\delta_{s}\left( F \right)}V(a_{s})\]</span>
is the p-ACGF of <span class="math display">\[s_{t}\]</span>;</p>
<p><span class="math inline">\(\gamma\left( B,F \right) = \frac{\theta\left( B \right)\theta\left( F \right)}{\phi\left( B \right)\delta\left( B \right)\phi\left( F \right)\delta\left( F \right)}V(a)\)</span>
is the p-ACGF of <span class="math inline">\(x_{t}\)</span>.</p>
<p>From <span class="math display">\[24\]</span> <!---\[7.48\]--> it can be seen that the WK filter depends on both the
component and the series models. Consequently, the estimator of the
component and the WK filter reflect the characteristic of data and by
construction, the WK filter adapts itself to the series under
consideration. Therefore, the ARIMA model is of particular importance
for the SEATS method. Its misspecification results in an incorrect
decomposition.</p>
<p>This adaptability, if the model has been correctly determined, avoids
the dangers of under and overestimation with an ad-hoc filtering. For
example, for the series with a highly stochastic seasonal component the
filter adapts to the width of the seasonal peaks and the seasonally
adjusted series does not display any spurious seasonality<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a>. Examples
of WK filters for stochastic and stable seasonal components are
presented on the figure below.</p>
<div class="figure">
<img src="All_images/UG_A_image9.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>WK filters for stable and stochastic seasonal components</strong></p>
<p>The derivation of the components requires an infinite realization of
<span class="math inline">\(x_{t}\)</span> in the direction of the past and of the future. However, the
convergence of the WK filter guarantees that, in practice, it could be
approximated by a truncated (finite) filter and, in most applications,
for large <span class="math display">\[k\]</span> the estimator for the central periods of the
series can be safely seen as generated by the WK filter<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a>:</p>
<p><span class="math display">\[{\widehat{s}}_{t}=\nu_{k}x_{t-k} + \ldots + \nu_{0}x_{t} + \ldots + \nu_{k}x_{t+k}\]</span>. <span class="math display">\[28\]</span> <!---\[7.52\]--></p>
<p>When <span class="math inline">\(T &gt; 2L + 1\)</span>, where <span class="math inline">\(T\)</span> is the last observed period, and <span class="math inline">\(L\)</span> is an
a priori number that typically expands between 3 and 5 years, the
estimator expressed by <span class="math display">\[23\]</span> <!---\[7.47\]--> can be assumed as the final (historical)
estimator for the central observations of the series<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a>. In practice,
the Wiener-Kolmogorov filter is applied to <span class="math inline">\(x_{t}\)</span> extended with
forecasts and backcasts from the ARIMA model. The final or historical
estimator of <span class="math display">\[{\widehat{s}}_{t}\]</span>, is obtained with a doubly infinite
filter, and therefore contains an error <span class="math display">\[e_{st}\]</span> called final
estimation error, which is equal <span class="math display">\[e_{st}=s_{t}-{\widehat{s}}_{t}\]</span>.</p>
<p>In the frequency domain, the Wiener-Kolmogorov filter<span class="math inline">\(\ \nu(B,F)\)</span> that
provides the final estimator of <span class="math inline">\(s_{t}\ \)</span>is expressed as the ratio of
the <span class="math inline">\(s_{t}\ \)</span>and <span class="math inline">\(x_{t}\)</span> pseudo-spectra:</p>
<p><span class="math display">\[\widetilde{\nu}\left( \omega \right) = \frac{g_{s}(\omega)}{g_{x}(\omega)}\]</span>. <span class="math display">\[29\]</span> <!---\[7.53\]--></p>
<p>The function <span class="math inline">\(\widetilde{\nu}\left( \omega \right)\ \)</span>is also referred as
the gain of the filter.<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a> GÓMEZ, V., and MARAVALL, A. (2001a) show
that when for some frequency the signal (the seasonally adjusted series)
dominates the noise (seasonal fluctuations) the gain
<span class="math inline">\(\widetilde{\nu}\left( \omega \right)\)</span> approaches 1. On the contrary,
when for some frequency the noise dominates the gain
<span class="math inline">\(\widetilde{\nu}\left( \omega \right)\ \)</span>approaches 0.</p>
<p>The spectrum of the estimator of the seasonal component is expressed as:</p>
<p><span class="math display">\[g_{\widehat{s}}\left( \omega \right) = \left\lbrack \frac{g_{s}(\omega)}{g_{x}(\omega)} \right\rbrack^{2}g_{x}(\omega)\]</span>, <span class="math display">\[30\]</span> <!---\[7.54\]--></p>
<p>where<span class="math inline">\(\ \left\lbrack \widetilde{\nu}\left( \omega \right) \right\rbrack^{2} = \left\lbrack \frac{g_{s}(\omega)}{g_{x}(\omega)} \right\rbrack^{2} = \left\lbrack \frac{g_{s}(\omega)}{g_{s}(\omega) + g_{n}(\omega)} \right\rbrack^{2} = \left\lbrack \frac{1}{1 + \frac{1}{r(\omega)}} \right\rbrack^{2}\)</span>
is the squared gain of the filter and
<span class="math inline">\(r\left( \omega \right) = \frac{g_{s}(\omega)}{g_{n}(\omega)}\)</span>
represents the signal-to-noise ratio.</p>
<p>For each <span class="math inline">\(\omega\)</span>, the MMSE estimation gives the signal-to-noise ratio.
If this ratio is high, then the contribution of that frequency to the
estimation of the signal will be also high. Assume that the trend is a
signal that needs to be extracted from a seasonal time series. Then
<span class="math inline">\(R\left( 0 \right) = 1\ \)</span>and the frequency <span class="math inline">\(\omega = 0\)</span> will only be
used for trend estimations. For seasonal frequencies
<span class="math inline">\(R\left( \omega \right) = 0,\)</span> so that these frequencies are ignored in
computing the trend resulting in spectral zeros in
<span class="math inline">\(g_{\widehat{s}}\left( \omega \right)\)</span>. For this reason, unlike the
spectrum of the component, the component spectrum contains dips as it
can be seen on the figure below: Component spectrum and estimator
spectrum for trend.</p>
<div class="figure">
<img src="All_images/UG_A_image10.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>Component spectrum and estimator spectrum for trend</strong></p>
<p>From the equation <span class="math display">\[29\]</span> <!---\[7.53\]--> it is clear that the squared gain of the
filter determines how the variance of the series contributes to the
variance of the seasonal component for the different frequencies. When
<span class="math inline">\(\widetilde{\nu}\left( \omega \right) = 1\)</span>, the full variation of
<span class="math inline">\(x_{t}\)</span> for that frequency is passed to <span class="math display">\[{\widehat{s}}_{t}\]</span>, while if
<span class="math display">\[\widetilde{\nu}\left(\omega\right) = 0 \]</span> the variation of <span class="math inline">\(x_{t}\)</span> for
that frequency is fully ignored in the computation of
<span class="math display">\[{\widehat{s}}_{t}\]</span>. These two cases are well illustrated by the figure below
that shows the square gain of the WK filter for two series already
analysed in the figure above (Figure: WK filters for stable and stochastic seasonal components).</p>
<div class="figure">
<img src="All_images/UG_A_image11.png" alt="" />
<p class="caption">Text</p>
</div>
<p><strong>The squared gain of the WK filter for stable and stochastic seasonal components.</strong></p>
<p>Since <span class="math inline">\(r\left( \omega \right) \geq 0\)</span>, then
<span class="math inline">\(\widetilde{\nu}\left( \omega \right) \leq 1\)</span> and from <span class="math display">\[29\]</span> <!---\[7.53\]--> it can
be derived that
<span class="math inline">\(g_{\widehat{s}}\left( \omega \right) = \widetilde{\nu}\left( \omega \right)g_{s}(\omega)\)</span>.
As a result, the estimator will always underestimate the component, i.e.
it will be always more stable that the component.<a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a></p>
<p>Since
<span class="math inline">\(g_{\widehat{n}}\left( \omega \right) &lt; g_{n}\left( \omega \right)\)</span>
and<span class="math inline">\(\ g_{\widehat{s}}\left( \omega \right) &lt; g_{s}\left( \omega \right)\)</span>
the expression:
<span class="math inline">\(g_{x}\left( \omega \right) - \left\lbrack g_{\widehat{n}}\left( \omega \right) + g_{\widehat{s}}\left( \omega \right) \right\rbrack \geq 0\)</span>
is the cross-spectrum. As it is positive, the MMSE yields correlated
estimators. This effect emerges since variance of estimator is smaller
than the variance of component. Nevertheless, if at least one
non-stationary component exists, cross-correlations estimated by
TRAMO-SEATS will tend to zero as cross-covariances between estimators of
the components are finite. In practice, the inconvenience caused by this
property will likely be of little relevance.</p>
<p><strong>Preliminary estimators for the components</strong></p>
<p>GÓMEZ, V., and MARAVALL, A. (2001a) point out that <em>the properties of
the estimators have been derived for the final (or historical)
estimators. For a finite (long enough) realization, they can be assumed
to characterize the estimators for the central observations of the
series, but for periods close to the beginning of the end the filter
cannot be completed and some preliminary estimator has to be used</em>.
Indeed, the historical estimator shown in <span class="math display">\[28\]</span> <!---\[7.52\]--> is obtained for the
central periods of the series. However, when <span class="math inline">\(t\)</span> approaches <span class="math inline">\(T\)</span> (last
observation), the WK filter requires observations, which are not
available yet. For this reason a preliminary estimator needs to be used.</p>
<p>To introduce preliminary estimators let us consider a semi-finite
realization <span class="math inline">\(\lbrack x_{- \infty}\)</span>,…<span class="math inline">\(\ x_{T}\)</span>], where <span class="math inline">\(T\)</span> is the last
observed period. The preliminary estimator of <span class="math display">\[x_{\text{it}}\]</span> obtained
at <span class="math inline">\(T\)</span> <span class="math display">\[(T - t = k \geq 0)\]</span> can be expressed as</p>
<p><span class="math display">\[
{\widehat{x}}_{it|t + k}=\nu_{i}\left(B,F\right)x_{t|T}^{e}
\]</span>, <span class="math display">\[31\]</span> <!---\[7.55\]--></p>
<p>where <span class="math display">\[\nu_{i}\left(B,F \right)\]</span> is the WK filter and <span class="math display">\[x_{t|T}^{e}\]</span> is
the extended series, such that <span class="math inline">\(x_{t|T}^{e} = x_{t}\)</span> for <span class="math inline">\(t \leq T\)</span> and
<span class="math display">\[x_{t|T}^{e}={\widehat{x}}_{t|T}\]</span> for <span class="math display">\[t&gt;T\]</span>, where
<span class="math display">\[{\widehat{x}}_{t|T}\]</span> denotes the forecast of <span class="math inline">\(x_{t}\)</span> obtained at period
<span class="math inline">\(T\)</span>.</p>
<p>The future <span class="math inline">\(k\)</span> values necessary to apply the filter are not yet
available and are replaced by their optimal forecasts from the ARIMA
model on <span class="math display">\[x_{t}\]</span>. When <span class="math display">\[k=0\]</span> the preliminary estimator becomes
the concurrent estimator. As the forecasts are linear functions of
present and past observations of <span class="math display">\[x_{t}\]</span>, the preliminary
estimator <span class="math display">\[{\widehat{x}}_{it}\]</span> will be a truncated asymmetric
filter applied to <span class="math display">\[x_{t}\]</span> that generates a phase effect<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a>.</p>
<p>When a new observation <span class="math display">\[x_{T + 1}\]</span> becomes available the forecast
<span class="math display">\[{\widehat{x}}_{T + 1|T}\]</span> is replaced by the observation and the
forecast <span class="math display">\[{\widehat{x}}_{iT + j|T}\]</span>, <span class="math display">\[j &gt; 1\]</span> are updated to
<span class="math display">\[x_{T + j|T + 1}\]</span> resulting in the revision error<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a>. The total error
in the preliminary estimator <span class="math display">\[d_{it|t + k}\]</span> is expressed as a sum of the
final estimation error (<span class="math display">\[e_{it}\]</span>) and the revision error
(<span class="math display">\[r_{it|t + k}\]</span>), i.e.:</p>
<p><span class="math display">\[
d_{it|t + k} = x_{it}-{\widehat{x}}_{it|t + k} = \left(x_{it} - {\widehat{x}}_{it}\right) + \left(          {\widehat{x}}_{it} - {\widehat{x}}_{it|t + k} \right) = e_{it} + r_{it|t + k}
\]</span>, <span class="math display">\[32\]</span> <!---\[7.56\]--></p>
<p>where:</p>
<p><span class="math display">\[x_{it}-i^{th}\]</span> component;</p>
<p><span class="math display">\[{\widehat{x}}_{it|t + k}\]</span>- the estimator of <span class="math display">\[x_{it}\]</span> when the
last observation is <span class="math display">\[x_{t + k}\]</span>.</p>
<p>Therefore the preliminary estimator is subject not only to the final
error but also to a revision error, which are orthogonal to each
other<a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a>. The revision error decreases as <span class="math display">\[k\]</span> increases, until
it can be assumed equal to 0 for large enough <span class="math display">\[k\]</span>.</p>
<p>It’s worth remembering that SEATS estimates the unobservable components
of the time series so the "true" components are never observed.
Therefore, MARAVALL, A. (2009) stresses that <em>the error in the
historical estimator is more of academic rather than practical interest.
In practice, interest centres on revisions. (…) the revision standard
deviation will be an indicator of how far we can expect to be from the
optimal estimator that will be eventually attained, and the speed of
convergence of</em> <span class="math inline">\({\theta\left( B \right)\ }^{- 1}\)</span> <em>will dictate the
speed of convergence of the preliminary estimator to the historical
one.</em> The analysis of an error is therefore useful for making decision
concerning the revision policy, including the policy for revisions and
horizon of revisions.</p>
</div>
<div id="psie-weights" class="section level4 hasAnchor" number="4.7.2.3">
<h4><span class="header-section-number">4.7.2.3</span> PsiE-weights<a href="seasonal-adjustment-1.html#psie-weights" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The estimator of the component is calculated as
<span class="math display">\[{\widehat{x}}_{it} = \nu_{s}\left(B,F\right)x_{t}\]</span>. By replacing
<span class="math display">\[x_{it}=\frac{\theta(B)}{\gamma(B)\delta(B)}a_{t}\]</span>, the
component estimator can be expressed as<a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a>:</p>
<p><span class="math display">\[
  {\widehat{x}}_{it} = \xi_{s}\left(B,F\right)a_{t}
  \]</span>, <span class="math display">\[33\]</span> <!---\[7.57\]--></p>
<p>where
<span class="math inline">\(\xi_{s}\left( B,F \right) = \ldots + \xi_{j}B^{j} + \ldots + \xi_{1}B + \xi_{0} + \xi_{- 1}F\ldots\xi_{- j}F^{j} + \ldots\)</span>.</p>
<p>This representation shows the estimator as a filter applied to the
innovation <span class="math display">\[a_{t}\]</span>, rather than on the
series <span class="math display">\[x_{t}\]</span><a href="#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a>. Hence, the filter from <span class="math display">\[32\]</span> <!---\[7.56\]--> can be
divided into two components: the first one, i.e.
<span class="math display">\[\ldots + \xi_{j}B^{j}+ \ldots+ \xi_{1}B + \xi_{0}\]</span>, applies to
prior and concurrent innovations, the second one, i.e.
<span class="math display">\[\xi_{- 1}F + \ldots + \xi_{- j}F^{j}\]</span> applies to future (i.e.
posterior to <span class="math display">\[t\]</span>) innovations. Consequently, <span class="math display">\[\xi_{j}\]</span>
determines the contribution of <span class="math display">\[a_{t - j}\]</span> to <span class="math display">\[{\widehat{s}}_{t}\]</span> while
<span class="math display">\[\xi_{- j}\]</span> determines the contribution of <span class="math display">\[a_{t + j}\]</span> to
<span class="math display">\[{\widehat{s}}_{t}\]</span>. Finally, the estimator of the component can be
expressed as:</p>
<p><span class="math display">\[
  {\widehat{x}}_{it} =\xi_{i}(B)^{-}a_{t} + \xi_{i}(F)^{+}a_{t + 1}
  \]</span>, <span class="math display">\[34\]</span> <!---\[7.58\]--></p>
<p>where:</p>
<p><span class="math inline">\(\xi_{i}{(B)}^{-}a_{t}\)</span> is an effect of starting conditions, present and
past innovations in series;</p>
<p><span class="math inline">\(\xi_{i}{(F)}^{+}a_{t + 1}\)</span> is an effect of future innovations.</p>
<p>For the two cases already presented in figure <em>WK filters for stable and stochastic seasonal components</em> and figure <em>The squared gain of the WK filter for stable and stochastic seasonal components</em> above, the psi-weights are shown in the figure below.</p>
<div class="figure">
<img src="All_images/UG_A_image12.png" alt="" />
<p class="caption">Text</p>
</div>
<p>It can be shown that <span class="math display">\[{\xi}_{- 1},\ldots,\xi_{- j}\]</span> are convergent and
<span class="math display">\[\xi_{j},\ldots, {\xi}_{1},\xi_{0}\]</span> are divergent. From <span class="math display">\[33\]</span> <!---\[7.57\]-->, the
concurrent estimator is equal to
<span class="math display">\[
{\widehat{x}}_{it|t} = E_{t}x_{it}=E_{t}{\widehat{x}}_{it} = {\xi}_{i}(B)^{-}a_{t}
\]</span>, <span class="math display">\[35\]</span> <!---\[7.59\]--></p>
<p>so that the revision
<span class="math display">\[
r_{it} = {\widehat{x}}_{it} - {\widehat{x}}_{it|t} = \xi_{i}(F)^{+}a_{t + 1}
\]</span> <span class="math display">\[36\]</span> <!---\[7.60\]--></p>
<p>is a zero-mean stationary MA process. As a result, historical and
preliminary estimators are cointegrated. From expression <span class="math display">\[25\]</span> <!---\[7.49\]--> the
relative size of the full revision and the speed of convergence can be
obtained.</p>

</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>When the series are non-stationary differentiation is performed
before the seasonality tests.<a href="seasonal-adjustment-1.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>The unmodified Seasonal-Irregular component corresponds to the
Seasonal-Irregular factors with the extreme values.<a href="seasonal-adjustment-1.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>DAGUM, E.B. (1987).<a href="seasonal-adjustment-1.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>For definition of the periodogram and Fourier frequencies see section <a href="..\theory\spectral.html">Spectral Analysis</a><a href="seasonal-adjustment-1.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>For definition of the periodogram and Fourier frequencies see section <a href="..\theory\spectral.html">Spectral Analysis</a><a href="seasonal-adjustment-1.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>When the series are non-stationary differentiation is performed
before the seasonality tests.<a href="seasonal-adjustment-1.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>When the series are non-stationary differentiation is performed
before the seasonality tests.<a href="seasonal-adjustment-1.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>In the original software SEATS can be used either with TRAMO,
operating on the input received from the latter, or alone, fitting
an ARIMA model to the series.<a href="seasonal-adjustment-1.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>GÓMEZ, V., and MARAVALL, A. (1998).<a href="seasonal-adjustment-1.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>GÓMEZ, V., and MARAVALL, A. (1997).<a href="seasonal-adjustment-1.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>GÓMEZ, V., and MARAVALL, A. (2001a).<a href="seasonal-adjustment-1.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>For description of the spectrum see section <a href="..\theory\spectral.html">Spectral Analysis</a>.<a href="seasonal-adjustment-1.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>MARAVALL, A. (1995).<a href="seasonal-adjustment-1.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>Description based on KAISER, R., and MARAVALL, A. (2000) and
MARAVALL, A. (2008c).<a href="seasonal-adjustment-1.html#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>For details see MARAVALL, A., CAPORELLO, G., PÉREZ, D., and
LÓPEZ, R. (2014).<a href="seasonal-adjustment-1.html#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>In JDemetra+ this argument is called <em>Trend boundary</em>.<a href="seasonal-adjustment-1.html#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p>The AR roots close to or at the trading day frequency generates a
stochastic trading day component. A stochastic trading day component
is always modelled as a stationary ARMA(2,2), where the AR part
contains the roots close to the TD frequency, and the MA(2) is
obtained from the model decomposition (MARAVALL, A., and PÉREZ, D.
(2011)). This component, estimated by SEATS, is not implemented by
the current version of JDemetra+.<a href="seasonal-adjustment-1.html#fnref17" class="footnote-back">↩︎</a></p></li>
<li id="fn18"><p>The term pseudo-spectrum is used for a non-stationary time
series, while the term spectrum is used for a stationary time
series.<a href="seasonal-adjustment-1.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>If the ARIMA model estimated in TRAMO does not accept an
admissible decomposition, SEATS replaces it with a decomposable
approximation. The modified model is therefore used to decompose the
series. There are also other rare situations when the ARIMA model
chosen by TRAMO is changed by SEATS. It happens when, for example,
the ARIMA models generate unstable seasonality or produce a
senseless decomposition. Such examples are discussed by MARAVALL, A.
(2009).<a href="seasonal-adjustment-1.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>HILLMER, S.C., and TIAO, G.C. (1982).<a href="seasonal-adjustment-1.html#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p>GÓMEZ, V., and MARAVALL, A. (2001a).<a href="seasonal-adjustment-1.html#fnref21" class="footnote-back">↩︎</a></p></li>
<li id="fn22"><p>HILLMER, S.C., and TIAO, G.C. (1982).<a href="seasonal-adjustment-1.html#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p>MARAVALL, A. (1986).<a href="seasonal-adjustment-1.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p>Ibid.<a href="seasonal-adjustment-1.html#fnref24" class="footnote-back">↩︎</a></p></li>
<li id="fn25"><p>KAISER, R., and MARAVALL, A. (2000).<a href="seasonal-adjustment-1.html#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p>The choice of the estimation method is controlled by the <em>Method</em>
parameter, explained in the <a href="../reference-manual/sa-spec-tramo.html">SEATS specification</a> section.<a href="seasonal-adjustment-1.html#fnref26" class="footnote-back">↩︎</a></p></li>
<li id="fn27"><p>MARAVALL, A. (2008c).<a href="seasonal-adjustment-1.html#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p>MARAVALL, A. (1995).<a href="seasonal-adjustment-1.html#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p>MARAVALL, A., and PLANAS, C. (1999).<a href="seasonal-adjustment-1.html#fnref29" class="footnote-back">↩︎</a></p></li>
<li id="fn30"><p>MARAVALL, A. (1998).<a href="seasonal-adjustment-1.html#fnref30" class="footnote-back">↩︎</a></p></li>
<li id="fn31"><p>GÓMEZ, V., and MARAVALL, A. (2001a).<a href="seasonal-adjustment-1.html#fnref31" class="footnote-back">↩︎</a></p></li>
<li id="fn32"><p>Ibid.<a href="seasonal-adjustment-1.html#fnref32" class="footnote-back">↩︎</a></p></li>
<li id="fn33"><p>KAISER, R., and MARAVALL, A. (2000).<a href="seasonal-adjustment-1.html#fnref33" class="footnote-back">↩︎</a></p></li>
<li id="fn34"><p>MARAVALL, A. (1995).<a href="seasonal-adjustment-1.html#fnref34" class="footnote-back">↩︎</a></p></li>
<li id="fn35"><p>MARAVALL, A. (2009).<a href="seasonal-adjustment-1.html#fnref35" class="footnote-back">↩︎</a></p></li>
<li id="fn36"><p>The section is based on KAISER, R., and MARAVALL, A. (2000).<a href="seasonal-adjustment-1.html#fnref36" class="footnote-back">↩︎</a></p></li>
<li id="fn37"><p>See section PsiE-weights. For further details see MARAVALL, A. (2008).<a href="seasonal-adjustment-1.html#fnref37" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="main-functions-overview.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="high-frequency-data-seasonal-adjustment.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-Seasonal-Adjustment.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
